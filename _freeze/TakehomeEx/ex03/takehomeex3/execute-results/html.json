{
  "hash": "4dcd02f23b57d17e1b09fa53856fdad6",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Take Home Ex 3\"\n\nauthor: \"Cheng Chun Chieh\"\n\ndate: \"18 May 2024\"\ndate-modified: \"last-modified\"\n\nformat: html\nexecute: \n  echo: true\n  eval: true\n  warning: false\n  freeze: true\n  \neditor: visual\n---\n\n\n# 1. Overview\n\nIn Oceanus, island life is defined by the coming and going of seafaring vessels, many of which are operated by commercial fishing companies. Typically, the movement of ships and goods are a sign of Oceanus’s healthy economy, especially in the fishing business. But mundane routines can be disrupted by a major event. Analysts at FishEye International, a non-profit organization that aims to find and prevent illegal fishing, need your help to better understand one such event.\n\nFishEye has learned that SouthSeafood Express Corp has been caught fishing illegally. The scandal caused a major disruption in the close-knit fishing community. FishEye has been collecting data on ship movements and shipping records in hopes that they could assemble a cohesive store of knowledge that will allow them to better understand local commercial fishing behavior. FishEye processed open-source and commercial vessel tracking and shipping records into CatchNet: the Oceanus Knowledge Graph. Analysts examine and correct data as it is loaded but need your help to create analytical capabilities for this data.\n\nFishEye analysts need your help to perform geographic and temporal analysis of the CatchNet data so they can prevent illegal fishing from happening again. Your task is to develop new visual analytics tools and workflows that can be used to discover and understand signatures of different types of behavior. Can you use your tool to visualize a signature of SouthSeafood Express Corp’s illegal behavior? FishEye needs your help to develop a workflow to find other instances of illegal behavior.\n\n1.  FishEye analysts have long wanted to better understand the flow of commercially caught fish through Oceanus’s many ports. But as they were loading data into CatchNet, they discovered they had purchased the wrong port records. They wanted to get the ship off-load records, but they instead got the port-exit records (essentially trucks/trains leaving the port area). Port exit records do not include which vessel that delivered the products. Given this limitation, develop a visualization system to associate vessels with their probable cargos. Which vessels deliver which products and when? What are the seasonal trends and anomalies in the port exit records?\n\n2.  Develop visualizations that illustrate the inappropriate behavior of SouthSeafood Express Corp vessels. How do their movement and catch contents compare to other fishing vessels? When and where did SouthSeafood Express Corp vessels perform their illegal fishing? How many different types of suspicious behaviors are observed? Use visual evidence to justify your conclusions.\n\n3.  To support further Fisheye investigations, develop visual analytics workflows that allow you to discover other vessels engaging in behaviors similar to SouthSeafood Express Corp’s illegal activities? Provide visual evidence of the similarities.\n\n4.  How did fishing activity change after SouthSeafood Express Corp was caught? What new behaviors in the Oceanus commercial fishing community are most suspicious and why?\n\n::: callout-note\nFor this Take-home Ex 3 - I will be focusing on Qn 1 and 2 first. If time is available, I will also attempt to go in to Qn 4.\n\nTo note that we will subsequently package these as part of our project.\n:::\n\n## 1.1 Loading Packages\n\nBecause the data are given in a json file format - we will have to load it using jsonlite. The following are the packages that we will be using for this ex.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, graphlayouts, ggforce, skimr, tidytext, tidyverse)\n```\n:::\n\n\n## 1.2 Data Provided by the Challenge\n\n### 1.2.1 Geography Data of Oceanus\n\n![](data/Oceanus%20Geography.png)\n\n### 1.2.2 Graph Data\n\nThe following is the graph data provided:\n\n-   Directed multi-graph, allowing multiple edges between nodes\n\n-   5637 nodes\n\n-   271752 edges\n\n-   1 (weakly) connected component\n\nWhich covers:\n\n-   **Vessel Movements:** Oceanus is outfitted with a transponder/ping system named the Oceanus Vessel Locator System (OVLS).  Vessels are outfitted with a transponder and periodic 'pings' from base-stations results in a report of vessel locations at any time.  The raw ping granularity is at the minute-level but post-processing has converted it into visit/dwell times. OVLS is generally reliable, though vessel records may be missing for a variety of reasons.\n\n    -   Node/Edge types and properties present\n\n        -   Entity.Vessel: Description of the vessel\n\n        -   Entity.Location: Description of a geographic location\n\n        -   Event.TransponderPing: Links a vessel to a location\n\n-   **Harbor Reports:** Harbor masters regularly report the vessels found in their purview anytime during the day.  This data is derived from a different system than OVLS (see \"Vessel Movements\"), though the data overlaps.  Harbor Reports are provided on a different schedule from different harbors. Since no harbor reports every day, this data has lower temporal granularity than vessel movement data. Additionally, the Harbor Master is also responsible for proximate navigational beacon(s), so this data has lower spatial granularity as well.  However, the list of vessels observed is considered canonical.\n\n    -   Node/edge types present:\n\n        -   Entity.Vessel\n\n        -   Entity.location\n\n        -   Event.HarborReport\n\n-   **Harbor Import Records**: Vessels deliver cargo to the ports, and that cargo is brought into Oceanus.  These records reflect the goods that \\*leave\\* the harbor to go to businesses in Oceanus or to be exported.  It was filtered pre-ingest to focus on the delivery of raw fish.  Because it is raw, fish leave the port quickly (generally one day after delivery).  Due to clerical error, the records purchased by FishEye do not include the vessel that delivered the cargo.\n\n    -   Node/Edge types present:\n\n        -   Entity.location\n\n        -   Entity.Commodity.Fish\n\n        -   Entity.Document.DeliveryReport\n\n        -   Event.Transaction\n\n## 1.3 Importing the Data\n\nWe will use jsonlite to import the data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc2_data <- fromJSON (\"data/mc2.json\")\n```\n:::\n\n\nImporting the nodes and edges as tibble data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc2_edges <-\n  as_tibble(mc2_data$links) %>%\n  distinct()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmc2_nodes <-\n  as_tibble(mc2_data$nodes) %>%\n  distinct()\n```\n:::\n\n\n# 2. Examining the Data\n\n## 2.1 Looking at the Nodes\n\nWe first look at the types of nodes and how many of each are present in the data set:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntype_counts_nodes <- mc2_nodes %>% count(type)\n\nprint(type_counts_nodes)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 12 × 2\n   type                               n\n   <chr>                          <int>\n 1 Entity.Commodity.Fish             10\n 2 Entity.Document.DeliveryReport  5307\n 3 Entity.Location.City               6\n 4 Entity.Location.Point             12\n 5 Entity.Location.Region             6\n 6 Entity.Vessel.CargoVessel        100\n 7 Entity.Vessel.Ferry.Cargo          2\n 8 Entity.Vessel.Ferry.Passenger      3\n 9 Entity.Vessel.FishingVessel      178\n10 Entity.Vessel.Other                5\n11 Entity.Vessel.Research             2\n12 Entity.Vessel.Tour                 6\n```\n\n\n:::\n:::\n\n\nOf note we have:\n\n-   5307 Delivery Reports\n\n-   178 Fishing Vessel (which is our key focus here)\n\n-   10 Fish\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc2_nodes_others <- mc2_nodes %>%\n  filter(!(type %in% c(\"Entity.Vessel.FishingVessel\", \"Entity.Document.DeliveryReport\")))\n```\n:::\n\n\n### 2.1.1 Tidying the Text \n\nFrom the table above, beside the date data type and inappropriate field name issues we discussed earlier, two additional data issues can be observed. They are:\n\n-   The values in Activities and fish_species_present fields are in **list** data type, which will affect the ability to process and to analyse the data.\n\n-   As shown in the screenshot below, some values in the Activities field are not ready to be analyse without further tidying (i.e. removing c(““)).\n\nIn the code chunk below, `mutate()` of dplyr and `gsub()` of Base R are used to perform the data todying task.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc2_nodes_tidied <- mc2_nodes %>%\n  mutate(Activities = gsub(\"c[(]\", \"\", Activities)) %>% \n  mutate(Activities = gsub(\"\\\"\", \"\", Activities)) %>%\n  mutate(Activities = gsub(\"[)]\", \"\", Activities)) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmc2_nodes_tidied <- mc2_nodes_tidied %>%\n  mutate(fish_species_present = gsub(\"c[(]\", \"\", fish_species_present)) %>% \n  mutate(fish_species_present = gsub(\"\\\"\", \"\", fish_species_present)) %>%\n  mutate(fish_species_present = gsub(\"[)]\", \"\", fish_species_present)) \n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(mc2_nodes_tidied, \"data/rds/mc2_nodes_tidied.rds\")\n```\n:::\n\n\n## 2.2 Looking at the Edges\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntype_counts_edges <- mc2_edges %>% count(type)\n\nprint(type_counts_edges)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 2\n  type                                      n\n  <chr>                                 <int>\n1 Event.HarborReport                     2487\n2 Event.Transaction                     10614\n3 Event.TransportEvent.TransponderPing 258542\n```\n\n\n:::\n:::\n\n\n### 2.2.1 Correcting date data type\n\nThe date format is not easily readable - so we need to convert them into something useful.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc2_edges$time <- as_datetime(mc2_edges$time)\nmc2_edges$\"_last_edited_date\" <- as_datetime(mc2_edges$\"_last_edited_date\")\nmc2_edges$\"_date_added\" <- as_datetime(mc2_edges$\"_date_added\")\nmc2_edges$\"date\" <- as_datetime(\"mc2_edges$date\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(mc2_edges)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 271,643\nColumns: 17\n$ type                <chr> \"Event.TransportEvent.TransponderPing\", \"Event.Tra…\n$ time                <dttm> 2035-09-16 04:06:48, 2035-09-20 05:21:33, 2035-09…\n$ dwell               <dbl> 115074.79, 412706.32, 286092.88, 327623.95, 243225…\n$ `_last_edited_by`   <chr> \"Olokun Daramola\", \"Melinda Manning\", \"Olokun Dara…\n$ `_date_added`       <dttm> 2035-09-16 00:59:46, 2035-09-22 02:37:37, 2035-09…\n$ `_last_edited_date` <dttm> 2035-09-16 00:59:46, 2035-09-22 02:37:37, 2035-10…\n$ `_raw_source`       <chr> \"Oceanus Vessel Locator System\", \"Oceanus Vessel L…\n$ `_algorithm`        <chr> \"OVLS-Catch&Hook\", \"OVLS-Catch&Hook\", \"OVLS-Catch&…\n$ source              <chr> \"City of Haacklee\", \"City of Haacklee\", \"City of H…\n$ target              <chr> \"perchplundererbc0\", \"perchplundererbc0\", \"perchpl…\n$ key                 <int> 0, 1, 2, 3, 4, 5, 6, 7, 8, 0, 1, 2, 3, 4, 5, 6, 7,…\n$ date                <dttm> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…\n$ data_author         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ aphorism            <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ holiday_greeting    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ wisdom              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ `saying of the sea` <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n```\n\n\n:::\n:::\n\n\n### 2.2.2 Changing the field names \n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc2_edges <- mc2_edges %>%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"date_added\" = \"_date_added\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"raw_source\" = \"_raw_source\",\n         \"algo\" = \"_algorithm\") \n```\n:::\n\n\n### 2.2.3 Splitting the Text under Type \n\n\n::: {.cell}\n\n```{.r .cell-code}\nword_list <- strsplit(mc2_edges$type, \"\\\\.\")\nmax_elements <- max(lengths(word_list))\nword_list_padded <- lapply(word_list, \nfunction(x) c(x, rep(NA, max_elements - length(x))))\nword_df <- do.call(rbind, word_list_padded)\ncolnames(word_df) <- paste0(\"event\", 1:max_elements)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nword_df <- as_tibble(word_df) %>%\n  select(event2, event3)\nclass(word_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmc2_edges <- mc2_edges %>%\n  cbind(word_df)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwrite_rds(mc2_edges, \"data/rds/mc2_edges.rds\")\n```\n:::\n\n\n## Work in Progress\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmc2_edges_transaction <- mc2_edges %>%\n  filter(type == \"Event.Transaction\")\n```\n:::\n\n\n1.  develop a visualization system to associate vessels with their probable cargos. Which vessels deliver which products and when? What are the seasonal trends and anomalies in the port exit records?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\nlibrary(lubridate)\n\n# Sample vessel data\nvessel_records <- data.frame(\n  vessel_id = c(1, 2, 3, 1, 2, 3),\n  port = c(\"PortA\", \"PortB\", \"PortA\", \"PortA\", \"PortB\", \"PortA\"),\n  offload_date = as.Date(c(\"2023-01-15\", \"2023-01-16\", \"2023-01-17\", \"2023-02-15\", \"2023-02-16\", \"2023-02-17\")),\n  cargo_type = c(\"Fish\", \"Shrimp\", \"Fish\", \"Crab\", \"Lobster\", \"Fish\")\n)\n\n# Sample port exit data\nport_exit_records <- data.frame(\n  exit_id = 1:6,\n  port = c(\"PortA\", \"PortB\", \"PortA\", \"PortA\", \"PortB\", \"PortA\"),\n  exit_date = as.Date(c(\"2023-01-16\", \"2023-01-17\", \"2023-01-18\", \"2023-02-16\", \"2023-02-17\", \"2023-02-18\")),\n  cargo_type = c(\"Fish\", \"Shrimp\", \"Fish\", \"Crab\", \"Lobster\", \"Fish\"),\n  quantity = c(100, 200, 150, 180, 220, 160)\n)\n\n# Merging data based on port and date\ncombined_data <- port_exit_records %>%\n  left_join(vessel_records, by = c(\"port\", \"cargo_type\"), suffix = c(\".exit\", \".offload\")) %>%\n  filter(exit_date >= offload_date & exit_date <= offload_date + days(1))\n\nprint(combined_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  exit_id  port  exit_date cargo_type quantity vessel_id offload_date\n1       1 PortA 2023-01-16       Fish      100         1   2023-01-15\n2       2 PortB 2023-01-17     Shrimp      200         2   2023-01-16\n3       3 PortA 2023-01-18       Fish      150         3   2023-01-17\n4       4 PortA 2023-02-16       Crab      180         1   2023-02-15\n5       5 PortB 2023-02-17    Lobster      220         2   2023-02-16\n6       6 PortA 2023-02-18       Fish      160         3   2023-02-17\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Plotting the cargo flow through ports\ncargo_flow_plot <- ggplot(combined_data, aes(x = exit_date, y = quantity, color = cargo_type)) +\n  geom_line() +\n  facet_wrap(~ port) +\n  labs(title = \"Cargo Flow Through Ports\", x = \"Date\", y = \"Quantity\") +\n  theme_minimal()\n\nprint(cargo_flow_plot)\n```\n\n::: {.cell-output-display}\n![](takehomeex3_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Plotting seasonal trends\nseasonal_trends_plot <- combined_data %>%\n  mutate(month = month(exit_date, label = TRUE)) %>%\n  group_by(month, cargo_type) %>%\n  summarise(total_quantity = sum(quantity)) %>%\n  ggplot(aes(x = month, y = total_quantity, fill = cargo_type)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Seasonal Trends in Cargo Types\", x = \"Month\", y = \"Total Quantity\") +\n  theme_minimal()\n\nprint(seasonal_trends_plot)\n```\n\n::: {.cell-output-display}\n![](takehomeex3_files/figure-html/unnamed-chunk-20-2.png){width=672}\n:::\n:::\n",
    "supporting": [
      "takehomeex3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}