[
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html",
    "href": "TakehomeEx/ex03/takehomeex3.html",
    "title": "Take Home Ex 3",
    "section": "",
    "text": "In Oceanus, island life is defined by the coming and going of seafaring vessels, many of which are operated by commercial fishing companies. Typically, the movement of ships and goods are a sign of Oceanus’s healthy economy, especially in the fishing business. But mundane routines can be disrupted by a major event. Analysts at FishEye International, a non-profit organization that aims to find and prevent illegal fishing, need your help to better understand one such event.\nFishEye has learned that SouthSeafood Express Corp has been caught fishing illegally. The scandal caused a major disruption in the close-knit fishing community. FishEye has been collecting data on ship movements and shipping records in hopes that they could assemble a cohesive store of knowledge that will allow them to better understand local commercial fishing behavior. FishEye processed open-source and commercial vessel tracking and shipping records into CatchNet: the Oceanus Knowledge Graph. Analysts examine and correct data as it is loaded but need your help to create analytical capabilities for this data.\nFishEye analysts need your help to perform geographic and temporal analysis of the CatchNet data so they can prevent illegal fishing from happening again. Your task is to develop new visual analytics tools and workflows that can be used to discover and understand signatures of different types of behavior. Can you use your tool to visualize a signature of SouthSeafood Express Corp’s illegal behavior? FishEye needs your help to develop a workflow to find other instances of illegal behavior.\n\nFishEye analysts have long wanted to better understand the flow of commercially caught fish through Oceanus’s many ports. But as they were loading data into CatchNet, they discovered they had purchased the wrong port records. They wanted to get the ship off-load records, but they instead got the port-exit records (essentially trucks/trains leaving the port area). Port exit records do not include which vessel that delivered the products. Given this limitation, develop a visualization system to associate vessels with their probable cargos. Which vessels deliver which products and when? What are the seasonal trends and anomalies in the port exit records?\nDevelop visualizations that illustrate the inappropriate behavior of SouthSeafood Express Corp vessels. How do their movement and catch contents compare to other fishing vessels? When and where did SouthSeafood Express Corp vessels perform their illegal fishing? How many different types of suspicious behaviors are observed? Use visual evidence to justify your conclusions.\nTo support further Fisheye investigations, develop visual analytics workflows that allow you to discover other vessels engaging in behaviors similar to SouthSeafood Express Corp’s illegal activities? Provide visual evidence of the similarities.\nHow did fishing activity change after SouthSeafood Express Corp was caught? What new behaviors in the Oceanus commercial fishing community are most suspicious and why?\n\n\n\n\n\n\n\nNote\n\n\n\nFor this Take-home Ex 3 - I will be focusing on Qn 1 and 2 first. If time is available, I will also attempt to go in to Qn 3.\nTo note that we will subsequently package these as part of our project.\n\n\n\n\nBecause the data are given in a json file format - we will have to load it using jsonlite. The following are the packages that we will be using for this ex.\n\n\nCode\npacman::p_load(jsonlite, tidygraph, igraph, ggraph, visNetwork, graphlayouts, ggforce, skimr, tidytext, tidyverse, plotly, shiny, DT, sf)\n\n\n\n\n\n\n\n\n\n\n\nThe following is the graph data provided:\n\nDirected multi-graph, allowing multiple edges between nodes\n5637 nodes\n271752 edges\n1 (weakly) connected component\n\nWhich covers:\n\nVessel Movements: Oceanus is outfitted with a transponder/ping system named the Oceanus Vessel Locator System (OVLS).  Vessels are outfitted with a transponder and periodic ‘pings’ from base-stations results in a report of vessel locations at any time.  The raw ping granularity is at the minute-level but post-processing has converted it into visit/dwell times. OVLS is generally reliable, though vessel records may be missing for a variety of reasons.\n\nNode/Edge types and properties present\n\nEntity.Vessel: Description of the vessel\nEntity.Location: Description of a geographic location\nEvent.TransponderPing: Links a vessel to a location\n\n\nHarbor Reports: Harbor masters regularly report the vessels found in their purview anytime during the day.  This data is derived from a different system than OVLS (see “Vessel Movements”), though the data overlaps.  Harbor Reports are provided on a different schedule from different harbors. Since no harbor reports every day, this data has lower temporal granularity than vessel movement data. Additionally, the Harbor Master is also responsible for proximate navigational beacon(s), so this data has lower spatial granularity as well.  However, the list of vessels observed is considered canonical.\n\nNode/edge types present:\n\nEntity.Vessel\nEntity.location\nEvent.HarborReport\n\n\nHarbor Import Records: Vessels deliver cargo to the ports, and that cargo is brought into Oceanus.  These records reflect the goods that *leave* the harbor to go to businesses in Oceanus or to be exported.  It was filtered pre-ingest to focus on the delivery of raw fish.  Because it is raw, fish leave the port quickly (generally one day after delivery).  Due to clerical error, the records purchased by FishEye do not include the vessel that delivered the cargo.\n\nNode/Edge types present:\n\nEntity.location\nEntity.Commodity.Fish\nEntity.Document.DeliveryReport\nEvent.Transaction\n\n\n\n\n\n\n\nWe will use jsonlite to import the data:\n\n\nCode\nmc2_data &lt;- fromJSON (\"data/mc2.json\")\n\n\nImporting the nodes and edges as tibble data\n\n\nCode\nmc2_edges &lt;-\n  as_tibble(mc2_data$links) %&gt;%\n  distinct()\n\n\n\n\nCode\nmc2_nodes &lt;-\n  as_tibble(mc2_data$nodes) %&gt;%\n  distinct()"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#loading-packages",
    "href": "TakehomeEx/ex03/takehomeex3.html#loading-packages",
    "title": "Take Home Ex 3",
    "section": "",
    "text": "Because the data are given in a json file format - we will have to load it using jsonlite. The following are the packages that we will be using for this ex.\n\n\nCode\npacman::p_load(jsonlite, tidygraph, igraph, ggraph, visNetwork, graphlayouts, ggforce, skimr, tidytext, tidyverse, plotly, shiny, DT, sf)"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#data-provided-by-the-challenge",
    "href": "TakehomeEx/ex03/takehomeex3.html#data-provided-by-the-challenge",
    "title": "Take Home Ex 3",
    "section": "",
    "text": "The following is the graph data provided:\n\nDirected multi-graph, allowing multiple edges between nodes\n5637 nodes\n271752 edges\n1 (weakly) connected component\n\nWhich covers:\n\nVessel Movements: Oceanus is outfitted with a transponder/ping system named the Oceanus Vessel Locator System (OVLS).  Vessels are outfitted with a transponder and periodic ‘pings’ from base-stations results in a report of vessel locations at any time.  The raw ping granularity is at the minute-level but post-processing has converted it into visit/dwell times. OVLS is generally reliable, though vessel records may be missing for a variety of reasons.\n\nNode/Edge types and properties present\n\nEntity.Vessel: Description of the vessel\nEntity.Location: Description of a geographic location\nEvent.TransponderPing: Links a vessel to a location\n\n\nHarbor Reports: Harbor masters regularly report the vessels found in their purview anytime during the day.  This data is derived from a different system than OVLS (see “Vessel Movements”), though the data overlaps.  Harbor Reports are provided on a different schedule from different harbors. Since no harbor reports every day, this data has lower temporal granularity than vessel movement data. Additionally, the Harbor Master is also responsible for proximate navigational beacon(s), so this data has lower spatial granularity as well.  However, the list of vessels observed is considered canonical.\n\nNode/edge types present:\n\nEntity.Vessel\nEntity.location\nEvent.HarborReport\n\n\nHarbor Import Records: Vessels deliver cargo to the ports, and that cargo is brought into Oceanus.  These records reflect the goods that *leave* the harbor to go to businesses in Oceanus or to be exported.  It was filtered pre-ingest to focus on the delivery of raw fish.  Because it is raw, fish leave the port quickly (generally one day after delivery).  Due to clerical error, the records purchased by FishEye do not include the vessel that delivered the cargo.\n\nNode/Edge types present:\n\nEntity.location\nEntity.Commodity.Fish\nEntity.Document.DeliveryReport\nEvent.Transaction"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#importing-the-data",
    "href": "TakehomeEx/ex03/takehomeex3.html#importing-the-data",
    "title": "Take Home Ex 3",
    "section": "",
    "text": "We will use jsonlite to import the data:\n\n\nCode\nmc2_data &lt;- fromJSON (\"data/mc2.json\")\n\n\nImporting the nodes and edges as tibble data\n\n\nCode\nmc2_edges &lt;-\n  as_tibble(mc2_data$links) %&gt;%\n  distinct()\n\n\n\n\nCode\nmc2_nodes &lt;-\n  as_tibble(mc2_data$nodes) %&gt;%\n  distinct()"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#looking-at-the-nodes",
    "href": "TakehomeEx/ex03/takehomeex3.html#looking-at-the-nodes",
    "title": "Take Home Ex 3",
    "section": "2.1 Looking at the Nodes",
    "text": "2.1 Looking at the Nodes\nWe first look at the types of nodes and how many of each are present in the data set:\n\n\nCode\ntype_counts_nodes &lt;- mc2_nodes %&gt;% count(type)\n\nprint(type_counts_nodes)\n\n\nOf note we have:\n\n5307 Delivery Reports\n178 Fishing Vessel and 100 Cargo Vessels\n10 Types of Fish\n\n\n2.1.1 Tidying the Text\nFrom the table above, beside the date data type and inappropriate field name issues we discussed earlier, two additional data issues can be observed. They are:\n\nThe values in Activities and fish_species_present fields are in list data type, which will affect the ability to process and to analyse the data.\nAs shown in the screenshot below, some values in the Activities field are not ready to be analyse without further tidying (i.e. removing c(““)).\n\nIn the code chunk below, mutate() of dplyr and gsub() of Base R are used to perform the data todying task.\n\n\nCode\nmc2_nodes_tidied &lt;- mc2_nodes %&gt;%\n  mutate(Activities = gsub(\"c[(]\", \"\", Activities)) %&gt;% \n  mutate(Activities = gsub(\"\\\"\", \"\", Activities)) %&gt;%\n  mutate(Activities = gsub(\"[)]\", \"\", Activities)) \n\n\n\n\nCode\nmc2_nodes_tidied &lt;- mc2_nodes_tidied %&gt;%\n  mutate(fish_species_present = gsub(\"c[(]\", \"\", fish_species_present)) %&gt;% \n  mutate(fish_species_present = gsub(\"\\\"\", \"\", fish_species_present)) %&gt;%\n  mutate(fish_species_present = gsub(\"[)]\", \"\", fish_species_present)) \n\n\n\n\nCode\nwrite_rds(mc2_nodes_tidied, \"data/rds/mc2_nodes_tidied.rds\")"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#looking-at-the-edges",
    "href": "TakehomeEx/ex03/takehomeex3.html#looking-at-the-edges",
    "title": "Take Home Ex 3",
    "section": "2.2 Looking at the Edges",
    "text": "2.2 Looking at the Edges\n\n\nCode\ntype_counts_edges &lt;- mc2_edges %&gt;% count(type)\n\nprint(type_counts_edges)\n\n\n\n2.2.1 Correcting date data type\nThe date format is not easily readable - so we need to convert them into something useful.\n\n\nCode\nmc2_edges$time &lt;- as_datetime(mc2_edges$time)\nmc2_edges$\"_last_edited_date\" &lt;- as_datetime(mc2_edges$\"_last_edited_date\")\nmc2_edges$\"_date_added\" &lt;- as_datetime(mc2_edges$\"_date_added\")\nmc2_edges$\"date\" &lt;- as_datetime(\"mc2_edges$date\")\n\n\n\n\nCode\nglimpse(mc2_edges)\n\n\n\n\n2.2.2 Changing the field names\n\n\nCode\nmc2_edges &lt;- mc2_edges %&gt;%\n  rename(\"last_edited_by\" = \"_last_edited_by\",\n         \"date_added\" = \"_date_added\",\n         \"last_edited_date\" = \"_last_edited_date\",\n         \"raw_source\" = \"_raw_source\",\n         \"algo\" = \"_algorithm\") \n\n\n\n\n2.2.3 Splitting the Text under Type\n\n\nCode\nword_list &lt;- strsplit(mc2_edges$type, \"\\\\.\")\nmax_elements &lt;- max(lengths(word_list))\nword_list_padded &lt;- lapply(word_list, \nfunction(x) c(x, rep(NA, max_elements - length(x))))\nword_df &lt;- do.call(rbind, word_list_padded)\ncolnames(word_df) &lt;- paste0(\"event\", 1:max_elements)\n\n\n\n\nCode\nword_df &lt;- as_tibble(word_df) %&gt;%\n  select(event2, event3)\nclass(word_df)\n\n\n\n\nCode\nmc2_edges &lt;- mc2_edges %&gt;%\n  cbind(word_df)\n\n\n\n\nCode\nwrite_rds(mc2_edges, \"data/rds/mc2_edges.rds\")"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#nodes-data",
    "href": "TakehomeEx/ex03/takehomeex3.html#nodes-data",
    "title": "Take Home Ex 3",
    "section": "3.1 Nodes Data",
    "text": "3.1 Nodes Data\nFrom the nodes data, we have the following information:\n\n\nCode\ntype_counts &lt;- mc2_nodes %&gt;%\n  group_by(type) %&gt;%\n  summarise(count = n())\n\n# Display the result\nprint(type_counts)\n\n\n# A tibble: 12 × 2\n   type                           count\n   &lt;chr&gt;                          &lt;int&gt;\n 1 Entity.Commodity.Fish             10\n 2 Entity.Document.DeliveryReport  5307\n 3 Entity.Location.City               6\n 4 Entity.Location.Point             12\n 5 Entity.Location.Region             6\n 6 Entity.Vessel.CargoVessel        100\n 7 Entity.Vessel.Ferry.Cargo          2\n 8 Entity.Vessel.Ferry.Passenger      3\n 9 Entity.Vessel.FishingVessel      178\n10 Entity.Vessel.Other                5\n11 Entity.Vessel.Research             2\n12 Entity.Vessel.Tour                 6\n\n\n\n\n\n\n\n\n\n\nData\nDescription\nRemarks\n\n\n\n\nFish\n10 Species of Fish\nKey fields are the:\nname and id\n\n\nLocation\nContains Point, City and Region\nContains the Name and id of the location - key field is the id\nfish_species_present is only listed for the region. Only 3 region for commercial fishing - Cod Table, Tuna Shelf and Wrasse Beds.\n\n\nDelivery Report\n5307 Delivery Report\nContains the id tied to the cargo id.\nAlso contains the qty by tons (qty_tons) and the date of the delivery (date).\n\n\nFishing Vessel\n178 Fishing Vessel\nContains the Name and id of the vessel. We can use id to identify the vessels.\nOther info includes: flag_country, company, tonnage, length_overall,\n\n\nCargo Vessel\n100 Cargo Vessels\nTo explore given that these vessels can be used for transshipment or IUU activities.\n\n\nOther Vessels\nSuch as Passenger, Research, Tour and Others\nKIV - but dont think needed for our analysis\n\n\n\nWe noticed that there are two columns for the name - one with name and the other with Name. Let us try to combine them into one column for easier analysis:\n\n\nCode\noverlaps &lt;- mc2_nodes %&gt;%\n  filter(!is.na(Name) & !is.na(name) & tolower(Name) == tolower(name))\n\n# Print overlaps\nprint(\"Overlaps between 'Name' and 'name' columns:\")\n\n\n[1] \"Overlaps between 'Name' and 'name' columns:\"\n\n\nCode\nprint(overlaps)\n\n\n# A tibble: 0 × 20\n# ℹ 20 variables: type &lt;chr&gt;, _last_edited_by &lt;chr&gt;, _date_added &lt;chr&gt;,\n#   _last_edited_date &lt;chr&gt;, _raw_source &lt;chr&gt;, _algorithm &lt;chr&gt;, name &lt;chr&gt;,\n#   id &lt;chr&gt;, Name &lt;chr&gt;, Description &lt;chr&gt;, Activities &lt;chr&gt;, kind &lt;chr&gt;,\n#   qty_tons &lt;dbl&gt;, date &lt;chr&gt;, flag_country &lt;chr&gt;, company &lt;chr&gt;,\n#   tonnage &lt;int&gt;, length_overall &lt;int&gt;, style &lt;chr&gt;,\n#   fish_species_present &lt;chr&gt;\n\n\nCode\n# Combine columns into one named 'name'\nmc2_nodes &lt;- mc2_nodes %&gt;%\n  mutate(name = ifelse(is.na(name), Name, name)) %&gt;%\n  select(-Name)"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#splitting-the-text-under-type-1",
    "href": "TakehomeEx/ex03/takehomeex3.html#splitting-the-text-under-type-1",
    "title": "Take Home Ex 3",
    "section": "3.2 Splitting the text under type",
    "text": "3.2 Splitting the text under type\nLike how we split the text for edges, we will do so for the nodes data.\n\n\nCode\nword_list &lt;- strsplit(mc2_nodes$type, \"\\\\.\")\nmax_elements &lt;- max(lengths(word_list))\n\nword_list_padded &lt;- lapply(word_list, \nfunction(x) c(x, rep(NA, max_elements - length(x))))\nword_df &lt;- do.call(rbind, word_list_padded)\ncolnames(word_df) &lt;- paste0(\"entity\", 1:max_elements)\n\n\n\n\nCode\nword_df &lt;- as_tibble(word_df) %&gt;%\n  select(entity2, entity3)\n\n\n\n\nCode\nmc2_nodes &lt;- mc2_nodes %&gt;%\n  cbind(word_df)"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#filter-out-the-species-in-region",
    "href": "TakehomeEx/ex03/takehomeex3.html#filter-out-the-species-in-region",
    "title": "Take Home Ex 3",
    "section": "3.3 Filter out the Species in Region",
    "text": "3.3 Filter out the Species in Region\n\n\nCode\nfish_species_df &lt;- mc2_nodes %&gt;%\n  filter(entity3 == 'Region') %&gt;%\n  select(name, fish_species_present)\n\n\n\n\nCode\n# Convert the fish_species_present column into a long format data frame for plotting\nlong_fish_species_df &lt;- fish_species_df %&gt;%\n  separate_rows(fish_species_present, sep = \",\") %&gt;%\n  mutate(fish_species_present = str_trim(fish_species_present)) %&gt;%\n  rename(region = name, fish_species = fish_species_present)\n\nreserve_only_species &lt;- c('Sockfish/Pisces foetida', 'Offidiaa/Piscis osseus', 'Helenaa/Pisces satis')  # Example reserve-only species\n\n# Add a column to indicate if a fish species is reserve-only\nlong_fish_species_df &lt;- long_fish_species_df %&gt;%\n  mutate(reserve_only = ifelse(fish_species %in% reserve_only_species, TRUE, FALSE)) %&gt;%\n  mutate(fishtype = sub(\"/.*\", \"\", fish_species))\n\n\n\n\nCode\nggplot(long_fish_species_df, aes(x = region, y = fishtype, color = fishtype, size = reserve_only)) +\n  geom_point() +\n  scale_size_manual(values = c(`FALSE` = 2, `TRUE` = 4), guide = FALSE) +\n  labs(title = \"Fish Species Present in Different Regions\", \n       subtitle = \"Salmon is not found in the Regions\",\n       x = \"Region\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 30, hjust = 1),\n        legend.position = \"none\",\n        axis.title.y = element_blank())"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#edges-data",
    "href": "TakehomeEx/ex03/takehomeex3.html#edges-data",
    "title": "Take Home Ex 3",
    "section": "3.4 Edges Data",
    "text": "3.4 Edges Data\n\n\nCode\ntype_counts &lt;- mc2_edges %&gt;%\n  group_by(type) %&gt;%\n  summarise(count = n())\n\n# Display the result\nprint(type_counts)\n\n\n# A tibble: 3 × 2\n  type                                  count\n  &lt;chr&gt;                                 &lt;int&gt;\n1 Event.HarborReport                     2487\n2 Event.Transaction                     10614\n3 Event.TransportEvent.TransponderPing 258542\n\n\nWe have 3 groups of data in the edges mainly the HarborReport, Transaction and the TransponderPing.\n\n\n\n\n\n\n\n\nData\nDescription\nRemarks\n\n\n\n\nHarbor Reports\nContains information about the vessel docking at which harbor.\nThere is a key column, but not sure what it means.\nContains a few other columns with aphorism, holiday greeting etc but seems not impt for our analysis here.\nKey fields here are:\nsource which is tied to the id of a vessel.\ntarget which is tied to the name of the city.\ndate_added and last_edited_date are the two key dates available\n\n\nTransaction\nInformation from OCEANS\nEach transaction has two rows - one connecting the transaction to the City, the other to the fish species.\nKey fields here are:\nsource which is tied to the id of a cargo.\ntarget which is tied to the name of the city and the id of the fish.\ndate_added and last_edited_date are the two key dates available\n\n\nTransponder Ping\nInformation from OVLS\nContains information about the time of ping, dwell time, and location.\nKey fields here are:\nsource which is tied to the nameof a location.\ntarget which is tied to the id of the vessel.\ntime, date_addedand last_edited_date are the three dates available - should be focusing on time here."
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#visualising-the-harbor-records",
    "href": "TakehomeEx/ex03/takehomeex3.html#visualising-the-harbor-records",
    "title": "Take Home Ex 3",
    "section": "4.1 Visualising the Harbor Records",
    "text": "4.1 Visualising the Harbor Records\n\n\nCode\nvessel_list &lt;- mc2_nodes %&gt;%\n  filter(type %in% c(\"Entity.Vessel.FishingVessel\", \"Entity.Vessel.CargoVessel\")) %&gt;%\n  mutate(type = case_when(\n    type == \"Entity.Vessel.FishingVessel\" ~ \"FishingVessel\",\n    type == \"Entity.Vessel.CargoVessel\" ~ \"CargoVessel\"\n  )) %&gt;%\n  select(type, name, id, flag_country, tonnage, length_overall, company) %&gt;%\n  rename(vessel = id)\n\n\n\n\nCode\nharbor_records &lt;- mc2_edges %&gt;%\n  filter(type == \"Event.HarborReport\") %&gt;%\n  select(date_added, last_edited_date, source, target) %&gt;%\n  rename(\"vessel\" = \"source\",\n         \"port\" = \"target\") \n\n\n\n\nCode\nharbor_records &lt;- harbor_records %&gt;%\n  left_join(vessel_list, by = \"vessel\") %&gt;%\n  filter(!is.na(name) & name != \"\")\n\n\n\n\nCode\nvisit_counts &lt;- harbor_records %&gt;%\n  mutate(month = month(date_added, label = TRUE)) %&gt;%\n  group_by(port, vessel, type, month) %&gt;%\n  summarise(visit_count = n(), \n            visit_dates = paste(date_added, collapse = ', ')) %&gt;%\n  ungroup()\n\nvisits_fishing &lt;- visit_counts %&gt;%\n  filter(type == \"FishingVessel\")\n\nvisits_fishing &lt;- visits_fishing %&gt;%\n  complete(month, port, fill = list(visit_count = NA))\n\nvisits_cargo &lt;- visit_counts %&gt;%\n  filter(type == \"CargoVessel\")\n\nvisits_cargo &lt;- visits_cargo %&gt;%\n  complete(month, port, fill = list(visit_count = NA))\n\n\n\nCode\nggplot(visits_fishing, aes(x = month, y = port, fill = visit_count)) +\n  geom_tile(color = \"black\") +\n  scale_fill_gradient(low = \"azure1\", high = \"deepskyblue4\", na.value = \"white\") +\n  labs(title = \"Paackland and Haacklee more frequented by Fishing Vessels\",\n       x = \"Month\",\n       y = \"Port\",\n       subtitle = \"Based on the Harbor Records\",\n       fill = \"Number of Visits\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nggplot(visits_cargo, aes(x = month, y = port, fill = visit_count)) +\n  geom_tile(color = \"black\") +\n  scale_fill_gradient(low = \"azure1\", high = \"deepskyblue4\", na.value = \"white\") +\n  labs(title = \"Paackland and Lomark more frequented by Cargo Vessels\",\n       x = \"Month\",\n       y = \"Port\",\n       subtitle = \"Based on the Harbor Records\",\n       fill = \"Number of Visits\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Port Visits by Fishing Vessels\n\n\n\n\n\n\n\n\n\n\n\n(b) Port Visits by Cargo Vessels\n\n\n\n\n\n\n\nFigure 1: Both Fishing and Cargo Vessels frequent Paackland"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#wrangling-the-transponder-data",
    "href": "TakehomeEx/ex03/takehomeex3.html#wrangling-the-transponder-data",
    "title": "Take Home Ex 3",
    "section": "4.2 Wrangling the Transponder Data",
    "text": "4.2 Wrangling the Transponder Data\n\n\nCode\ntransponder &lt;- mc2_edges %&gt;%\n  filter(type == \"Event.TransportEvent.TransponderPing\") %&gt;%\n  select(time, dwell, source, target) %&gt;%\n  rename(\"id\" = \"target\")\n\n\n\n\nCode\n# Selecting only the 'id' and 'vessel' columns from vessel_list\nvessel_subset &lt;- vessel_list %&gt;% \n  select(vessel, name, type) %&gt;%\n  rename (id = vessel)\n\n# Performing left join on transponder and vessel_subset\ntransponder &lt;- left_join(transponder, vessel_subset, by = \"id\")\n\n# Filtering only those Cargo and Fishing Vessels\n\ntransponder &lt;- transponder %&gt;%\n  filter(!is.na(type))\n\n\n\n4.2.1 Visualising the Transponder Data\nFor us to better visualise the transponder data, we will split the data by months and also group it by the days of the week.\n\n\nCode\ntransponder &lt;- transponder %&gt;%\n  mutate(month = month(time),\n         day = wday(time, label = TRUE))\n\n\nWe want to also indicate if the vessel was within a port or not.\n\n\nCode\ntransponder &lt;- transponder %&gt;%\n  mutate(area = \n          ifelse (grepl(\"^City of\", source), \"Ports\", \n          ifelse(source %in% c(\"Cod Table\", \"Tuna Shelf\", \"Wrasse Beds\"), \"Fishing Grounds\",\n        ifelse(grepl(\"^Nav\", source), \"Nav Areas\",\n        ifelse(source %in% c(\"Don Limpet Preserve\", \"Nemo Reef\", \"Ghoti Preserve\"), \"Reserves\",\n        ifelse(grepl(\"^Exit\", source), \"Exit Areas\",\n                              \"Unknown\")))))) %&gt;%\n  rename(\"location\" = \"source\",\n         \"vessel\" = \"name\")\n\n\n\n\nCode\ntransponder &lt;- transponder %&gt;%\n  arrange(vessel, time) %&gt;%\n  group_by(vessel, location) %&gt;%\n  mutate(\n    stay_start = time,\n    stay_end = time + dwell,\n    stay_duration = as.numeric(difftime(stay_end, stay_start, units = \"mins\"))\n  )\n\n# Filter out rows where location is NA or stay_duration is NA or negative\ntransponder &lt;- transponder %&gt;%\n  filter(!is.na(location) & !is.na(stay_duration) & stay_duration &gt;= 0)\n\n\n\n\n4.2.2 Looking at the areas that the vessels visited\n\n\nCode\n# Plotting\nggplot(transponder, aes(x = area, fill = type)) +\n  geom_bar(position = \"dodge\", stat = \"count\") +\n  labs(title = \"Cargo Vessels should not linger in Fishing Grounds or Reserves\",\n       x = \"Location Type\",\n       y = \"Count\",\n       fill = \"Vessel Type\",\n       subtitle = \"Fishing Vessels were present in Reserves as well\") +\n  scale_fill_manual(values = c(\"azure4\", \"lightskyblue4\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n4.2.3 Vessels within Reserve Areas\n\n\nCode\nreserves_data &lt;- transponder %&gt;%\n  filter(area == \"Reserves\")\n\n# Count the number of unique vessels in the reserves area by vessel type\nunique_vessels_count &lt;- reserves_data %&gt;%\n  group_by(type) %&gt;%\n  summarize(unique_vessels = n_distinct(vessel))\n\nmean_value &lt;- mean(reserves_data$stay_duration)\nmedian_value &lt;- median(reserves_data$stay_duration)\n\n# Plot a box plot of the dwell time in the reserves area\nboxplot &lt;- ggplot(reserves_data, aes(x = type, y = stay_duration, fill = type)) +\n  geom_boxplot(fill = \"azure3\", color = \"lightskyblue4\", outlier.shape = 16, outlier.size = 2, outlier.colour = \"deepskyblue4\") +\n  geom_hline(yintercept = mean_value, color = \"azure4\", linetype = \"dashed\", size = 1) +  # Add mean line\n  geom_hline(yintercept = median_value, color = \"lightblue\", linetype = \"dotted\", size = 1) + \n  labs(title = \"Many Instances of Fishing Vessel Overspending Time in Reserves\",\n       x = NULL,\n       y = \"Stay Duration (mins) - Log Scale\",\n       subtitle = \"71 Cargo Vessels and 131 Fishing Vessels spent time in Reserves\") +\n  scale_y_log10() + \n  theme_minimal()\n\n# Print the number of unique vessels in the reserves area\nprint(unique_vessels_count)\n\n\n# A tibble: 2 × 2\n  type          unique_vessels\n  &lt;chr&gt;                  &lt;int&gt;\n1 CargoVessel               71\n2 FishingVessel            131\n\n\nCode\n# Display the box plot\nprint(boxplot)\n\n\n\n\n\n\n\n\n\n\n\n4.2.4 Cargo Vessels within Fishing Grounds\n\n\nCode\n# Filter the data for cargo vessels in fishing grounds\ncargo_fishing_data &lt;- transponder %&gt;%\n  filter(type == \"CargoVessel\" & area == \"Fishing Grounds\")\n\n# Calculate mean and median values\nmean_value &lt;- mean(cargo_fishing_data$stay_duration)\nmedian_value &lt;- median(cargo_fishing_data$stay_duration)\n\n# Plot a box plot of the dwell time for cargo vessels in fishing grounds\nggplot(cargo_fishing_data, aes(x = \"\", y = stay_duration)) +\n  geom_boxplot(fill = \"azure3\", color = \"lightskyblue4\") +\n  geom_hline(yintercept = mean_value, color = \"azure4\", linetype = \"dashed\", size = 1) +  # Add mean line\n  geom_hline(yintercept = median_value, color = \"lightblue\", linetype = \"dotted\", size = 1) +  \n  scale_y_log10() +\n  labs(title = \"Cargo Vessels spending more time in Fishing Grounds\",\n       x = NULL,\n       y = \"Stay Duration (min) (log scale)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\nvessels_above_mean &lt;- cargo_fishing_data %&gt;%\n  filter(stay_duration &gt; mean_value)\n\n# Count the number of unique vessels\nnum_vessels_above_mean &lt;- n_distinct(vessels_above_mean$vessel)\n\n# Print the count\nprint(num_vessels_above_mean)\n\n\n[1] 1\n\n\nNotice that there is only 1 Cargo Vessel which stays in the fishing grounds above the mean duration - Nautical Nomad (Tuna Shelf and Wrasse Beds).\nWhy is this out of the norm? Typical cargo vessels could have only just transited across the fishing grounds, but if the cargo vessel stays beyond the transit time, they could be involved in illegal fishing activities, e.g. transshipment at sea as shown in the photo below.\n\n\n\nCode\nggplot(transponder, aes(x = stay_duration)) +\n  geom_histogram(binwidth = 100, fill = \"azure4\", color = \"black\") +\n  xlim (0, 5000) +\n  labs(title = \"Stay Duration is typically about 100 mins\", x = \"Stay Duration (mins)\", y = \"Frequency\")+\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nWe will notice that there are vessels with dwell time = 0. This is so for the first row of data for each vessel, where it seems to initialise the starting of the location tracking of each vessel. However, there are also other times, where the dwell time was 0. Thinking that this could due to the vessel passing by the Port or could have traveled within the vicinity.\n\nCode\n# Summarize data to get the number of unique vessels in each reserve area\nvessels_reserve &lt;- reserves_data %&gt;%\n  group_by(location) %&gt;%\n  summarise(unique_vessel_count = n_distinct(vessel))\n\nreserves_data &lt;- reserves_data %&gt;%\n  mutate (stay_duration_min = stay_duration/60)\n\n# Bar chart showing the number of unique vessels in different reserve areas\nggplot(vessels_reserve, aes(x = location, y = unique_vessel_count)) +\n  geom_bar(stat = \"identity\", fill = \"azure4\") +\n  labs(title = \"Nemo Reef saw the most vessels entering the reserve\",\n       x = \"Reserve Area\",\n       y = \"Number of Unique Vessels\") +\n  geom_text(aes(label = unique_vessel_count), vjust = -0.5, size = 3.5) +\n  theme_minimal()\n\n# Boxplot of stay_duration in different reserve areas\nggplot(reserves_data, aes(x = location, y = stay_duration_min)) +\n  geom_boxplot(fill = \"lightskyblue3\") +\n  labs(title = \"But Ghoti Preserve saw longer stay duration\",\n       x = \"Reserve Area\",\n       y = \"Stay Duration (mins)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Number of Unique Vessels entering the Reserves\n\n\n\n\n\n\n\n\n\n\n\n(b) Stay Duration (mins) of the Vessels\n\n\n\n\n\n\n\nFigure 2: Vessels entering Reserves and their Stay Duration\n\n\n\n\n\n4.2.5 Vessels’ Stay Duration at the Ports\n\n\nCode\nport_data &lt;- transponder %&gt;%\n  filter(area == \"Ports\")\n\nmean_value &lt;- mean(port_data$stay_duration)\nmedian_value &lt;- median(port_data$stay_duration)\n\n# Plot a box plot of the dwell time in the reserves area\nboxplot &lt;- ggplot(port_data, aes(x = type, y = stay_duration, fill = type)) +\n  geom_boxplot(fill = \"azure3\", color = \"lightskyblue4\", outlier.shape = 16, outlier.size = 2, outlier.colour = \"deepskyblue4\") +\n  geom_hline(yintercept = mean_value, color = \"azure4\", linetype = \"dashed\", size = 1) +  # Add mean line\n  geom_hline(yintercept = median_value, color = \"lightblue\", linetype = \"dotted\", size = 1) + \n  labs(title = \"Cargo Vessels spend less time at ports as compared to Fishing Vessels\",\n       x = NULL,\n       y = \"Stay Duration (mins) - Log Scale\",\n       subtitle = \"Average Time: 1985mins ; Median Time: 1675mins\") +\n  scale_y_log10() + \n  theme_minimal()\n\n# Display the box plot\nprint(boxplot)"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#finding-out-the-catches-within-the-vessel",
    "href": "TakehomeEx/ex03/takehomeex3.html#finding-out-the-catches-within-the-vessel",
    "title": "Take Home Ex 3",
    "section": "4.3 Finding out the catches within the Vessel",
    "text": "4.3 Finding out the catches within the Vessel\n\n\nCode\nfishes &lt;- mc2_nodes %&gt;%\n  filter(type == \"Entity.Commodity.Fish\") %&gt;%\n  select(\"name\", \"id\") %&gt;%\n  rename(\"fishid\" = \"id\")\n\n\n\n\nCode\nregion &lt;- mc2_nodes %&gt;%\n  filter(type == \"Entity.Location.Region\")\n\n\n\n\nCode\nregion &lt;- region %&gt;%\n  separate_rows(fish_species_present, sep = \",\\\\s*\") \n\n\n\n\nCode\nregion &lt;- region %&gt;%\n  left_join(fishes, by = c(\"fish_species_present\" = \"name\"))\n\n\n\n\nCode\npossible_catches &lt;- region %&gt;%\n  group_by(name) %&gt;%\n  summarize(fishes = list(unique(fishid))) %&gt;%\n  rename (\"location\" = \"name\")\n\n\n\n\nCode\nmapped_data &lt;- transponder %&gt;%\n  left_join(possible_catches, by = \"location\") %&gt;%\n  arrange(id, time)\n\n\n\n\nCode\n# Identify port returns\nmapped_data$is_port_return &lt;- grepl(\"^City of\", mapped_data$location)\n\n\n\n\nCode\ncatch_summary &lt;- mapped_data %&gt;%\n  group_by(id, vessel, return_number = cumsum(is_port_return)) %&gt;%\n  summarise(\n    start_port = first(location),\n    start_leg = first(time),\n    last_point_b4_port = last(location),\n    time_before_port = last(time),\n    time_check = first(time + dwell),\n    possible_catches = list(unique(unlist(fishes)))\n  )\n\n\n\n\nCode\ncatch_summary &lt;- catch_summary %&gt;%\n  mutate(end_port = lead(start_port, order_by = id),\n         time_into_port = lead(start_leg, order_by = id),\n         time_exit_port = lead(time_check, order_by = id))\n\n\n\n\nCode\nall_catch_summary &lt;- catch_summary %&gt;%\n  unnest(possible_catches) %&gt;%\n  rename (\"fish\" = \"possible_catches\",\n          \"port\" = \"end_port\",\n          \"name\" = \"vessel\")\n\nall_catch_summary &lt;- all_catch_summary %&gt;%\n  left_join(vessel_list, by = \"name\")\n\nall_catch_summary &lt;- all_catch_summary %&gt;%\n  left_join(fishes, by = c(\"fish\" = \"fishid\"))\n\nall_catch_summary &lt;- all_catch_summary %&gt;%\n  mutate(fishtype = sub(\"/.*\", \"\", name.y))\n\nall_catch_summary &lt;- all_catch_summary %&gt;%\n  select (name.x, port, time_into_port, time_exit_port, type, flag_country, tonnage, company, fishtype) %&gt;%\n  rename (\"vessel\" = \"name.x\")\n\nall_catch_summary &lt;- all_catch_summary %&gt;%\n  mutate(month = month(time_into_port,label = TRUE))\n\ncatch_month_summary &lt;- all_catch_summary %&gt;%\n  group_by(month, fishtype) %&gt;%\n  summarise(vessel_count = n_distinct(vessel))\n\n\n\n\nCode\nggplot(catch_month_summary, aes(x = month, y = fishtype, size = vessel_count)) +\n  geom_point(color = \"lightskyblue4\", alpha = 0.8) +\n  scale_size_continuous(range = c(1, 10)) +  # Adjust the range of the dot sizes\n  labs(title = \"Possible Fish Types Caught by Month\",\n       x = \"Month\",\n       y = \"Fish Type\",\n       subtitle = \"Based on the transponder data and their duration in the region\",\n       size = \"Number of Vessels\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nHere, we attempt to match the catch summary with the harbor records, so that we exclude transponder pings that are not part of the harbor records.\n\n\nCode\nharbor_summary &lt;- catch_summary %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    harbor = ifelse(any(harbor_records$name == vessel &\n                        harbor_records$port == end_port &\n                        harbor_records$date_added &gt;= time_into_port),\n              \"Y\", \"N\")\n  ) %&gt;%\n  ungroup()\n\nharbor_summary &lt;- harbor_summary%&gt;%\n  filter(harbor == \"Y\")"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#wrangling-with-the-delivery-reports",
    "href": "TakehomeEx/ex03/takehomeex3.html#wrangling-with-the-delivery-reports",
    "title": "Take Home Ex 3",
    "section": "4.4 Wrangling with the Delivery Reports",
    "text": "4.4 Wrangling with the Delivery Reports\n\n\nCode\ndeliveryreports &lt;- mc2_nodes %&gt;%\n  filter(type == \"Entity.Document.DeliveryReport\")%&gt;%\n  select(id, qty_tons, date) \n\n\n\n\nCode\n# Plot histogram\nggplot(deliveryreports, aes(x = qty_tons)) +\n  geom_histogram(binwidth = 5, fill = \"azure4\", color = \"black\") +\n  labs(title = \"There are 5307 delivery reports and the qty ranges from 0 to ~80tons\",\n       x = \"Quantity in Tons\",\n       y = \"Frequency\",\n       subtitle = \"315 values are 0 and below (to remove these data)\") +\n  theme_minimal() +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"deepskyblue4\", size = 1)\n\n\n\n\n\n\n\n\n\n\n\nCode\ndelivery_reports_0andbelow &lt;- deliveryreports %&gt;%\n  filter (qty_tons &lt;= 0)\n\n\n\n\nCode\ndelivery_reports &lt;- deliveryreports %&gt;%\n  filter (qty_tons &gt; 0)\n\n\n\n\nCode\ndelivery_trans &lt;- mc2_edges %&gt;%\n  filter(type == \"Event.Transaction\") %&gt;%\n  select(source, target, date_added) %&gt;%\n  rename(\"id\" = \"source\") \n\n\n\n\nCode\ndelivery_trans$index &lt;- ifelse(seq(nrow(delivery_trans)) %% 2 == 0, \"port\", \"fish\")\n\ndelivery_trans1 &lt;- delivery_trans %&gt;%\n  pivot_wider(names_from = index, values_from = target) %&gt;%\n  rename (\"fishid\" = \"fish\")\n\n\n\n\nCode\ndelivery_reports &lt;- delivery_reports %&gt;%\n  left_join(delivery_trans1, by = \"id\")\n\n\n\n\nCode\ndelivery_reports &lt;- delivery_reports %&gt;%\n  left_join(fishes, by = \"fishid\")\n\n\n\n\nCode\ndelivery_reports &lt;- delivery_reports %&gt;%\n  mutate(fishtype = sub(\"/.*\", \"\", name))\n\n\n\n\nCode\ndelivery_reports &lt;- delivery_reports %&gt;%\n  select(-fishid, -name, -date_added)\n\n\n\n4.4.1 Deliveries by the Ports\n\n\nCode\ncustom_labels &lt;- c(\"City of Haacklee\" = \"Haacklee\", \n                   \"City of Himark\" = \"Himark\",\n                   \"City of Lomark\" = \"Lomark\",\n                   \"City of Paackland\" = \"Paackland\",\n                   \"City of South Paackland\" = \"S.Paackland\")\n\n\nggplot(delivery_reports, aes(x = port, y = qty_tons)) +\n  geom_boxplot(fill = \"azure4\", color = \"black\") +\n  labs(title = \"Similar Range in terms of Qty at the different Ports\",\n       x = \"Port\",\n       y = \"Quantity in Tons\") +\n  scale_x_discrete(labels = custom_labels) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n4.4.2 Fish Species not found in Fishing Grounds but Delivered at the Ports\n\n\nCode\n# Summarize the data to count the number of deliveries for each combination of port and fish type\ndelivery_summary &lt;- delivery_reports %&gt;%\n  group_by(port, fishtype) %&gt;%\n  summarize(num_deliveries = n())\n\nggplot(delivery_summary, aes(x = port, y = fishtype, color = fishtype, size = num_deliveries)) +\n  geom_point(alpha = 1) +  # Adjust alpha for transparency if needed\n  labs(title = \"Sockfish, Salmon, Offidiaa and Helenaa are found at the Ports\",\n       x = NULL,\n       y = NULL,\n       size = \"Number of Deliveries\") +\n  scale_x_discrete(labels = custom_labels) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 11, face = \"bold\"))  \n\n\n\n\n\n\n\n\n\nFrom the graph, we identified that Sockfish, Salmon, Offidiaa and Helenaa are found at the various ports. These are fishes that are not found in the fishing grounds, so identifying the vessels that offload these cargoes can help to narrow down IUU fishing.\n\n\n4.4.3 Monthly Delivery Trend by Fish Types\n\n\nCode\ndelivery_reports &lt;- delivery_reports %&gt;%\n  mutate (date = as.Date(date))\n\n# Extract month from the date\ndelivery_reports &lt;- delivery_reports %&gt;%\n  mutate(month = floor_date(date, \"month\"))\n\n# Summarize the data to count the number of deliveries for each combination of month and fish type\nmonthly_summary &lt;- delivery_reports %&gt;%\n  group_by(month, fishtype) %&gt;%\n  summarize(num_deliveries = n())\n\n# Calculate the mean deliveries per fish type\nmean_deliveries &lt;- monthly_summary %&gt;%\n  group_by(fishtype) %&gt;%\n  summarize(mean_deliveries = mean(num_deliveries))\n\n# Find the highest delivery per fish type\nmax_deliveries &lt;- monthly_summary %&gt;%\n  group_by(fishtype) %&gt;%\n  filter(num_deliveries == max(num_deliveries))\n\n# Merge the summary data to add the mean delivery to each row\nmonthly_summary &lt;- monthly_summary %&gt;%\n  left_join(mean_deliveries, by = \"fishtype\")\n\n# Plot the monthly delivery\nggplot(monthly_summary, aes(x = month, y = num_deliveries, color = fishtype)) +\n  geom_line(size = 1) +  # Line plot for monthly trend\n  geom_point(size = 2) +  # Add points for each month\n  labs(title = \"Cod has the highest number of deliveries\",\n       x = \"Month\",\n       y = \"Number of Deliveries\",\n       subtitle = \"The four illegal fish species are delivered in certain months only\",\n       color = \"Fish Type\") +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 11, face = \"bold\"),\n        legend.position = \"none\") +\n  geom_text(data = max_deliveries, aes(label = num_deliveries), size = 2, vjust = -1) + \n  scale_y_continuous(expand = expansion(mult = c(0, 0.2))) +\n  facet_wrap(~ fishtype)  \n\n\n\n\n\n\n\n\n\n\n\nCode\nfiltered_summary &lt;- delivery_reports %&gt;%\n  group_by(month, fishtype, port) %&gt;%\n  summarize(num_deliveries = n())\n\n\n\n\nCode\nfiltered_summary &lt;- filtered_summary %&gt;%\n  filter(fishtype %in% c(\"Sockfish\", \"Salmon\", \"Offidiaa\", \"Helenaa\"))\n\n# Calculate the total deliveries across all ports for each month\ntotal_deliveries &lt;- filtered_summary %&gt;%\n  group_by(month, fishtype) %&gt;%\n  summarise(num_deliveries = sum(num_deliveries)) %&gt;%\n  mutate(port = \"Total\")  \n\n# Combine the filtered summary data with the total deliveries\ncombined_summary &lt;- bind_rows(filtered_summary, total_deliveries)\n\n# Plot the monthly delivery\nggplot(combined_summary, aes(x = month, y = num_deliveries, color = fishtype)) +\n  geom_line(size = 1) +  # Line plot for monthly trend\n  geom_point(size = 2) +  # Add points for each month\n  labs(title = \"Paackland and Himark saw high delivery of the four fish species\",\n       x = \"Month\",\n       y = \"Number of Deliveries\",\n       subtitle = \"Salmon is mostly delivered through Haacklee and Paackland\",\n       color = \"Fish Type\") +\n  theme_minimal() +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b\", limits = as.Date(c(\"2035-02-01\", \"2035-11-31\"))) +\n  geom_text(data = combined_summary, aes(label = num_deliveries), size = 2, vjust = -1) + \n  theme(plot.title = element_text(size = 14, face = \"bold\"),\n        axis.text.x = element_text(size = 5)) +\n  facet_wrap(~ port)"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#merging-the-catch-summary-data-with-delivery-reports",
    "href": "TakehomeEx/ex03/takehomeex3.html#merging-the-catch-summary-data-with-delivery-reports",
    "title": "Take Home Ex 3",
    "section": "4.5 Merging the Catch Summary Data with Delivery Reports",
    "text": "4.5 Merging the Catch Summary Data with Delivery Reports\n\n\nCode\nexpanded_catch_summary &lt;- harbor_summary %&gt;%\n  unnest(possible_catches) %&gt;%\n  rename (\"fish\" = \"possible_catches\",\n          \"port\" = \"end_port\",\n          \"name\" = \"vessel\")\n\n\n\n\nCode\nexpanded_catch_summary &lt;- expanded_catch_summary %&gt;%\n  left_join(vessel_list, by = \"name\")\n\n\n\n\nCode\nexpanded_catch_summary &lt;- expanded_catch_summary %&gt;%\n  left_join(fishes, by = c(\"fish\" = \"fishid\"))\n\n\n\n\nCode\nexpanded_catch_summary &lt;- expanded_catch_summary %&gt;%\n  mutate(fishtype = sub(\"/.*\", \"\", name.y))\n\n\nClean up the summary.\n\n\nCode\nfinal_catch_summary &lt;- expanded_catch_summary %&gt;%\n  select (name.x, port, time_into_port, time_exit_port, type, flag_country, tonnage, company, fishtype) %&gt;%\n  rename (\"vessel\" = \"name.x\")\n\n\n\n\nCode\nmatched_data &lt;- final_catch_summary %&gt;%\n  left_join(delivery_reports, by = c(\"port\", \"fishtype\")) %&gt;%\n  filter(date &gt;= time_into_port + 0.5 &\n         date &lt;= time_exit_port + 1) %&gt;%\n  mutate(cargo = ifelse(!is.na(id), as.character(id), \"N\"))\n\n\n\n\nCode\nsummary_cargo &lt;- matched_data %&gt;%\n  group_by(id) %&gt;%\n  summarise(count = n())\n\nsummary_cargo_unique &lt;- summary_cargo %&gt;%\n  filter(count==1)"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#match-with-harbor-records-instead",
    "href": "TakehomeEx/ex03/takehomeex3.html#match-with-harbor-records-instead",
    "title": "Take Home Ex 3",
    "section": "5.1 Match with Harbor Records Instead",
    "text": "5.1 Match with Harbor Records Instead\n\n\nCode\nmatched_data_harbor &lt;- harbor_records %&gt;%\n  left_join(delivery_reports, by = c(\"port\")) %&gt;%\n  filter(date &gt;= date_added  &\n           date &lt;= date_added + 1)\n\n\n\n\nCode\nsummary_cargo &lt;- matched_data_harbor %&gt;%\n  group_by(id) %&gt;%\n  summarise(count = n())\n\nsummary_cargo_unique &lt;- summary_cargo %&gt;%\n  filter(count==1)\n\n\n\n\nCode\n# Summarize the data to count the number of deliveries for each combination of port and fish type\nmatch_summary &lt;- matched_data_harbor %&gt;%\n  group_by(port, fishtype) %&gt;%\n  summarize(num_deliveries = n())\n\nggplot(match_summary, aes(x = port, y = fishtype, color = fishtype, size = num_deliveries)) +\n  geom_point(alpha = 1) +  # Adjust alpha for transparency if needed\n  labs(title = \"More records matched, with 1613 unique matches\",\n       x = NULL,\n       y = NULL,\n       subtitle = \"Matching with the harbor records only could be more accurate\",\n       size = \"Number of Deliveries\") +\n  scale_x_discrete(labels = custom_labels) +\n  theme_minimal() +\n  theme(plot.title = element_text(size = 11, face = \"bold\")) \n\n\n\n\n\n\n\n\n\n\n\nCode\nedges &lt;- matched_data_harbor %&gt;%\n  select(vessel, id) %&gt;%\n  distinct() %&gt;%\n  filter(!is.na(vessel) & !is.na(id))\n\n# Create nodes for the network graph\nnodes &lt;- data.frame(name = unique(c(edges$vessel, edges$id)))\n\n# Create igraph object\ngraph &lt;- graph_from_data_frame(d = edges, vertices = nodes, directed = FALSE)\n\n\nTrying to plot using network graphs - but this is a mess - need to tidy up!\n\n\nCode\n# Plot the network graph\nggraph(graph, layout = \"fr\") + \n  geom_edge_link(aes(start_cap = label_rect(node1.name), end_cap = label_rect(node2.name)), arrow = arrow(type = \"closed\", length = unit(4, \"mm\")), color = \"gray\") +\n  geom_node_point(aes(color = name %in% edges$vessel), size = 5) + \n  geom_node_text(aes(label = name), vjust = 1.5, size = 3) +\n  labs(title = \"Network Graph of Vessels and Linked Cargo\") +\n  theme_void() +\n  theme(legend.position = \"none\", plot.title = element_text(hjust = 0.5, face = \"bold\"))"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#identify-vessels-belonging-to-sec",
    "href": "TakehomeEx/ex03/takehomeex3.html#identify-vessels-belonging-to-sec",
    "title": "Take Home Ex 3",
    "section": "6.1 Identify Vessels belonging to SEC",
    "text": "6.1 Identify Vessels belonging to SEC\n\n\nCode\nSEC_vessel &lt;- vessel_list %&gt;%\n  filter (company == \"SouthSeafood Express Corp\")\n\n\nWe found only 2 vessels linked to SEC:\n\nSnapper Snatcher (snappersnatcher7be)- a small 100 ton vessel\nRoach Robber (roachrobberdb6)- a 11700 ton bigger vessel"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#introducing-the-geospatial-data-to-help-in-visualising",
    "href": "TakehomeEx/ex03/takehomeex3.html#introducing-the-geospatial-data-to-help-in-visualising",
    "title": "Take Home Ex 3",
    "section": "6.2 Introducing the Geospatial Data to help in visualising",
    "text": "6.2 Introducing the Geospatial Data to help in visualising\nImporting the geographical data in geojson file format\n\n\nCode\nOceanusGeography = st_read(\"data/OceanusGeography.geojson\") %&gt;%\n  st_transform(crs = 4326)\n\n\nReading layer `OceanusGeography' from data source \n  `C:\\zjjgithubb\\ISSS608VA\\TakehomeEx\\ex03\\data\\OceanusGeography.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 29 features and 7 fields\nGeometry type: GEOMETRY\nDimension:     XY\nBounding box:  xmin: -167.0654 ymin: 38.07452 xmax: -163.2723 ymax: 40.67775\nGeodetic CRS:  WGS 84\n\n\nVisualising the geojson:\n\n\nCode\nggplot(data = OceanusGeography) +\n  geom_sf()\n\n\n\n\n\n\n\n\n\n\n\nCode\nwrite_rds(OceanusGeography, \"data/rds/OceanusGeography.rds\")"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#importing-geographical-data-in-esri-shapefile-format",
    "href": "TakehomeEx/ex03/takehomeex3.html#importing-geographical-data-in-esri-shapefile-format",
    "title": "Take Home Ex 3",
    "section": "6.3 Importing Geographical Data in ESRI shapefile format",
    "text": "6.3 Importing Geographical Data in ESRI shapefile format\n\n\nCode\nOceanusLocations &lt;- st_read(dsn = \"data/shp\",\n  layer = \"Oceanus Geography\")\n\n\nReading layer `Oceanus Geography' from data source \n  `C:\\zjjgithubb\\ISSS608VA\\TakehomeEx\\ex03\\data\\shp' using driver `ESRI Shapefile'\nSimple feature collection with 27 features and 7 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: -167.0654 ymin: 38.07452 xmax: -163.2723 ymax: 40.67775\nGeodetic CRS:  WGS 84\n\n\n\n\nCode\nggplot(data = OceanusLocations) +\n  geom_sf()\n\n\n\n\n\n\n\n\n\n\n\nCode\nwrite_rds(OceanusLocations, \"data/rds/OceanusLocations.rds\")"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#data-prep-for-vessel-movement-data",
    "href": "TakehomeEx/ex03/takehomeex3.html#data-prep-for-vessel-movement-data",
    "title": "Take Home Ex 3",
    "section": "6.4 Data Prep for Vessel Movement Data",
    "text": "6.4 Data Prep for Vessel Movement Data\n\n\nCode\nvessel_movement_data &lt;- mc2_edges %&gt;%\n  filter(event3 == \"TransponderPing\") %&gt;%\n  select(time, dwell, source, target)\n\n\n\n\nCode\nunique(vessel_movement_data$source)\n\n\n [1] \"City of Haacklee\"        \"City of Lomark\"         \n [3] \"City of Himark\"          \"City of Paackland\"      \n [5] \"City of South Paackland\" \"City of Port Grove\"     \n [7] \"Exit West\"               \"Nav 3\"                  \n [9] \"Nav D\"                   \"Nav B\"                  \n[11] \"Nav A\"                   \"Nav C\"                  \n[13] \"Nav 2\"                   \"Nav 1\"                  \n[15] \"Exit East\"               \"Exit South\"             \n[17] \"Exit North\"              \"Nav E\"                  \n[19] \"Cod Table\"               \"Ghoti Preserve\"         \n[21] \"Wrasse Beds\"             \"Nemo Reef\"              \n[23] \"Don Limpet Preserve\"     \"Tuna Shelf\"             \n\n\n\n\nCode\nunique(OceanusLocations$Name)\n\n\n [1] \"Haacklee\"            \"Port Grove\"          \"Lomark\"             \n [4] \"Himark\"              \"Paackland\"           \"Centralia\"          \n [7] \"South Paackland\"     \"Exit West\"           \"Nav 3\"              \n[10] \"Nav D\"               \"Nav B\"               \"Nav A\"              \n[13] \"Nav C\"               \"Nav 2\"               \"Nav 1\"              \n[16] \"Exit East\"           \"Exit South\"          \"Exit North\"         \n[19] \"Nav E\"               \"Don Limpet Preserve\" \"Tuna Shelf\"         \n[22] \"Makara Shoal\"        \"Silent Sanctuary\"    \"Cod Table\"          \n[25] \"Ghoti Preserve\"      \"Wrasse Beds\"         \"Nemo Reef\"          \n\n\nWe note that the vessel movement data’s name of the location did not match the OceanusLocations. So we need to match.\n\n\nCode\nvessel_movement_data &lt;- vessel_movement_data%&gt;%\n  mutate(source = gsub(\"^City of\", \"\", source)) %&gt;%\n  mutate(source = gsub(\"^\\\\s+\", \"\", source))\n\n\n\n\nCode\ncoords &lt;- st_coordinates(OceanusLocations)\n\n\n\n\nCode\nOceanusLocations_df &lt;- OceanusLocations %&gt;%\n  st_drop_geometry()\n\n\n\n\nCode\nOceanusLocations_df$XCOORD &lt;- coords[, \"X\"]\nOceanusLocations_df$YCOORD &lt;- coords[, \"Y\"]\n\n\n\n\nCode\nOceanusLocations_df &lt;- OceanusLocations_df %&gt;%\n  select(Name, X.Kind, XCOORD, YCOORD) %&gt;%\n  rename(Loc_Type = X.Kind)\n\n\n\n\nCode\nvessel_movement_data &lt;- vessel_movement_data %&gt;%\n  left_join(OceanusLocations_df,\n            by = c(\"source\" = \"Name\"))\n\n\n\n\nCode\nwrite_rds(vessel_movement_data, \"data/rds/vessel_movement_data.rds\")"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#visualising-the-trajectories-of-snappy-snatcher-and-roach-robber",
    "href": "TakehomeEx/ex03/takehomeex3.html#visualising-the-trajectories-of-snappy-snatcher-and-roach-robber",
    "title": "Take Home Ex 3",
    "section": "6.5 Visualising the Trajectories of Snappy Snatcher and Roach Robber",
    "text": "6.5 Visualising the Trajectories of Snappy Snatcher and Roach Robber\n\n6.5.1 Transforming the vessel movement data to a path\n\n\nCode\nvessel_movement_data &lt;- read_rds(\"data/rds/vessel_movement_data.rds\")\n\nOceanusGeography &lt;- read_rds(\"data/rds/OceanusGeography.rds\")\n\n\n\n\nCode\nvessel_movement_sf &lt;- vessel_movement_data %&gt;%\n  st_as_sf(coords = c(\"XCOORD\", \"YCOORD\"), \n           crs = 4326)\n\n\n\n\nCode\nvessel_movement_sf &lt;- vessel_movement_sf %&gt;%\n  arrange(target, time)\n\n\n\n\nCode\nvessel_trajectory &lt;- vessel_movement_sf %&gt;%\n  group_by(target) %&gt;%\n  summarize(do_union = FALSE) %&gt;%\n  st_cast(\"LINESTRING\")\n\n\n\n\nCode\nvessel_trajectory_selected &lt;- vessel_trajectory %&gt;%\n  filter(target == \"snappersnatcher7be\")\n\n\n\n\n6.5.2 Calculating the Dwell Time (mins) at each point\nFor now, we will look at the total amount of time that each vessel has spent at each location. We will sum the dwell time (converted to mins) at each location.\n\n\nCode\npoints_data &lt;- vessel_movement_sf %&gt;%\n  filter (target == \"snappersnatcher7be\") %&gt;%\n  group_by(target, geometry) %&gt;%\n  summarize(dwell_time = sum(dwell)/60)\n\n# Ensure the geometry column is retained as a 'geometry' class\nst_geometry(points_data) &lt;- points_data$geometry\n\n\nSubsequently, it will be richer if we are able to plot the data by months. This would help us better visualise and compare the movement of the vessels.\n\n\n6.5.3 Path of Snapper Snatcher and Roach Robber\n\n\nCode\nvessel_trajectory_robber &lt;- vessel_trajectory %&gt;%\n  filter(target == \"roachrobberdb6\")\n\npoints_data_robber &lt;- vessel_movement_sf %&gt;%\n  filter (target == \"roachrobberdb6\") %&gt;%\n  group_by(target, geometry) %&gt;%\n  summarize(dwell_time = sum(dwell)/60)\n\n# Ensure the geometry column is retained as a 'geometry' class\nst_geometry(points_data_robber) &lt;- points_data_robber$geometry\n\n\n\nCode\nggplot() +\n  geom_sf(data = OceanusGeography) +\n  geom_sf_text(data = OceanusGeography, aes(label = Name), nudge_y = 0.1, size = 2) + \n  geom_sf(data = vessel_trajectory_selected, \n          color = \"blue\",  # Set the color of the trajectory\n          linewidth = 1.2, alpha = 0.5) +\n  geom_point(data = points_data, \n             aes(x = st_coordinates(geometry)[, \"X\"], \n                 y = st_coordinates(geometry)[, \"Y\"], \n                 size = dwell_time, color = dwell_time), \n             alpha = 0.7) +  # Add points with size based on dwell time\n  scale_size_continuous(name = \"Dwell Time (mins)\") +  \n  scale_color_gradient(name = \"Dwell Time (mins)\", low = \"lavender\", high = \"mediumpurple4\") +  \n  theme_minimal() +\n  labs(title = \"Snapper Snatcher spent substantial time within Ghouti Preserve\", \n       x = \"Longitude\", y = \"Latitude\")\n\n\nggplot() +\n  geom_sf(data = OceanusGeography) +\n  geom_sf_text(data = OceanusGeography, aes(label = Name), nudge_y = 0.1, size = 2) + \n  geom_sf(data = vessel_trajectory_robber, \n          color = \"blue\",  # Set the color of the trajectory\n          linewidth = 1.2, alpha = 0.5) +\n  geom_point(data = points_data_robber, \n             aes(x = st_coordinates(geometry)[, \"X\"], \n                 y = st_coordinates(geometry)[, \"Y\"], \n                 size = dwell_time, color = dwell_time), \n             alpha = 0.7) +  # Add points with size based on dwell time\n  scale_size_continuous(name = \"Dwell Time (mins)\") +  \n  scale_color_gradient(name = \"Dwell Time (mins)\", low = \"lavender\", high = \"mediumpurple4\") +  \n  theme_minimal() +\n  labs(title = \"Roach Robber spent time mostly at Himark, Wrasse Beds and Nav C\", \n       x = \"Longitude\", y = \"Latitude\")\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Path of Snapper Snatcher\n\n\n\n\n\n\n\n\n\n\n\n(b) Patch of Roach Robber\n\n\n\n\n\n\n\nFigure 3: Snapper Snatcher lingered in Ghoti Preserve\n\n\n\nSnapper Snatcher also spent time at Exit East - they are likely to engage in Deep Sea Fishing there (activities tied to the Exit Areas). This is also likely where they can fish for Salmon (assumption) - given that Salmon was not found in the other fishing grounds.\n\n\nCode\ncombined_path &lt;- bind_rows(vessel_trajectory_selected, vessel_trajectory_robber)\n\npoints_data_combined &lt;- bind_rows(points_data, points_data_robber)\n\nwrapped_subtitle &lt;- str_wrap(\"Transhipment could have occured at these locations\", width = 60)\n\nggplot() +\n  geom_sf(data = OceanusGeography) +\n  geom_sf_text(data = OceanusGeography, aes(label = Name), nudge_y = 0.1, size = 2) + \n  geom_sf(data = combined_path, aes(color = target), linewidth = 1.2, alpha = 0.2) +\n  \n  scale_color_manual(name = \"Path\", \n                     values = c(\"snappersnatcher7be\" = \"blue\", \"roachrobberdb6\" = \"red\")) +\n  \n  geom_point(data = points_data_combined, aes(x = st_coordinates(geometry)[, \"X\"], \n                                              y = st_coordinates(geometry)[, \"Y\"], \n                                              size = dwell_time), \n             alpha = 0.7) +  \n   \n  scale_size_continuous(name = \"Dwell Time (mins)\") +\n  \n  theme_minimal() +\n  labs(title = \"Common Points at Lomark, Wrasse Beds and Nav C\", \n       subtitle = wrapped_subtitle, \n       x = \"Longitude\", y = \"Latitude\")\n\n\n\n\n\n\n\n\n\n\n\n6.5.4 When and Where did the illegal fishing took place?\n\n\nCode\nSEC_catches &lt;- all_catch_summary %&gt;%\n  filter (vessel %in% c(\"Snapper Snatcher\", \"Roach Robber\"))\n\n\n\n\nCode\nSEC_catch_summary &lt;- SEC_catches %&gt;%\n  group_by(vessel, fishtype) %&gt;%\n  summarise(fishtype_count = n()) %&gt;%\n  ungroup()\n\nSEC_catch_summary\n\n\n# A tibble: 9 × 3\n  vessel           fishtype fishtype_count\n  &lt;chr&gt;            &lt;chr&gt;             &lt;int&gt;\n1 Roach Robber     Beauvoir             22\n2 Roach Robber     Birdseye             22\n3 Roach Robber     Wrasse               22\n4 Snapper Snatcher Beauvoir             18\n5 Snapper Snatcher Birdseye             18\n6 Snapper Snatcher Cod                  16\n7 Snapper Snatcher Helenaa               4\n8 Snapper Snatcher Offidiaa              4\n9 Snapper Snatcher Wrasse               12\n\n\nFrom the table above, we would notice that because Snapper Snatcher spent time in the Ghoti Preserve, it would like have caught species like Helenaa and Offidiaa which are species that are found in the preserve only. These data is collated based on the vessel’s transponder ping location.\nNext we will try to find out when did such fishing took place based on the transponder data.\n\n\nCode\n# Define the location and vessel of interest\nlocation_of_interest &lt;- \"Ghoti Preserve\"\nvessel_of_interest &lt;- \"Snapper Snatcher\"\n\n# Filter data for the specific location and vessel\ntrespassing_dates &lt;- transponder %&gt;%\n  filter(location == location_of_interest, vessel == vessel_of_interest) %&gt;%\n  select(time, month, day) \n\nprint(trespassing_dates)\n\n\n# A tibble: 4 × 5\n# Groups:   vessel, location [1]\n  vessel           location       time                month day  \n  &lt;chr&gt;            &lt;chr&gt;          &lt;dttm&gt;              &lt;dbl&gt; &lt;ord&gt;\n1 Snapper Snatcher Ghoti Preserve 2035-02-02 05:39:59     2 Fri  \n2 Snapper Snatcher Ghoti Preserve 2035-02-09 05:49:11     2 Fri  \n3 Snapper Snatcher Ghoti Preserve 2035-02-16 07:02:09     2 Fri  \n4 Snapper Snatcher Ghoti Preserve 2035-03-15 05:46:02     3 Thu  \n\n\nWe note from the data that the activities took place in Feb and Mar - however, this did not correspond to any cargo delivery reports from the earlier data.\nWe will also check the other vessels that spent time in Ghoti Preserve.\n\n\nCode\nother_trespassers &lt;- transponder %&gt;%\n  filter(location == \"Ghoti Preserve\") %&gt;%\n  select(vessel, time, month, day, stay_duration, location) \n\n\n\n\nCode\nmonthly_summary &lt;- other_trespassers %&gt;%\n  group_by(month) %&gt;%\n  summarise(\n    unique_vessels = n_distinct(vessel),\n    mean_stay_duration = mean(stay_duration/360, na.rm = TRUE)\n  )\n\n\n\n\nCode\nggplot(monthly_summary, aes(x = month)) +\n  geom_bar(aes(y = unique_vessels), stat = \"identity\", fill = \"azure4\") +\n  geom_line(aes(y = mean_stay_duration * 10), color = \"lightpink\", size = 1) +  # Scale mean stay duration for visibility\n  geom_point(aes(y = mean_stay_duration * 10), color = \"red\", size = 2) +  # Add points for mean stay duration\n  scale_y_continuous(\n    name = \"Number of Unique Vessels\",\n    sec.axis = sec_axis(~./10, name = \"Mean Stay Duration (hours)\")  # Adjust secondary axis scale\n  ) +\n  labs(title = \"Monthly Trespass into Ghouti Preserve\",\n       x = \"Month\",\n       y = \"Number of Unique Vessels\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Convert month and day to Date object\nother_trespassers &lt;- other_trespassers %&gt;%\n  mutate (month = month(time, label = TRUE))\n\nother_trespassers &lt;- other_trespassers %&gt;%\n  mutate (stay_duration = stay_duration/60)\n\n\n\n\nCode\n# Create the boxplot\nggplot(other_trespassers, aes(x = month, y = stay_duration)) +\n  geom_boxplot() +\n  labs(title = \"Box plot of Duration in Ghoti Preserve\",\n       x = \"Month\",\n       y = \"Stay Duration (mins)\",\n       subtitle = \"Mean time spent dropped in Apr to Jul; Increased from Aug to Nov\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nFrom the charts, I postulate that after Snapper Snatcher was caught in May, the other vessels chose to spend lesser time in Ghoti Preserve, but their time in the Preserve subsequently picked up again from Aug onwards. This corresponds to the delivery pattern of Helenaa and Offidiaa, where their deliveries started to increase from Sep onwards. That said - we may also need to note the species habitual patterns and whether are they present in Ghoti Preserve during these months. (Tried to google these species, but seems like they are fictitious).\n\n\n6.5.6 Other Vessels Movement Path\n\n\nCode\nvessel_trajectory_carp &lt;- vessel_trajectory %&gt;%\n  filter(target == \"carpcapturer993\")\n\npoints_data_carp &lt;- vessel_movement_sf %&gt;%\n  filter (target == \"carpcapturer993\") %&gt;%\n  group_by(target, geometry) %&gt;%\n  summarize(dwell_time = sum(dwell)/60)\n\n# Ensure the geometry column is retained as a 'geometry' class\nst_geometry(points_data_carp) &lt;- points_data_carp$geometry\n\n\n\n\nCode\nggplot() +\n  geom_sf(data = OceanusGeography) +\n  geom_sf_text(data = OceanusGeography, aes(label = Name), nudge_y = 0.1, size = 2) + \n  geom_sf(data = vessel_trajectory_carp, \n          color = \"blue\",  # Set the color of the trajectory\n          linewidth = 1.2, alpha = 0.5) +\n  geom_point(data = points_data_carp, \n             aes(x = st_coordinates(geometry)[, \"X\"], \n                 y = st_coordinates(geometry)[, \"Y\"], \n                 size = dwell_time, color = dwell_time), \n             alpha = 0.7) +  # Add points with size based on dwell time\n  scale_size_continuous(name = \"Dwell Time (mins)\") +  \n  scale_color_gradient(name = \"Dwell Time (mins)\", low = \"lavender\", high = \"mediumpurple4\") +  \n  theme_minimal() +\n  labs(title = \"Carp Capturer spent time at Himark, Wrasse Beds and Nav C\", \n       subtitle = \"Dwell Time at Nav C seems high - can investigate further\", \n       x = \"Longitude\", y = \"Latitude\")\n\n\n\n\n\n\n\n\n\nCarp Capturer seems like a fishing vessel that engages only in legal fishing activities, with no time spent in the reserves and mostly shuttling between the ports, navigation lines and the fishing grounds."
  },
  {
    "objectID": "TakehomeEx/ex02/takehomeex2.html",
    "href": "TakehomeEx/ex02/takehomeex2.html",
    "title": "Take Home Ex 2",
    "section": "",
    "text": "In this take-home exercise, we are required to:\n\nselect one data visualisation from the Take-home Exercise 1 submission prepared by your classmate,\ncritic the submission in terms of clarity and aesthetics,\nprepare a sketch for the alternative design by using the data visualisation design principles and best practices you had learned in Lesson 1 and 2.\nremake the original design by using ggplot2, ggplot2 extensions and tidyverse packages."
  },
  {
    "objectID": "TakehomeEx/ex02/takehomeex2.html#original-design",
    "href": "TakehomeEx/ex02/takehomeex2.html#original-design",
    "title": "Take Home Ex 2",
    "section": "1.1 Original Design",
    "text": "1.1 Original Design\nThe plot below shows the original design of the unit price deviations by planning areas. We can access the original dashboard from here.\n\nThe PlotCode\n\n\n\n\n\n\n# Private\ndf_Aavg &lt;- uniondata %&gt;%\n  filter(Purchaser.Address.Indicator == \"Private\") %&gt;%\n  group_by(Planning.Area) %&gt;%\n  summarise(avg_Aprice = mean(Unit.Price....PSF.))\n\ndf_Aavg$p_z &lt;- round((df_Aavg$avg_Aprice - mean(df_Aavg$avg_Aprice)) / sd(df_Aavg$avg_Aprice), 2)\ndf_Aavg$p_ztype &lt;- ifelse(df_Aavg$p_z &lt; 0, \"below\", \"above\")\ndf_Aavg &lt;- df_Aavg[order(df_Aavg$p_z), ]\n\ndf_Aavg$Planning.Area &lt;- factor(df_Aavg$Planning.Area, levels = df_Aavg$Planning.Area)\n\nplot11 &lt;- ggplot(df_Aavg, aes(x = Planning.Area, y = p_z, label = p_z)) +\n  geom_bar(stat = \"identity\", aes(fill = p_ztype), position = position_dodge2(width = 2), width = 0.8) +\n  scale_fill_manual(name = \"Average Price\", labels = c(\"Above Average\", \"Below Average\"), values = c(\"below\" = \"#C83E4D\", \"above\" = \"#4A5859\")) +\n  labs(title = \"Unit Price Deviations by Area\", y = \"\", subtitle = \"Private\") +\n  coord_flip() +\n  theme(legend.position = \"None\", text = element_text(size = 8), plot.title = element_text(size = 12, face = \"bold\"))\n\n# HDB\ndf_AHavg &lt;- uniondata %&gt;%\n  filter(Purchaser.Address.Indicator == \"HDB\") %&gt;%\n  group_by(Planning.Area) %&gt;%\n  summarise(avg_Aprice = mean(Unit.Price....PSF.))\n\ndf_AHavg$p_z &lt;- round((df_AHavg$avg_Aprice - mean(df_AHavg$avg_Aprice)) / sd(df_AHavg$avg_Aprice), 2)\ndf_AHavg$p_ztype &lt;- ifelse(df_AHavg$p_z &lt; 0, \"below\", \"above\")\ndf_AHavg &lt;- df_AHavg[order(df_AHavg$p_z), ]\n\ndf_AHavg$Planning.Area &lt;- factor(df_AHavg$Planning.Area, levels = df_AHavg$Planning.Area)\n\nplot22 &lt;- ggplot(df_AHavg, aes(x = Planning.Area, y = p_z, label = p_z)) +\n  geom_bar(stat = \"identity\", aes(fill = p_ztype), position = position_dodge2(width = 2), width = 0.8) +\n  scale_fill_manual(name = \"Average Price\", labels = c(\"Above Average\", \"Below Average\"), values = c(\"below\" = \"#C83E4D\", \"above\" = \"#4A5859\")) +\n  labs(y = \"\", x = \"\", subtitle = \"HDB\") +\n  coord_flip() +\n  theme(text = element_text(size = 8),\n        legend.title = element_blank(),\n        legend.position = c(0.25, 0.9),\n        legend.key.size = unit(0.4, 'cm'),\n        legend.key.height = unit(0.4, 'cm'),\n        legend.key.width = unit(0.4, 'cm'))\n\nplot11 + plot22"
  },
  {
    "objectID": "TakehomeEx/ex02/takehomeex2.html#clarity",
    "href": "TakehomeEx/ex02/takehomeex2.html#clarity",
    "title": "Take Home Ex 2",
    "section": "2.1 Clarity",
    "text": "2.1 Clarity\n\nI think the chart is a bit misleading given that the data did not include HDB prices, perhaps the originator was a bit confused about the data set. In fact, the data comprises only private residential property - we will try to adjust this in our data visualisation make over.\nWhen we look at the title - it says “Unit Price Deviations by Area” which provides a brief overview of what the graph is trying to show - but the title could be titled differently to bring across the key points from the chart. For example in the initial chart where the originator separated by HDB and Private - they could compare the unit prices between them and whether the planning areas are the same. Or simply the title could say - “Unit Prices are higher than average in the Central Region”.\nThe data utilised all the planning areas and show it on the chart, but it does not bring across the key message that we want to convey - or whether there are any important planning areas that we want to focus on. The order of the planning area here is not meaningful for us to understand.\nThe x-axis is in terms of std dev above the average price (we assume so and also not indicated whether is it in psf or psm), but there is no indication of the actual prices. This makes it difficult for the reader to associate the chart with the actual prices and the delta in between. The comparison of the actual average price is also not listed here.\nThe chart also did not indicate a time frame and it was also not highlighted in the title - hence we are not clear about the time period that this chart is referring to - whether 2023 or quarterly or monthly data.\nWe are also not sure which type of sales data the price is referring to - whether is it new sale or resale."
  },
  {
    "objectID": "TakehomeEx/ex02/takehomeex2.html#aesthetics",
    "href": "TakehomeEx/ex02/takehomeex2.html#aesthetics",
    "title": "Take Home Ex 2",
    "section": "2.2 Aesthetics",
    "text": "2.2 Aesthetics\n\nThere is color differentiation between those with prices above average and those below average which makes it easier to read.\nThe y axis - should change the label to remove the underscore.\nThe chart looks clean and neat. The legend is neatly tucked away and not repeated in both graphs.\nThe gridlines can be a bit distracting."
  },
  {
    "objectID": "TakehomeEx/ex02/takehomeex2.html#design-sketch",
    "href": "TakehomeEx/ex02/takehomeex2.html#design-sketch",
    "title": "Take Home Ex 2",
    "section": "3.1 Design Sketch",
    "text": "3.1 Design Sketch\nWe start by thinking about the message we want to convey and coming up with a sketch.\n\nSince we want to talk abt the unit prices across planning areas, I think we should have them grouped by regions.\nWe can compare the current price in Q1 Y24 vs the median prices in 2023 - so we know the changes in unit prices of each area.\nWe compare the bars between the Condominiums and Landed Properties so we can easily understand the unit prices of each area.\nThe scale should also be in $psm so that the readers can visualise how much in dollar sense instead of requiring to do a mental calculation"
  },
  {
    "objectID": "TakehomeEx/ex02/takehomeex2.html#data-preparation",
    "href": "TakehomeEx/ex02/takehomeex2.html#data-preparation",
    "title": "Take Home Ex 2",
    "section": "3.2 Data Preparation",
    "text": "3.2 Data Preparation\nGiven that there were some misconception about the data by the originator, I will utilise the version that was cleaned up by myself to try to plot this chart instead.\nHaving save the data previously in rds - i can easily call it up:\nLoading the packages:\n\npacman::p_load(plotly, patchwork, hrbrthemes, ggridges, ggrepel, tidyverse, ggpubr, scales, colorspace, ggdist)\n\nReading the data from rds file:\n\nrealis2324 &lt;- read_rds(\"rds/realis2324_cleaned.rds\")\n\nData Prep required:\n\nAdjust the property types to summarise Landed Properties.\nCalculate the median prices in 2023 and the difference in unit price ($psm) for Q1Y24 and determine if it is above median or below median for both Condominiums, Exec Condo and Landed Properties\n\n\n\nCode\nrealis2324 &lt;- realis2324 %&gt;%\n  mutate(property_type = case_when(\n    property_type %in% c(\"Condominium\", \"Executive Condominium\") ~ property_type,\n    TRUE ~ \"Landed\"\n  ))\n\nrealis_subset23 &lt;- realis2324 %&gt;%\n  filter(sale_type %in% c(\"Resale\", \"Sub Sale\"), \n         quarter %in% c(\"Q1Y23\", \"Q2Y23\", \"Q3Y23\", \"Q4Y23\") \n         )\n\nresale23_median &lt;- round(median(realis_subset23$unit_psm))\n\nrealis_subset24 &lt;- realis2324 %&gt;%\n  filter(sale_type %in% c(\"Resale\", \"Sub Sale\"), \n         quarter %in% c(\"Q1Y24\") \n         )\n\nrealis_subset24 &lt;- realis_subset24 %&gt;%\n  mutate(\n    diff_from_median = unit_psm - resale23_median, \n    percent_difference = ((unit_psm - resale23_median)/resale23_median)* 100\n         )\n\ndf_unitprices &lt;- realis_subset24 %&gt;%\n  group_by(planning_area, property_type) %&gt;%\n  summarize(\n    average_diff_from_median = mean(diff_from_median, na.rm = TRUE),\n    average_percent_from_median = mean(percent_difference, na.rm = TRUE),\n    planning_region = first(planning_region)\n  ) %&gt;%\n  mutate(above_median = ifelse(average_diff_from_median &gt; 0, \"Above Median\", \"Below Median\"))"
  },
  {
    "objectID": "TakehomeEx/ex02/takehomeex2.html#plotting-the-charts",
    "href": "TakehomeEx/ex02/takehomeex2.html#plotting-the-charts",
    "title": "Take Home Ex 2",
    "section": "3.3 Plotting the Charts",
    "text": "3.3 Plotting the Charts\nWe will try with one planning region first - lets start with the Central Region.\n\nrealis_subset24_central &lt;- df_unitprices %&gt;%\n  filter(planning_region == \"Central Region\") \n\nrealis_subset24_ocr &lt;- df_unitprices %&gt;%\n  filter(planning_region != \"Central Region\") \n\nUtilising the code by the originator:\n\nplot11 &lt;- ggplot(realis_subset24_central, aes(x = planning_area, y = average_percent_from_median)) +\n  geom_bar(stat = \"identity\", aes(fill = above_median), position = position_dodge2(width = 2), width = 0.8) +\n  scale_fill_manual(name = \"Median Price\", labels = c(\"Above Median\", \"Below Median\"), values = c(\"below\" = \"#C83E4D\", \"above\" = \"#4A5859\")) +\n  labs(title = \"Unit Price Deviations by Area\", y = \"\", subtitle = \"Private\") +\n  coord_flip() +\n  facet_wrap(~ property_type, scales = \"free_y\", ncol = 1) +\n  theme(legend.position = \"None\", text = element_text(size = 8), plot.title = element_text(size = 12, face = \"bold\"))\n\nplot11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWe notice here that for the Central Region, the average unit price in $ psm is all above the median and that there are 19 planning areas within the Central Region out of 38 (i.e. 50%).\nThe data is now on two separate graphs, lets see if we can combine them into 1.\n\n\n\nplot_cr &lt;- ggplot(realis_subset24_central, aes(x = planning_area, y = average_percent_from_median, fill = above_median)) +\n  geom_bar(aes(fill = property_type), stat = \"identity\", position = \"dodge\", width = 0.4, alpha = 0.7) +\n  scale_fill_manual(name = \"Property Type\", labels = c(\"Condominium\",  \"Landed\"), \n  values = c(\"Condominium\" = \"#C83E4D\", \"Landed\" = \"#4A5859\")) +\n  labs(x = \"Planning Area\", y = \"Percentage Diff from Median Unit Price in 2023\", subtitle = \"Central Region\") +\n  coord_flip() +\n  ylim(-50, 160) +\n  theme_minimal() +\n  theme(legend.position = \"none\", \n        text = element_text(size = 8)\n        )\n\nplot_cr\n\n\n\n\n\n\n\n\n\nplot_ocr &lt;- ggplot(realis_subset24_ocr, aes(x = planning_area, y = average_percent_from_median, fill = above_median)) +\n  geom_bar(aes(fill = property_type), stat = \"identity\", position = \"dodge\", width = 0.4, alpha = 0.7) +\n  scale_fill_manual(name = \"Property Type\", labels = c(\"Condominium\",  \"Executive Condominium\", \"Landed\"), \n  values = c(\"Condominium\" = \"#C83E4D\",\"Executive Condominium\" = \"orange\", \"Landed\" = \"#4A5859\")) +\n  labs(x = \"Planning Area\", y = \"Percentage Diff from Median Unit Price in 2023\", subtitle = \"Outside Central Region\")  +\n  coord_flip() +\n  ylim(-50, 160) +\n  theme_minimal()+\n  theme(legend.position = \"none\", \n        text = element_text(size = 8), \n        plot.title = element_text(size = 12, face = \"bold\"))\n\nplot_ocr"
  },
  {
    "objectID": "TakehomeEx/ex02/takehomeex2.html#final-chart",
    "href": "TakehomeEx/ex02/takehomeex2.html#final-chart",
    "title": "Take Home Ex 2",
    "section": "3.4 Final Chart",
    "text": "3.4 Final Chart\nThen we will use patchwork to combine the 2 charts and also to beautify the chart.\n\ng1 &lt;- plot_cr | plot_ocr\n\ng2 &lt;- g1 + plot_annotation(\n  title = str_wrap(\"Unit Prices ($psm) for resale private properties was higher for Central Region in Q1Y24 as compared to 2023\"),\n  subtitle = str_wrap(\"Unit Prices in OCR mostly dropped in Q1Y24 as compared to median unit price in 2023 which was $16,667 psm\"),\n  caption = \"Median Unit Price ($psm) in 2023 was $16,667. Data sourced from https://www.ura.gov.sg/reis/index\"\n  ) + \n  plot_layout(axis_titles = \"collect\", guides = \"collect\") &\n  theme(title=element_text(size=8, face='bold'), \n        axis.text.x = element_text(size = 5),\n        axis.text.y = element_text(size = 5),\n        axis.title.y = element_text(size = 7),\n        axis.title.x = element_text(size = 7),\n        legend.key.size = unit(0.3, 'cm'), #change legend key size\n        legend.key.height = unit(0.3, 'cm'), #change legend key height\n        legend.key.width = unit(0.3, 'cm'), #change legend key width\n        legend.title = element_text(size=6), #change legend title font size\n        legend.text = element_text(size=6),\n        legend.position = \"bottom\"\n        ) \n\ng2"
  },
  {
    "objectID": "TakehomeEx/ex02/takehomeex2.html#improvements-of-chart",
    "href": "TakehomeEx/ex02/takehomeex2.html#improvements-of-chart",
    "title": "Take Home Ex 2",
    "section": "3.5 Improvements of Chart",
    "text": "3.5 Improvements of Chart\nSome of the improvements made to the chart:\n\nProvided the key messages in the title and sub-title\nLabelled the axes accordingly to provide readers a clearer understanding of the graphs\nSeparated the graph by the regions - Central vs Outside Central Region - which provided a key insight into the changes in the unit prices ($psm) for Q1Y24\nProvided a quick comparison across property types - between Condominiums, Executive Condos and Landed properties. This also showed a key insight - that only the landed properties in Kallang (within Central Region) transacted at below median.\nProvided the source of the data in the captions.\nKept the axes consistent to show the delta between those in central region and those in OCR."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Visual Analytics and Applications",
    "section": "",
    "text": "Below are the course work for this module."
  },
  {
    "objectID": "index.html#hands-on-exercise",
    "href": "index.html#hands-on-exercise",
    "title": "Visual Analytics and Applications",
    "section": "Hands On Exercise",
    "text": "Hands On Exercise\n\n\n\n\n\n\n\n\n\nHands-On Ex 1\n\n\n\nCheng Chun Chieh\n\n\nApr 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Ex 2\n\n\n\nCheng Chun Chieh\n\n\nApr 17, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Ex 3 - Part 2\n\n\n\nCheng Chun Chieh\n\n\nApr 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands-On Ex 3\n\n\n\nCheng Chun Chieh\n\n\nApr 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Ex 4 - Fundamentals of Visual Analytics\n\n\n\nCheng Chun Chieh\n\n\nApr 27, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Ex 5 - Visualising and Anlysing Text with R\n\n\n\nCheng Chun Chieh\n\n\nMay 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Ex 6 - Modelling, Visualising and Analysing Network Data with R\n\n\n\nCheng Chun Chieh\n\n\nMay 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nHands On Ex 7 - Time Oriented Data\n\n\n\nCheng Chun Chieh\n\n\nMay 28, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nVisualising Geospatial Data\n\n\n\nCheng Chun Chieh\n\n\nJun 5, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nEx 9 - Multivariate Analysis\n\n\n\nCheng Chun Chieh\n\n\nJun 14, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#in-class-exercise",
    "href": "index.html#in-class-exercise",
    "title": "Visual Analytics and Applications",
    "section": "In Class Exercise",
    "text": "In Class Exercise\n\n\n\n\n\n\n\n\n\nIn Class Ex 01\n\n\n\nCheng Chun Chieh\n\n\nApr 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Ex 02\n\n\n\nCheng Chun Chieh\n\n\nApr 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn-Class Ex 3\n\n\n\nCheng Chun Chieh\n\n\nApr 24, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Ex 4\n\n\n\nCheng Chun Chieh\n\n\nMay 4, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Ex 5 - Text Analytics\n\n\n\nCheng Chun Chieh\n\n\nMay 11, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Ex 6\n\n\n\nCheng Chun Chieh\n\n\nMay 18, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Ex - Geospatial\n\n\n\nCheng Chun Chieh\n\n\nJun 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nIn Class Ex 9 - Interactive Multivariate\n\n\n\nCheng Chun Chieh\n\n\nJun 15, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#take-home-exercise",
    "href": "index.html#take-home-exercise",
    "title": "Visual Analytics and Applications",
    "section": "Take Home Exercise",
    "text": "Take Home Exercise\n\n\n\n\n\n\n\n\n\nTake Home Ex 1\n\n\n\nCheng Chun Chieh\n\n\nApr 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake Home Ex 2\n\n\n\nCheng Chun Chieh\n\n\nApr 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nTake Home Ex 3\n\n\n\nCheng Chun Chieh\n\n\nMay 18, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "InClassEx/Ex08/data/shp/Oceanus Geography.html",
    "href": "InClassEx/Ex08/data/shp/Oceanus Geography.html",
    "title": "Visual Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "InClassEx/Ex05/inclassex5.html",
    "href": "InClassEx/Ex05/inclassex5.html",
    "title": "In Class Ex 5 - Text Analytics",
    "section": "",
    "text": "pacman::p_load(tidytext, tidyverse, readtext, quanteda, ggwordcloud)\n\nCan refer to the following links for info about the packages:\n\nquanteda - https://quanteda.io/articles/quickstart.html\nreadtext - https://readtext.quanteda.io/articles/readtext_vignette.html\n\n\n\n\narticles &lt;- \"data/articles/*\"\n\n\ntext_data &lt;- readtext(articles)\n\n\n\n\n\n\n\n\nA corpus is designed to be a “library” of original documents that have been converted to plain, UTF-8 encoded text, and stored along with meta-data at the corpus level and at the document-level. We have a special name for document-level meta-data: docvars. These are variables or features that describe attributes of each document.\nA corpus is designed to be a more or less static container of texts with respect to processing and analysis. This means that the texts in corpus are not designed to be changed internally through (for example) cleaning or pre-processing steps, such as stemming or removing punctuation. Rather, texts can be extracted from the corpus as part of processing, and assigned to new objects, but the idea is that the corpus will remain as an original reference copy so that other analyses – for instance those in which stems and punctuation were required, such as analysing a reading ease index – can be performed on the same corpus.\nA corpus is a special form of character vector, meaning most functions that work with a character input will also work on a corpus. But a corpus object (as do other quanteda core objects) has its own convenient print method.\n\ncorpus_text &lt;- corpus(text_data)\nsummary(corpus_text,5)\n\nCorpus consisting of 338 documents, showing 5 documents:\n\n                                   Text Types Tokens Sentences\n Alvarez PLC__0__0__Haacklee Herald.txt   206    433        18\n    Alvarez PLC__0__0__Lomark Daily.txt   102    170        12\n   Alvarez PLC__0__0__The News Buoy.txt    90    200         9\n Alvarez PLC__0__1__Haacklee Herald.txt    96    187         8\n    Alvarez PLC__0__1__Lomark Daily.txt   241    504        21\n\n\n\n\n\n\n\n\nusenet_words &lt;- text_data %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nDoing a word count:\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\nreadtext object consisting of 3260 documents and 0 docvars.\n# A data frame: 3,260 × 3\n  word             n text     \n  &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,254 more rows\n\n\n\nwords_by_doc_id &lt;- usenet_words %&gt;%\n  count(doc_id, word, sort = TRUE) %&gt;%\n  ungroup()\n\n\n\n\n\ntext_data_split &lt;- text_data %&gt;%\n  mutate(Company = str_extract(doc_id, \"^[^_]+\"),\n         News_Agencies = str_extract(doc_id, \"(?&lt;=__)[^_]+(?=\\\\.txt)\"))\n\n\n(?&lt;=__) is a positive lookbehind assertion that ensures the match occurs after “__”.\n[^_]+ matches one or more characters that are not underscores, representing the news agency.\n(?=\\\\.txt) is a positive lookahead assertion that ensures the match occurs before “.txt”.\n\n\ntext_data_splitted &lt;- text_data %&gt;%\n  separate_wider_delim(\"doc_id\",\n                       delim=\"__0__\",\n                       names = c(\"X\",\"Y\"),\n                       too_few = \"align_end\"\n  )\n\n\nusenet_words1 &lt;- text_data_split %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nwords_by_news_agencies &lt;- usenet_words1 %&gt;%\n  count(News_Agencies, word, sort = TRUE) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "InClassEx/Ex05/inclassex5.html#importing-text-data-using-readtext",
    "href": "InClassEx/Ex05/inclassex5.html#importing-text-data-using-readtext",
    "title": "In Class Ex 5 - Text Analytics",
    "section": "",
    "text": "articles &lt;- \"data/articles/*\"\n\n\ntext_data &lt;- readtext(articles)"
  },
  {
    "objectID": "InClassEx/Ex05/inclassex5.html#corpus",
    "href": "InClassEx/Ex05/inclassex5.html#corpus",
    "title": "In Class Ex 5 - Text Analytics",
    "section": "",
    "text": "A corpus is designed to be a “library” of original documents that have been converted to plain, UTF-8 encoded text, and stored along with meta-data at the corpus level and at the document-level. We have a special name for document-level meta-data: docvars. These are variables or features that describe attributes of each document.\nA corpus is designed to be a more or less static container of texts with respect to processing and analysis. This means that the texts in corpus are not designed to be changed internally through (for example) cleaning or pre-processing steps, such as stemming or removing punctuation. Rather, texts can be extracted from the corpus as part of processing, and assigned to new objects, but the idea is that the corpus will remain as an original reference copy so that other analyses – for instance those in which stems and punctuation were required, such as analysing a reading ease index – can be performed on the same corpus.\nA corpus is a special form of character vector, meaning most functions that work with a character input will also work on a corpus. But a corpus object (as do other quanteda core objects) has its own convenient print method.\n\ncorpus_text &lt;- corpus(text_data)\nsummary(corpus_text,5)\n\nCorpus consisting of 338 documents, showing 5 documents:\n\n                                   Text Types Tokens Sentences\n Alvarez PLC__0__0__Haacklee Herald.txt   206    433        18\n    Alvarez PLC__0__0__Lomark Daily.txt   102    170        12\n   Alvarez PLC__0__0__The News Buoy.txt    90    200         9\n Alvarez PLC__0__1__Haacklee Herald.txt    96    187         8\n    Alvarez PLC__0__1__Lomark Daily.txt   241    504        21"
  },
  {
    "objectID": "InClassEx/Ex05/inclassex5.html#cleaning-text",
    "href": "InClassEx/Ex05/inclassex5.html#cleaning-text",
    "title": "In Class Ex 5 - Text Analytics",
    "section": "",
    "text": "usenet_words &lt;- text_data %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nDoing a word count:\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\nreadtext object consisting of 3260 documents and 0 docvars.\n# A data frame: 3,260 × 3\n  word             n text     \n  &lt;chr&gt;        &lt;int&gt; &lt;chr&gt;    \n1 fishing       2177 \"\\\"\\\"...\"\n2 sustainable   1525 \"\\\"\\\"...\"\n3 company       1036 \"\\\"\\\"...\"\n4 practices      838 \"\\\"\\\"...\"\n5 industry       715 \"\\\"\\\"...\"\n6 transactions   696 \"\\\"\\\"...\"\n# ℹ 3,254 more rows\n\n\n\nwords_by_doc_id &lt;- usenet_words %&gt;%\n  count(doc_id, word, sort = TRUE) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "InClassEx/Ex05/inclassex5.html#splitting-up-the-doc_id",
    "href": "InClassEx/Ex05/inclassex5.html#splitting-up-the-doc_id",
    "title": "In Class Ex 5 - Text Analytics",
    "section": "",
    "text": "text_data_split &lt;- text_data %&gt;%\n  mutate(Company = str_extract(doc_id, \"^[^_]+\"),\n         News_Agencies = str_extract(doc_id, \"(?&lt;=__)[^_]+(?=\\\\.txt)\"))\n\n\n(?&lt;=__) is a positive lookbehind assertion that ensures the match occurs after “__”.\n[^_]+ matches one or more characters that are not underscores, representing the news agency.\n(?=\\\\.txt) is a positive lookahead assertion that ensures the match occurs before “.txt”.\n\n\ntext_data_splitted &lt;- text_data %&gt;%\n  separate_wider_delim(\"doc_id\",\n                       delim=\"__0__\",\n                       names = c(\"X\",\"Y\"),\n                       too_few = \"align_end\"\n  )\n\n\nusenet_words1 &lt;- text_data_split %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nwords_by_news_agencies &lt;- usenet_words1 %&gt;%\n  count(News_Agencies, word, sort = TRUE) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "InClassEx/Ex05/inclassex5.html#importing-mc3-data",
    "href": "InClassEx/Ex05/inclassex5.html#importing-mc3-data",
    "title": "In Class Ex 5 - Text Analytics",
    "section": "2.2 Importing mc3 data",
    "text": "2.2 Importing mc3 data\n\n# Specify the file paths\ninput_file &lt;- \"data/mc3.json\"\noutput_file &lt;- \"data/mc3_processed.json\"\n\n# Read the JSON file\njson_data &lt;- readLines(input_file)\n\n# Replace NaN with null\njson_data &lt;- gsub(\"NaN\", \"null\", json_data)\n\n# Write the updated JSON data back to a file\nwriteLines(json_data, con = output_file)\n\n# Now you can read the processed JSON file into R\nmc3_data &lt;- fromJSON(output_file)"
  },
  {
    "objectID": "InClassEx/Ex03/inclassex3.html",
    "href": "InClassEx/Ex03/inclassex3.html",
    "title": "In-Class Ex 3",
    "section": "",
    "text": "can futher use the quick table calculation to spread the data\n\n\n\n\n\n\nDrop the variables into the “Marks” field\n\nSelect Size for Sum(Sales)\nSelect Colour Sum(Profit)\n\n\nChange the shape to circle - then it will be fill circles\nThe colors can also be further adjusted - together with the range\n\nUsing annotate area to annotate the four quadrants:\n\nCreating filter interactivity - expose the interface for the filters (checkbox)\n\nAdjusting the title of the graph - click on the insert button (to select the fields to show)\n\n\n\n\nCreate a second worksheet\n\nuse of dual-axis (select from the row button)\nadjust the color range (to be red for below 0, and blue for above 0)\n add in the sum(profit) into the color - then adjust the color range\n\n\n\nUse the edit tooltip on the first worksheet, click the insert button to insert from worksheet 2\n\n\n\n\n\nhttps://public.tableau.com/app/profile/chun.chieh.cheng/viz/ProfitLoss_17141962081520/Dashboard1?publish=yes\n\n\n\nInstead of dropping the Order_Date into filter -&gt; drop them into pages\n\n\nIt will show the animation pane on the right hand side.\nNext we adjust the timeframe to show by quarters instead.\n\n\n\nCreate the graphs to show in Tableu\n\nHere we are using the Maths and Science data from Exam_Data\n\nThen we will use the “Actions” under Dashboard menu item to create this.\n\n\n\nNeed to use ID under the scatterplot to sort of link the data up together"
  },
  {
    "objectID": "InClassEx/Ex03/inclassex3.html#drawing-a-scatterplot",
    "href": "InClassEx/Ex03/inclassex3.html#drawing-a-scatterplot",
    "title": "In-Class Ex 3",
    "section": "",
    "text": "can futher use the quick table calculation to spread the data"
  },
  {
    "objectID": "InClassEx/Ex03/inclassex3.html#changing-to-a-bubbleplot",
    "href": "InClassEx/Ex03/inclassex3.html#changing-to-a-bubbleplot",
    "title": "In-Class Ex 3",
    "section": "",
    "text": "Drop the variables into the “Marks” field\n\nSelect Size for Sum(Sales)\nSelect Colour Sum(Profit)\n\n\nChange the shape to circle - then it will be fill circles\nThe colors can also be further adjusted - together with the range\n\nUsing annotate area to annotate the four quadrants:\n\nCreating filter interactivity - expose the interface for the filters (checkbox)\n\nAdjusting the title of the graph - click on the insert button (to select the fields to show)"
  },
  {
    "objectID": "InClassEx/Ex03/inclassex3.html#creating-a-custom-tooltip",
    "href": "InClassEx/Ex03/inclassex3.html#creating-a-custom-tooltip",
    "title": "In-Class Ex 3",
    "section": "",
    "text": "Create a second worksheet\n\nuse of dual-axis (select from the row button)\nadjust the color range (to be red for below 0, and blue for above 0)\n add in the sum(profit) into the color - then adjust the color range\n\n\n\nUse the edit tooltip on the first worksheet, click the insert button to insert from worksheet 2"
  },
  {
    "objectID": "InClassEx/Ex03/inclassex3.html#profit-loss-dashboard",
    "href": "InClassEx/Ex03/inclassex3.html#profit-loss-dashboard",
    "title": "In-Class Ex 3",
    "section": "",
    "text": "https://public.tableau.com/app/profile/chun.chieh.cheng/viz/ProfitLoss_17141962081520/Dashboard1?publish=yes"
  },
  {
    "objectID": "InClassEx/Ex03/inclassex3.html#creating-animation-from-time",
    "href": "InClassEx/Ex03/inclassex3.html#creating-animation-from-time",
    "title": "In-Class Ex 3",
    "section": "",
    "text": "Instead of dropping the Order_Date into filter -&gt; drop them into pages\n\n\nIt will show the animation pane on the right hand side.\nNext we adjust the timeframe to show by quarters instead."
  },
  {
    "objectID": "InClassEx/Ex03/inclassex3.html#creating-coordinated-link-view",
    "href": "InClassEx/Ex03/inclassex3.html#creating-coordinated-link-view",
    "title": "In-Class Ex 3",
    "section": "",
    "text": "Create the graphs to show in Tableu\n\nHere we are using the Maths and Science data from Exam_Data\n\nThen we will use the “Actions” under Dashboard menu item to create this.\n\n\n\nNeed to use ID under the scatterplot to sort of link the data up together"
  },
  {
    "objectID": "InClassEx/Ex01/inclassex01.html",
    "href": "InClassEx/Ex01/inclassex01.html",
    "title": "In Class Ex 01",
    "section": "",
    "text": "pacman::p_load(tidyverse)\n\n\n\n\nRmb to use read_csv instead or read.csv\nUsing read_csv will retain the field names as per the csv file.\n\nrealis2019 &lt;- read_csv(\"data/realis2019.csv\")\n\n\n\n\nFirst - to take a look at the data:\n\nhead(realis2019)\n\n# A tibble: 6 × 20\n  `Project Name`           Address    `No. of Units` `Area (sqm)` `Type of Area`\n  &lt;chr&gt;                    &lt;chr&gt;               &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;         \n1 PEIRCE VIEW              557 Upper…              1          113 Strata        \n2 FLORIDA PARK             54 Sunris…              1          312 Land          \n3 BULLION PARK             164 Lento…              1           75 Strata        \n4 CASTLE GREEN             483 Yio C…              1          107 Strata        \n5 HAPPY ESTATE             36 Thomso…              1          687 Land          \n6 TEACHER'S HOUSING ESTATE 148 Tagor…              1          228 Land          \n# ℹ 15 more variables: `Transacted Price ($)` &lt;dbl&gt;, `Nett Price($)` &lt;chr&gt;,\n#   `Unit Price ($ psm)` &lt;dbl&gt;, `Unit Price ($ psf)` &lt;dbl&gt;, `Sale Date` &lt;chr&gt;,\n#   `Property Type` &lt;chr&gt;, Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;,\n#   `Type of Sale` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal District` &lt;dbl&gt;, `Postal Sector` &lt;dbl&gt;, `Postal Code` &lt;dbl&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;\n\n\n\ncolnames(realis2019)\n\n [1] \"Project Name\"                \"Address\"                    \n [3] \"No. of Units\"                \"Area (sqm)\"                 \n [5] \"Type of Area\"                \"Transacted Price ($)\"       \n [7] \"Nett Price($)\"               \"Unit Price ($ psm)\"         \n [9] \"Unit Price ($ psf)\"          \"Sale Date\"                  \n[11] \"Property Type\"               \"Tenure\"                     \n[13] \"Completion Date\"             \"Type of Sale\"               \n[15] \"Purchaser Address Indicator\" \"Postal District\"            \n[17] \"Postal Sector\"               \"Postal Code\"                \n[19] \"Planning Region\"             \"Planning Area\"              \n\n\n\nrealis2019 &lt;- realis2019 %&gt;% \n  rename(\n    unit_psm = 'Unit Price ($ psm)',\n    unit_psf = 'Unit Price ($ psf)',\n    sale_date = 'Sale Date',\n    property_type = `Property Type`,\n    sale_type = `Type of Sale`,\n    planning_region = `Planning Region`,\n    planning_area = `Planning Area`,\n    trans_price = `Transacted Price ($)`\n      )\n\nChecking the transaction price across planning regions:\n\nggplot(data=realis2019, \n       aes(x= trans_price)) +\n  geom_histogram(bins=50) +\n  xlim (0, 5000000) +\n  facet_wrap(~ planning_region) +\n  labs(title=\"Histogram of Transacted Price across Planning Regions (up to $5M)\", y=\"Count\", x=\"Transacted Price ($)\")+\n  theme_minimal() +\n  theme(axis.text.x = element_text(size = 6))\n\n\n\n\n\n\n\n\n\nggplot(data=realis2019, \n       aes(x= unit_psm)) +\n  geom_histogram(bins=50) +\n  labs(title=\"Histogram of Unit Price (psf)\", y=\"Count\", x=\"Transacted Price ($)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nggplot(data=realis2019, \n       aes(x= unit_psm)) +\n  geom_histogram(bins=50) +\n  facet_wrap(~ planning_region) +\n  labs(title=\"Histogram of Unit Price (psf) across Planning Regions\", y=\"Count\", x=\"Transacted Price ($)\")+\n  theme_minimal() +\n  theme(axis.text.x = element_text(size = 8))\n\n\n\n\n\n\n\n\nTaking a look at the unit price (psf) across property types:\n\nggplot(data=realis2019, \n       aes(y = unit_psf, x= property_type)) +\n  geom_boxplot(colour =\"black\", fill=\"#88abff\", alpha=0.5) +\n  geom_point(stat=\"summary\",        \n             fun=mean,           \n             colour =\"darkblue\",          \n             size=2) +\n  theme_light() +\n  labs(title=\"Unit Price (psf) across Property Type\", y=\"Unit Price ($psf)\", x=\"Property Type\")\n\n\n\n\n\n\n\n\nand across planning regions:\n\nggplot(data=realis2019, \n       aes(y = unit_psf, x= planning_region)) +\n  geom_boxplot(colour =\"black\", fill=\"#88abff\", alpha=0.5) +\n  geom_point(stat=\"summary\",        \n             fun=mean,           \n             colour =\"darkblue\",          \n             size=2) +\n  theme_light() +\n  labs(title=\"Unit Price (psf) across Planning Region\", y=\"Unit Price ($psf)\", x=\"Planning Region\")"
  },
  {
    "objectID": "InClassEx/Ex01/inclassex01.html#loading-the-required-packages",
    "href": "InClassEx/Ex01/inclassex01.html#loading-the-required-packages",
    "title": "In Class Ex 01",
    "section": "",
    "text": "pacman::p_load(tidyverse)"
  },
  {
    "objectID": "InClassEx/Ex01/inclassex01.html#loading-the-data",
    "href": "InClassEx/Ex01/inclassex01.html#loading-the-data",
    "title": "In Class Ex 01",
    "section": "",
    "text": "Rmb to use read_csv instead or read.csv\nUsing read_csv will retain the field names as per the csv file.\n\nrealis2019 &lt;- read_csv(\"data/realis2019.csv\")"
  },
  {
    "objectID": "InClassEx/Ex01/inclassex01.html#some-visualisation",
    "href": "InClassEx/Ex01/inclassex01.html#some-visualisation",
    "title": "In Class Ex 01",
    "section": "",
    "text": "First - to take a look at the data:\n\nhead(realis2019)\n\n# A tibble: 6 × 20\n  `Project Name`           Address    `No. of Units` `Area (sqm)` `Type of Area`\n  &lt;chr&gt;                    &lt;chr&gt;               &lt;dbl&gt;        &lt;dbl&gt; &lt;chr&gt;         \n1 PEIRCE VIEW              557 Upper…              1          113 Strata        \n2 FLORIDA PARK             54 Sunris…              1          312 Land          \n3 BULLION PARK             164 Lento…              1           75 Strata        \n4 CASTLE GREEN             483 Yio C…              1          107 Strata        \n5 HAPPY ESTATE             36 Thomso…              1          687 Land          \n6 TEACHER'S HOUSING ESTATE 148 Tagor…              1          228 Land          \n# ℹ 15 more variables: `Transacted Price ($)` &lt;dbl&gt;, `Nett Price($)` &lt;chr&gt;,\n#   `Unit Price ($ psm)` &lt;dbl&gt;, `Unit Price ($ psf)` &lt;dbl&gt;, `Sale Date` &lt;chr&gt;,\n#   `Property Type` &lt;chr&gt;, Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;,\n#   `Type of Sale` &lt;chr&gt;, `Purchaser Address Indicator` &lt;chr&gt;,\n#   `Postal District` &lt;dbl&gt;, `Postal Sector` &lt;dbl&gt;, `Postal Code` &lt;dbl&gt;,\n#   `Planning Region` &lt;chr&gt;, `Planning Area` &lt;chr&gt;\n\n\n\ncolnames(realis2019)\n\n [1] \"Project Name\"                \"Address\"                    \n [3] \"No. of Units\"                \"Area (sqm)\"                 \n [5] \"Type of Area\"                \"Transacted Price ($)\"       \n [7] \"Nett Price($)\"               \"Unit Price ($ psm)\"         \n [9] \"Unit Price ($ psf)\"          \"Sale Date\"                  \n[11] \"Property Type\"               \"Tenure\"                     \n[13] \"Completion Date\"             \"Type of Sale\"               \n[15] \"Purchaser Address Indicator\" \"Postal District\"            \n[17] \"Postal Sector\"               \"Postal Code\"                \n[19] \"Planning Region\"             \"Planning Area\"              \n\n\n\nrealis2019 &lt;- realis2019 %&gt;% \n  rename(\n    unit_psm = 'Unit Price ($ psm)',\n    unit_psf = 'Unit Price ($ psf)',\n    sale_date = 'Sale Date',\n    property_type = `Property Type`,\n    sale_type = `Type of Sale`,\n    planning_region = `Planning Region`,\n    planning_area = `Planning Area`,\n    trans_price = `Transacted Price ($)`\n      )\n\nChecking the transaction price across planning regions:\n\nggplot(data=realis2019, \n       aes(x= trans_price)) +\n  geom_histogram(bins=50) +\n  xlim (0, 5000000) +\n  facet_wrap(~ planning_region) +\n  labs(title=\"Histogram of Transacted Price across Planning Regions (up to $5M)\", y=\"Count\", x=\"Transacted Price ($)\")+\n  theme_minimal() +\n  theme(axis.text.x = element_text(size = 6))\n\n\n\n\n\n\n\n\n\nggplot(data=realis2019, \n       aes(x= unit_psm)) +\n  geom_histogram(bins=50) +\n  labs(title=\"Histogram of Unit Price (psf)\", y=\"Count\", x=\"Transacted Price ($)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nggplot(data=realis2019, \n       aes(x= unit_psm)) +\n  geom_histogram(bins=50) +\n  facet_wrap(~ planning_region) +\n  labs(title=\"Histogram of Unit Price (psf) across Planning Regions\", y=\"Count\", x=\"Transacted Price ($)\")+\n  theme_minimal() +\n  theme(axis.text.x = element_text(size = 8))\n\n\n\n\n\n\n\n\nTaking a look at the unit price (psf) across property types:\n\nggplot(data=realis2019, \n       aes(y = unit_psf, x= property_type)) +\n  geom_boxplot(colour =\"black\", fill=\"#88abff\", alpha=0.5) +\n  geom_point(stat=\"summary\",        \n             fun=mean,           \n             colour =\"darkblue\",          \n             size=2) +\n  theme_light() +\n  labs(title=\"Unit Price (psf) across Property Type\", y=\"Unit Price ($psf)\", x=\"Property Type\")\n\n\n\n\n\n\n\n\nand across planning regions:\n\nggplot(data=realis2019, \n       aes(y = unit_psf, x= planning_region)) +\n  geom_boxplot(colour =\"black\", fill=\"#88abff\", alpha=0.5) +\n  geom_point(stat=\"summary\",        \n             fun=mean,           \n             colour =\"darkblue\",          \n             size=2) +\n  theme_light() +\n  labs(title=\"Unit Price (psf) across Planning Region\", y=\"Unit Price ($psf)\", x=\"Planning Region\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx7/handsonex7.html",
    "href": "HandsOnEx/HandsOnEx7/handsonex7.html",
    "title": "Hands On Ex 7 - Time Oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise, we will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart\n\n\n\nInstall and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, tidyverse, CGPfunctions, ggHoriPlot)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx7/handsonex7.html#importing-the-packages",
    "href": "HandsOnEx/HandsOnEx7/handsonex7.html#importing-the-packages",
    "title": "Hands On Ex 7 - Time Oriented Data",
    "section": "",
    "text": "Install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, tidyverse, CGPfunctions, ggHoriPlot)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx7/handsonex7.html#data",
    "href": "HandsOnEx/HandsOnEx7/handsonex7.html#data",
    "title": "Hands On Ex 7 - Time Oriented Data",
    "section": "2.1 Data",
    "text": "2.1 Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx7/handsonex7.html#examining-the-data-structure",
    "href": "HandsOnEx/HandsOnEx7/handsonex7.html#examining-the-data-structure",
    "title": "Hands On Ex 7 - Time Oriented Data",
    "section": "2.2 Examining the Data Structure",
    "text": "2.2 Examining the Data Structure\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx7/handsonex7.html#data-preparation",
    "href": "HandsOnEx/HandsOnEx7/handsonex7.html#data-preparation",
    "title": "Hands On Ex 7 - Time Oriented Data",
    "section": "2.4 Data Preparation",
    "text": "2.4 Data Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', 'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', 'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx7/handsonex7.html#building-the-heatmap",
    "href": "HandsOnEx/HandsOnEx7/handsonex7.html#building-the-heatmap",
    "title": "Hands On Ex 7 - Time Oriented Data",
    "section": "2.5 Building the Heatmap",
    "text": "2.5 Building the Heatmap\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_minimal() + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"azure2\", \n                    high = \"deepskyblue4\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx7/handsonex7.html#building-multiple-heatmaps",
    "href": "HandsOnEx/HandsOnEx7/handsonex7.html#building-multiple-heatmaps",
    "title": "Hands On Ex 7 - Time Oriented Data",
    "section": "2.6 Building multiple heatmaps",
    "text": "2.6 Building multiple heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_minimal() + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"azure2\", \n                    high = \"deepskyblue4\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 5),\n        axis.text.y = element_text(size = 5),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 5),\n        legend.text = element_text(size = 5) )"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx7/handsonex7.html#data-1",
    "href": "HandsOnEx/HandsOnEx7/handsonex7.html#data-1",
    "title": "Hands On Ex 7 - Time Oriented Data",
    "section": "3.1 Data",
    "text": "3.1 Data\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx7/handsonex7.html#data-preparation-1",
    "href": "HandsOnEx/HandsOnEx7/handsonex7.html#data-preparation-1",
    "title": "Hands On Ex 7 - Time Oriented Data",
    "section": "3.2 Data Preparation",
    "text": "3.2 Data Preparation\nDeriving the month and year field:\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\nExtracting the target country.\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx7/handsonex7.html#plotting",
    "href": "HandsOnEx/HandsOnEx7/handsonex7.html#plotting",
    "title": "Hands On Ex 7 - Time Oriented Data",
    "section": "3.3 Plotting",
    "text": "3.3 Plotting\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_grey() +\n  theme(axis.text.x = element_blank())"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx7/handsonex7.html#data-2",
    "href": "HandsOnEx/HandsOnEx7/handsonex7.html#data-2",
    "title": "Hands On Ex 7 - Time Oriented Data",
    "section": "4.1 Data",
    "text": "4.1 Data\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\nkable(rice)\n\n\n\n\nCountry\nYear\nYield\nProduction\n\n\n\n\nChina\n1961\n20787\n56217601\n\n\nChina\n1962\n23700\n65675288\n\n\nChina\n1963\n26833\n76439280\n\n\nChina\n1964\n28289\n85853780\n\n\nChina\n1965\n29667\n90705630\n\n\nChina\n1966\n31445\n98403990\n\n\nChina\n1967\n31006\n96734816\n\n\nChina\n1968\n31868\n97716767\n\n\nChina\n1969\n31415\n97998492\n\n\nChina\n1970\n34162\n113101869\n\n\nChina\n1971\n33145\n118129210\n\n\nChina\n1972\n32475\n116428562\n\n\nChina\n1973\n34818\n124584090\n\n\nChina\n1974\n35033\n127010740\n\n\nChina\n1975\n35283\n128726270\n\n\nChina\n1976\n34957\n129231900\n\n\nChina\n1977\n36373\n131917520\n\n\nChina\n1978\n39809\n140023850\n\n\nChina\n1979\n42491\n146846140\n\n\nChina\n1980\n41435\n142876520\n\n\nChina\n1981\n43315\n146959840\n\n\nChina\n1982\n48888\n164741380\n\n\nChina\n1983\n50918\n172008862\n\n\nChina\n1984\n53634\n181095744\n\n\nChina\n1985\n52498\n171318865\n\n\nChina\n1986\n53272\n174720521\n\n\nChina\n1987\n54035\n176662485\n\n\nChina\n1988\n52819\n171441923\n\n\nChina\n1989\n55005\n182485243\n\n\nChina\n1990\n57166\n191614672\n\n\nChina\n1991\n56238\n185692640\n\n\nChina\n1992\n57959\n188291880\n\n\nChina\n1993\n58462\n179746930\n\n\nChina\n1994\n58288\n177994400\n\n\nChina\n1995\n60210\n187297970\n\n\nChina\n1996\n62050\n197032900\n\n\nChina\n1997\n63111\n202771840\n\n\nChina\n1998\n63529\n200571160\n\n\nChina\n1999\n63344\n200403300\n\n\nChina\n2000\n62642\n189814060\n\n\nChina\n2001\n61524\n179304900\n\n\nChina\n2002\n61855\n176342190\n\n\nChina\n2003\n60606\n162304280\n\n\nChina\n2004\n63085\n180522610\n\n\nChina\n2005\n62527\n182055140\n\n\nChina\n2006\n62763\n183276050\n\n\nChina\n2007\n64223\n187397460\n\n\nChina\n2008\n65535\n193284180\n\n\nChina\n2009\n65820\n196681170\n\n\nChina\n2010\n65482\n197212010\n\n\nIndia\n1961\n15419\n53494500\n\n\nIndia\n1962\n13959\n49825600\n\n\nIndia\n1963\n15498\n55497000\n\n\nIndia\n1964\n16171\n58962000\n\n\nIndia\n1965\n12936\n45883500\n\n\nIndia\n1966\n12952\n45657000\n\n\nIndia\n1967\n15484\n56418300\n\n\nIndia\n1968\n16134\n59641800\n\n\nIndia\n1969\n16094\n60644500\n\n\nIndia\n1970\n16849\n63337800\n\n\nIndia\n1971\n17110\n64602000\n\n\nIndia\n1972\n16046\n58868000\n\n\nIndia\n1973\n17259\n66077000\n\n\nIndia\n1974\n15744\n59650000\n\n\nIndia\n1975\n18582\n73352000\n\n\nIndia\n1976\n16372\n63051900\n\n\nIndia\n1977\n19613\n79005600\n\n\nIndia\n1978\n19912\n80608500\n\n\nIndia\n1979\n16105\n63475700\n\n\nIndia\n1980\n20002\n80312000\n\n\nIndia\n1981\n19623\n79883000\n\n\nIndia\n1982\n18497\n70771700\n\n\nIndia\n1983\n21833\n90048000\n\n\nIndia\n1984\n21272\n87552800\n\n\nIndia\n1985\n23292\n95817700\n\n\nIndia\n1986\n22052\n90779400\n\n\nIndia\n1987\n21991\n85338700\n\n\nIndia\n1988\n25486\n106369000\n\n\nIndia\n1989\n26161\n110311000\n\n\nIndia\n1990\n26125\n111517000\n\n\nIndia\n1991\n26271\n112042000\n\n\nIndia\n1992\n26092\n109001000\n\n\nIndia\n1993\n28303\n120400000\n\n\nIndia\n1994\n28645\n122640000\n\n\nIndia\n1995\n26972\n115440000\n\n\nIndia\n1996\n28226\n122500000\n\n\nIndia\n1997\n28457\n123700000\n\n\nIndia\n1998\n28805\n129055000\n\n\nIndia\n1999\n29782\n134496000\n\n\nIndia\n2000\n28508\n127465000\n\n\nIndia\n2001\n31158\n139900000\n\n\nIndia\n2002\n26163\n107730000\n\n\nIndia\n2003\n31177\n132789000\n\n\nIndia\n2004\n29756\n124697000\n\n\nIndia\n2005\n31537\n137690000\n\n\nIndia\n2006\n31759\n139137000\n\n\nIndia\n2007\n32924\n144570000\n\n\nIndia\n2008\n34169\n148770000\n\n\nIndia\n2009\n31947\n133700000\n\n\nIndia\n2010\n32644\n120620000\n\n\nIndonesia\n1961\n17623\n12084000\n\n\nIndonesia\n1962\n17855\n13004000\n\n\nIndonesia\n1963\n17226\n11595000\n\n\nIndonesia\n1964\n17630\n12306000\n\n\nIndonesia\n1965\n17708\n12975000\n\n\nIndonesia\n1966\n17748\n13650000\n\n\nIndonesia\n1967\n17592\n13222000\n\n\nIndonesia\n1968\n21398\n17162800\n\n\nIndonesia\n1969\n22487\n18020200\n\n\nIndonesia\n1970\n23763\n19331000\n\n\nIndonesia\n1971\n24254\n20190000\n\n\nIndonesia\n1972\n24556\n19393600\n\n\nIndonesia\n1973\n25572\n21489500\n\n\nIndonesia\n1974\n26412\n22473000\n\n\nIndonesia\n1975\n26297\n22339200\n\n\nIndonesia\n1976\n27843\n23300900\n\n\nIndonesia\n1977\n27929\n23347100\n\n\nIndonesia\n1978\n28862\n25771600\n\n\nIndonesia\n1979\n29855\n26282700\n\n\nIndonesia\n1980\n32928\n29651900\n\n\nIndonesia\n1981\n34934\n32774200\n\n\nIndonesia\n1982\n37363\n33583700\n\n\nIndonesia\n1983\n38530\n35303000\n\n\nIndonesia\n1984\n39060\n38136400\n\n\nIndonesia\n1985\n39418\n39032900\n\n\nIndonesia\n1986\n39773\n39726800\n\n\nIndonesia\n1987\n40391\n40078200\n\n\nIndonesia\n1988\n41108\n41676200\n\n\nIndonesia\n1989\n42470\n44725600\n\n\nIndonesia\n1990\n43018\n45178800\n\n\nIndonesia\n1991\n43465\n44688200\n\n\nIndonesia\n1992\n43447\n48240000\n\n\nIndonesia\n1993\n43750\n48181100\n\n\nIndonesia\n1994\n43453\n46641500\n\n\nIndonesia\n1995\n43487\n49744100\n\n\nIndonesia\n1996\n44168\n51101500\n\n\nIndonesia\n1997\n44322\n49377100\n\n\nIndonesia\n1998\n41974\n49236700\n\n\nIndonesia\n1999\n42519\n50866400\n\n\nIndonesia\n2000\n44007\n51898000\n\n\nIndonesia\n2001\n43879\n50460800\n\n\nIndonesia\n2002\n44691\n51489700\n\n\nIndonesia\n2003\n45426\n52137600\n\n\nIndonesia\n2004\n45365\n54088500\n\n\nIndonesia\n2005\n45739\n54151100\n\n\nIndonesia\n2006\n46201\n54454900\n\n\nIndonesia\n2007\n47052\n57157400\n\n\nIndonesia\n2008\n48948\n60251100\n\n\nIndonesia\n2009\n49985\n64398900\n\n\nIndonesia\n2010\n50144\n66411500\n\n\nJapan\n1961\n48793\n16160400\n\n\nJapan\n1962\n51372\n16927100\n\n\nJapan\n1963\n50821\n16648800\n\n\nJapan\n1964\n50111\n16356100\n\n\nJapan\n1965\n49489\n16126100\n\n\nJapan\n1966\n50841\n16564000\n\n\nJapan\n1967\n57490\n18782000\n\n\nJapan\n1968\n57183\n18779000\n\n\nJapan\n1969\n55505\n18200000\n\n\nJapan\n1970\n56348\n16493000\n\n\nJapan\n1971\n52439\n14148000\n\n\nJapan\n1972\n58458\n15450500\n\n\nJapan\n1973\n60175\n15778000\n\n\nJapan\n1974\n58605\n15964000\n\n\nJapan\n1975\n61856\n17097000\n\n\nJapan\n1976\n55013\n15288000\n\n\nJapan\n1977\n61683\n17006000\n\n\nJapan\n1978\n61758\n15736000\n\n\nJapan\n1979\n59864\n14948000\n\n\nJapan\n1980\n51279\n12189000\n\n\nJapan\n1981\n56295\n12824000\n\n\nJapan\n1982\n56881\n12838000\n\n\nJapan\n1983\n57008\n12958000\n\n\nJapan\n1984\n64138\n14848000\n\n\nJapan\n1985\n62246\n14578000\n\n\nJapan\n1986\n63218\n14559000\n\n\nJapan\n1987\n61901\n13284000\n\n\nJapan\n1988\n58858\n12419000\n\n\nJapan\n1989\n61679\n12934000\n\n\nJapan\n1990\n63279\n13124000\n\n\nJapan\n1991\n58590\n12005000\n\n\nJapan\n1992\n62754\n13216000\n\n\nJapan\n1993\n45783\n9793000\n\n\nJapan\n1994\n67703\n14976000\n\n\nJapan\n1995\n63432\n13435000\n\n\nJapan\n1996\n65402\n12930000\n\n\nJapan\n1997\n64163\n12531000\n\n\nJapan\n1998\n62188\n11200000\n\n\nJapan\n1999\n64143\n11468800\n\n\nJapan\n2000\n67023\n11863000\n\n\nJapan\n2001\n66354\n11320000\n\n\nJapan\n2002\n65823\n11111000\n\n\nJapan\n2003\n58499\n9740000\n\n\nJapan\n2004\n64151\n10912000\n\n\nJapan\n2005\n66483\n11342000\n\n\nJapan\n2006\n63359\n10695000\n\n\nJapan\n2007\n65111\n10893000\n\n\nJapan\n2008\n67786\n11028800\n\n\nJapan\n2009\n65209\n10590000\n\n\nJapan\n2010\n65111\n10600000\n\n\nKorea\n1961\n41481\n4679000\n\n\nKorea\n1962\n35768\n4074000\n\n\nKorea\n1963\n43974\n5079000\n\n\nKorea\n1964\n44720\n5344000\n\n\nKorea\n1965\n39634\n4867000\n\n\nKorea\n1966\n44257\n5448000\n\n\nKorea\n1967\n40551\n5008000\n\n\nKorea\n1968\n38593\n4442000\n\n\nKorea\n1969\n46623\n5688000\n\n\nKorea\n1970\n45520\n5476000\n\n\nKorea\n1971\n46697\n5557000\n\n\nKorea\n1972\n46146\n5496000\n\n\nKorea\n1973\n49504\n5850000\n\n\nKorea\n1974\n51257\n6174000\n\n\nKorea\n1975\n53243\n6485000\n\n\nKorea\n1976\n59667\n7249000\n\n\nKorea\n1977\n67868\n8348000\n\n\nKorea\n1978\n69380\n8532000\n\n\nKorea\n1979\n63905\n7880940\n\n\nKorea\n1980\n43076\n5311410\n\n\nKorea\n1981\n58410\n7148700\n\n\nKorea\n1982\n61510\n7307860\n\n\nKorea\n1983\n61926\n7607540\n\n\nKorea\n1984\n64754\n7970330\n\n\nKorea\n1985\n63514\n7855260\n\n\nKorea\n1986\n63688\n7871370\n\n\nKorea\n1987\n60173\n7595760\n\n\nKorea\n1988\n65550\n8260160\n\n\nKorea\n1989\n64456\n8099950\n\n\nKorea\n1990\n62057\n7721970\n\n\nKorea\n1991\n60346\n7292530\n\n\nKorea\n1992\n63120\n7303000\n\n\nKorea\n1993\n57330\n6507000\n\n\nKorea\n1994\n62393\n6882000\n\n\nKorea\n1995\n60524\n6387300\n\n\nKorea\n1996\n67888\n7121420\n\n\nKorea\n1997\n69529\n7312100\n\n\nKorea\n1998\n64169\n6779290\n\n\nKorea\n1999\n65961\n7032760\n\n\nKorea\n2000\n67110\n7196580\n\n\nKorea\n2001\n68381\n7406520\n\n\nKorea\n2002\n63495\n6687230\n\n\nKorea\n2003\n59201\n6015000\n\n\nKorea\n2004\n67291\n6736930\n\n\nKorea\n2005\n65682\n6435000\n\n\nKorea\n2006\n67114\n6410950\n\n\nKorea\n2007\n63541\n6038000\n\n\nKorea\n2008\n73942\n6919250\n\n\nKorea\n2009\n75967\n7022970\n\n\nKorea\n2010\n65062\n5804000\n\n\nMalaysia\n1961\n21086\n1089080\n\n\nMalaysia\n1962\n20678\n1125340\n\n\nMalaysia\n1963\n21525\n1190210\n\n\nMalaysia\n1964\n19968\n1109780\n\n\nMalaysia\n1965\n21578\n1255610\n\n\nMalaysia\n1966\n21408\n1226680\n\n\nMalaysia\n1967\n20165\n1205070\n\n\nMalaysia\n1968\n21714\n1433950\n\n\nMalaysia\n1969\n23246\n1590600\n\n\nMalaysia\n1970\n23858\n1681420\n\n\nMalaysia\n1971\n24736\n1816920\n\n\nMalaysia\n1972\n23980\n1837320\n\n\nMalaysia\n1973\n26342\n1979940\n\n\nMalaysia\n1974\n28311\n2095000\n\n\nMalaysia\n1975\n26615\n1997000\n\n\nMalaysia\n1976\n27217\n1995000\n\n\nMalaysia\n1977\n26252\n1898000\n\n\nMalaysia\n1978\n25695\n1498000\n\n\nMalaysia\n1979\n28388\n2095000\n\n\nMalaysia\n1980\n28524\n2044600\n\n\nMalaysia\n1981\n28409\n2019900\n\n\nMalaysia\n1982\n27619\n1883600\n\n\nMalaysia\n1983\n26041\n1734330\n\n\nMalaysia\n1984\n25187\n1571670\n\n\nMalaysia\n1985\n26648\n1745370\n\n\nMalaysia\n1986\n26399\n1718220\n\n\nMalaysia\n1987\n24686\n1626700\n\n\nMalaysia\n1988\n25251\n1696240\n\n\nMalaysia\n1989\n26251\n1743440\n\n\nMalaysia\n1990\n27694\n1884980\n\n\nMalaysia\n1991\n28178\n1926350\n\n\nMalaysia\n1992\n29918\n2012730\n\n\nMalaysia\n1993\n30348\n2104450\n\n\nMalaysia\n1994\n30614\n2138790\n\n\nMalaysia\n1995\n31619\n2127270\n\n\nMalaysia\n1996\n32510\n2228490\n\n\nMalaysia\n1997\n30676\n2119620\n\n\nMalaysia\n1998\n28829\n1944240\n\n\nMalaysia\n1999\n29415\n2036640\n\n\nMalaysia\n2000\n30640\n2140800\n\n\nMalaysia\n2001\n31102\n2095000\n\n\nMalaysia\n2002\n32385\n2197350\n\n\nMalaysia\n2003\n33596\n2257000\n\n\nMalaysia\n2004\n33260\n2264000\n\n\nMalaysia\n2005\n34221\n2314000\n\n\nMalaysia\n2006\n33907\n2187000\n\n\nMalaysia\n2007\n35277\n2375000\n\n\nMalaysia\n2008\n35836\n2353000\n\n\nMalaysia\n2009\n36591\n2460000\n\n\nMalaysia\n2010\n37818\n2548000\n\n\nMyanmar\n1961\n16066\n6834100\n\n\nMyanmar\n1962\n16469\n7664700\n\n\nMyanmar\n1963\n15957\n7782900\n\n\nMyanmar\n1964\n17097\n8507700\n\n\nMyanmar\n1965\n16614\n8055100\n\n\nMyanmar\n1966\n14694\n6636400\n\n\nMyanmar\n1967\n16510\n7769400\n\n\nMyanmar\n1968\n16843\n8022900\n\n\nMyanmar\n1969\n17092\n7984700\n\n\nMyanmar\n1970\n16973\n8161900\n\n\nMyanmar\n1971\n17161\n8175000\n\n\nMyanmar\n1972\n16247\n7356800\n\n\nMyanmar\n1973\n17629\n8601900\n\n\nMyanmar\n1974\n17574\n8583400\n\n\nMyanmar\n1975\n18307\n9207700\n\n\nMyanmar\n1976\n18974\n9319300\n\n\nMyanmar\n1977\n19453\n9462000\n\n\nMyanmar\n1978\n21012\n10528300\n\n\nMyanmar\n1979\n23521\n10447900\n\n\nMyanmar\n1980\n27739\n13317400\n\n\nMyanmar\n1981\n29419\n14146600\n\n\nMyanmar\n1982\n31505\n14373400\n\n\nMyanmar\n1983\n30666\n14288100\n\n\nMyanmar\n1984\n30981\n14255500\n\n\nMyanmar\n1985\n30718\n14317000\n\n\nMyanmar\n1986\n30279\n14127100\n\n\nMyanmar\n1987\n30424\n13638400\n\n\nMyanmar\n1988\n29084\n13167100\n\n\nMyanmar\n1989\n29174\n13806500\n\n\nMyanmar\n1990\n29353\n13971800\n\n\nMyanmar\n1991\n28862\n13204200\n\n\nMyanmar\n1992\n29351\n14840400\n\n\nMyanmar\n1993\n30552\n16763200\n\n\nMyanmar\n1994\n31690\n18198900\n\n\nMyanmar\n1995\n29766\n17956900\n\n\nMyanmar\n1996\n30649\n17679800\n\n\nMyanmar\n1997\n30789\n16651400\n\n\nMyanmar\n1998\n31286\n17077700\n\n\nMyanmar\n1999\n32405\n20126000\n\n\nMyanmar\n2000\n33834\n21323900\n\n\nMyanmar\n2001\n34177\n21916000\n\n\nMyanmar\n2002\n34172\n21805000\n\n\nMyanmar\n2003\n35457\n23146300\n\n\nMyanmar\n2004\n38175\n24939000\n\n\nMyanmar\n2005\n37491\n27683000\n\n\nMyanmar\n2006\n38301\n30924000\n\n\nMyanmar\n2007\n39260\n31451000\n\n\nMyanmar\n2008\n40323\n32573000\n\n\nMyanmar\n2009\n40853\n32682000\n\n\nMyanmar\n2010\n41239\n33204500\n\n\nPhilippines\n1961\n12299\n3910100\n\n\nPhilippines\n1962\n12548\n3966980\n\n\nPhilippines\n1963\n12447\n3842860\n\n\nPhilippines\n1964\n12478\n3992400\n\n\nPhilippines\n1965\n13099\n4072640\n\n\nPhilippines\n1966\n13223\n4094020\n\n\nPhilippines\n1967\n13804\n4560700\n\n\nPhilippines\n1968\n13339\n4444660\n\n\nPhilippines\n1969\n17098\n5464080\n\n\nPhilippines\n1970\n17460\n5578410\n\n\nPhilippines\n1971\n15980\n5324880\n\n\nPhilippines\n1972\n14431\n4609510\n\n\nPhilippines\n1973\n14624\n5158900\n\n\nPhilippines\n1974\n15458\n5615270\n\n\nPhilippines\n1975\n16636\n6112040\n\n\nPhilippines\n1976\n17967\n6542610\n\n\nPhilippines\n1977\n20142\n7254390\n\n\nPhilippines\n1978\n20253\n7211620\n\n\nPhilippines\n1979\n21131\n7684800\n\n\nPhilippines\n1980\n22105\n7646490\n\n\nPhilippines\n1981\n22977\n7910740\n\n\nPhilippines\n1982\n26342\n8533730\n\n\nPhilippines\n1983\n23227\n7294910\n\n\nPhilippines\n1984\n24300\n7828880\n\n\nPhilippines\n1985\n25879\n8805600\n\n\nPhilippines\n1986\n27173\n9246790\n\n\nPhilippines\n1987\n26229\n8539850\n\n\nPhilippines\n1988\n26442\n8970920\n\n\nPhilippines\n1989\n27046\n9458770\n\n\nPhilippines\n1990\n29786\n9885000\n\n\nPhilippines\n1991\n28243\n9673260\n\n\nPhilippines\n1992\n29388\n9513000\n\n\nPhilippines\n1993\n28742\n9434210\n\n\nPhilippines\n1994\n28866\n10540600\n\n\nPhilippines\n1995\n28043\n10540600\n\n\nPhilippines\n1996\n28558\n11283600\n\n\nPhilippines\n1997\n29326\n11268000\n\n\nPhilippines\n1998\n26984\n8554000\n\n\nPhilippines\n1999\n29468\n11786600\n\n\nPhilippines\n2000\n30681\n12389400\n\n\nPhilippines\n2001\n31866\n12954900\n\n\nPhilippines\n2002\n32797\n13270700\n\n\nPhilippines\n2003\n33696\n13499900\n\n\nPhilippines\n2004\n35130\n14496800\n\n\nPhilippines\n2005\n35876\n14603000\n\n\nPhilippines\n2006\n36844\n15326700\n\n\nPhilippines\n2007\n38008\n16240200\n\n\nPhilippines\n2008\n37703\n16815500\n\n\nPhilippines\n2009\n35890\n16266400\n\n\nPhilippines\n2010\n36222\n15771700\n\n\nSriLanka\n1961\n18626\n923024\n\n\nSriLanka\n1962\n19539\n1029190\n\n\nSriLanka\n1963\n19547\n1045910\n\n\nSriLanka\n1964\n19962\n1074050\n\n\nSriLanka\n1965\n17696\n764158\n\n\nSriLanka\n1966\n18365\n980746\n\n\nSriLanka\n1967\n21259\n1158150\n\n\nSriLanka\n1968\n23968\n1359540\n\n\nSriLanka\n1969\n25654\n1375960\n\n\nSriLanka\n1970\n22485\n1615930\n\n\nSriLanka\n1971\n20119\n1395780\n\n\nSriLanka\n1972\n20540\n1312450\n\n\nSriLanka\n1973\n19539\n1312420\n\n\nSriLanka\n1974\n20104\n1602310\n\n\nSriLanka\n1975\n19325\n1154160\n\n\nSriLanka\n1976\n19712\n1252620\n\n\nSriLanka\n1977\n21441\n1677290\n\n\nSriLanka\n1978\n22521\n1890490\n\n\nSriLanka\n1979\n24282\n1917220\n\n\nSriLanka\n1980\n25897\n2133200\n\n\nSriLanka\n1981\n26462\n2229350\n\n\nSriLanka\n1982\n28896\n2155630\n\n\nSriLanka\n1983\n31977\n2483530\n\n\nSriLanka\n1984\n27316\n2419700\n\n\nSriLanka\n1985\n30777\n2661210\n\n\nSriLanka\n1986\n30944\n2588180\n\n\nSriLanka\n1987\n31318\n2127830\n\n\nSriLanka\n1988\n30367\n2476610\n\n\nSriLanka\n1989\n29916\n2063440\n\n\nSriLanka\n1990\n30643\n2538000\n\n\nSriLanka\n1991\n30215\n2389000\n\n\nSriLanka\n1992\n30544\n2339700\n\n\nSriLanka\n1993\n31350\n2570000\n\n\nSriLanka\n1994\n29933\n2683690\n\n\nSriLanka\n1995\n31586\n2809890\n\n\nSriLanka\n1996\n31231\n2061520\n\n\nSriLanka\n1997\n32451\n2239370\n\n\nSriLanka\n1998\n35102\n2692340\n\n\nSriLanka\n1999\n32810\n2857100\n\n\nSriLanka\n2000\n34374\n2859900\n\n\nSriLanka\n2001\n35228\n2695080\n\n\nSriLanka\n2002\n34889\n2859480\n\n\nSriLanka\n2003\n33696\n3071200\n\n\nSriLanka\n2004\n36516\n2628000\n\n\nSriLanka\n2005\n35465\n3246000\n\n\nSriLanka\n2006\n36705\n3342000\n\n\nSriLanka\n2007\n38337\n3131000\n\n\nSriLanka\n2008\n36800\n3875000\n\n\nSriLanka\n2009\n37374\n3652000\n\n\nSriLanka\n2010\n40558\n4300620\n\n\nThailand\n1961\n16585\n10150000\n\n\nThailand\n1962\n17202\n11250000\n\n\nThailand\n1963\n18725\n12171000\n\n\nThailand\n1964\n18384\n11600000\n\n\nThailand\n1965\n17805\n11164000\n\n\nThailand\n1966\n18360\n13500000\n\n\nThailand\n1967\n17497\n11198000\n\n\nThailand\n1968\n17882\n12410000\n\n\nThailand\n1969\n18474\n13410000\n\n\nThailand\n1970\n20207\n13850000\n\n\nThailand\n1971\n19369\n13744000\n\n\nThailand\n1972\n18308\n12413000\n\n\nThailand\n1973\n19242\n14899000\n\n\nThailand\n1974\n18254\n13386000\n\n\nThailand\n1975\n18308\n15300000\n\n\nThailand\n1976\n18450\n15068000\n\n\nThailand\n1977\n15910\n13921000\n\n\nThailand\n1978\n19552\n17470000\n\n\nThailand\n1979\n18209\n15758000\n\n\nThailand\n1980\n18878\n17368100\n\n\nThailand\n1981\n19521\n17774300\n\n\nThailand\n1982\n18880\n16878500\n\n\nThailand\n1983\n20351\n19548900\n\n\nThailand\n1984\n20670\n19904800\n\n\nThailand\n1985\n20608\n20263900\n\n\nThailand\n1986\n20522\n18868200\n\n\nThailand\n1987\n20147\n18428300\n\n\nThailand\n1988\n21465\n21262900\n\n\nThailand\n1989\n20853\n20601000\n\n\nThailand\n1990\n19556\n17193200\n\n\nThailand\n1991\n22534\n20400000\n\n\nThailand\n1992\n21744\n19917000\n\n\nThailand\n1993\n21700\n19530000\n\n\nThailand\n1994\n23521\n21111000\n\n\nThailand\n1995\n24158\n22015500\n\n\nThailand\n1996\n24097\n22331600\n\n\nThailand\n1997\n23787\n23580000\n\n\nThailand\n1998\n24654\n23450000\n\n\nThailand\n1999\n24245\n24172000\n\n\nThailand\n2000\n26128\n25843900\n\n\nThailand\n2001\n27687\n28033700\n\n\nThailand\n2002\n28996\n27991800\n\n\nThailand\n2003\n28998\n29473500\n\n\nThailand\n2004\n28559\n28538200\n\n\nThailand\n2005\n29625\n30291900\n\n\nThailand\n2006\n29160\n29641900\n\n\nThailand\n2007\n30087\n32099400\n\n\nThailand\n2008\n29626\n31650600\n\n\nThailand\n2009\n28826\n32116100\n\n\nThailand\n2010\n28751\n31597200\n\n\nVietNam\n1961\n18966\n8997400\n\n\nVietNam\n1962\n19937\n9747040\n\n\nVietNam\n1963\n21400\n9622670\n\n\nVietNam\n1964\n19442\n9697030\n\n\nVietNam\n1965\n19414\n9369700\n\n\nVietNam\n1966\n18079\n8463500\n\n\nVietNam\n1967\n19159\n9188400\n\n\nVietNam\n1968\n17095\n8366150\n\n\nVietNam\n1969\n17880\n8815000\n\n\nVietNam\n1970\n21534\n10173300\n\n\nVietNam\n1971\n22265\n10447000\n\n\nVietNam\n1972\n21935\n10748200\n\n\nVietNam\n1973\n22117\n11125000\n\n\nVietNam\n1974\n21564\n11023300\n\n\nVietNam\n1975\n21198\n10293600\n\n\nVietNam\n1976\n22327\n11827200\n\n\nVietNam\n1977\n19378\n10597100\n\n\nVietNam\n1978\n17922\n9789900\n\n\nVietNam\n1979\n20716\n11362900\n\n\nVietNam\n1980\n20798\n11647400\n\n\nVietNam\n1981\n21966\n12415200\n\n\nVietNam\n1982\n25194\n14390200\n\n\nVietNam\n1983\n26272\n14743300\n\n\nVietNam\n1984\n27323\n15505600\n\n\nVietNam\n1985\n27761\n15874800\n\n\nVietNam\n1986\n28060\n16002900\n\n\nVietNam\n1987\n26954\n15102600\n\n\nVietNam\n1988\n29613\n17000000\n\n\nVietNam\n1989\n32136\n18996300\n\n\nVietNam\n1990\n31815\n19225100\n\n\nVietNam\n1991\n31133\n19621900\n\n\nVietNam\n1992\n33342\n21590300\n\n\nVietNam\n1993\n34815\n22836600\n\n\nVietNam\n1994\n35657\n23528300\n\n\nVietNam\n1995\n36898\n24963700\n\n\nVietNam\n1996\n37689\n26396700\n\n\nVietNam\n1997\n38768\n27523900\n\n\nVietNam\n1998\n39585\n29145500\n\n\nVietNam\n1999\n41018\n31393800\n\n\nVietNam\n2000\n42432\n32529500\n\n\nVietNam\n2001\n42853\n32108400\n\n\nVietNam\n2002\n45903\n34447200\n\n\nVietNam\n2003\n46387\n34568800\n\n\nVietNam\n2004\n48553\n36148900\n\n\nVietNam\n2005\n48891\n35832900\n\n\nVietNam\n2006\n48943\n35849500\n\n\nVietNam\n2007\n49869\n35942700\n\n\nVietNam\n2008\n52336\n38729800\n\n\nVietNam\n2009\n52372\n38950200\n\n\nVietNam\n2010\n53221\n39988900\n\n\n\n\n\nThe data comprise the country, year, yield and production."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx7/handsonex7.html#plotting-1",
    "href": "HandsOnEx/HandsOnEx7/handsonex7.html#plotting-1",
    "title": "Hands On Ex 7 - Time Oriented Data",
    "section": "4.2 Plotting",
    "text": "4.2 Plotting\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Plotting Slope Graph - Ref Dr Kam\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to visualise and analyse text data using R.\nBy the end of this hands-on exercise, we will be able to:\n\nunderstand tidytext framework for processing, analysing and visualising text data,\nwrite function for importing multiple files into R,\ncombine multiple files into a single data frame,\nclean and wrangle text data by using tidyverse approach,\nvisualise words with Word Cloud,\ncompute term frequency–inverse document frequency (TF-IDF) using tidytext method, and\nvisualising texts and terms relationship.\n\n\n\nIn this hands-on exercise, the following R packages for handling, processing, wrangling, analysing and visualising text data will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph, )\nDT,\nlubridate and hms.\n\n\npacman::p_load(tidytext, widyr, wordcloud, DT, ggwordcloud, textplot, lubridate, hms,tidyverse, tidygraph, ggraph, igraph)\n\n\n\n\nThe files are stored in a folder named 20news under data.\n\nnews20 &lt;- \"data/20news/\"\n\nDefining a function to read all files into a dataframe:\n\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder, \n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file, read_lines)) %&gt;%\n    transmute(id = basename(file), text) %&gt;%\n    unnest(text)\n}\n\nReading all the messages in the folder:\n\nraw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), id, text)\n\n\nwrite_rds(raw_text, \"data/rds/news20.rds\")\n\n\n\n\n\n\n\nNote\n\n\n\nread_lines() of readr package is used to read up to n_max lines from a file.\n\nmap() of purrr package is used to transform their input by applying a function to each element of a list and returning an object of the same length as the input.\nunnest() of dplyr package is used to flatten a list-column of data frames back out into regular columns.\nmutate() of dplyr is used to add new variables and preserves existing ones;\ntransmute() of dplyr is used to add new variables and drops existing ones.\nread_rds() is used to save the extracted and combined data frame as rds file for future use.\n\n\n\n\n\n\n\nraw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#installing-the-packages",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#installing-the-packages",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "",
    "text": "In this hands-on exercise, the following R packages for handling, processing, wrangling, analysing and visualising text data will be used:\n\ntidytext, tidyverse (mainly readr, purrr, stringr, ggplot2)\nwidyr,\nwordcloud and ggwordcloud,\ntextplot (required igraph, tidygraph and ggraph, )\nDT,\nlubridate and hms.\n\n\npacman::p_load(tidytext, widyr, wordcloud, DT, ggwordcloud, textplot, lubridate, hms,tidyverse, tidygraph, ggraph, igraph)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#importing-multiple-text-files",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#importing-multiple-text-files",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "",
    "text": "The files are stored in a folder named 20news under data.\n\nnews20 &lt;- \"data/20news/\"\n\nDefining a function to read all files into a dataframe:\n\nread_folder &lt;- function(infolder) {\n  tibble(file = dir(infolder, \n                    full.names = TRUE)) %&gt;%\n    mutate(text = map(file, read_lines)) %&gt;%\n    transmute(id = basename(file), text) %&gt;%\n    unnest(text)\n}\n\nReading all the messages in the folder:\n\nraw_text &lt;- tibble(folder = \n                     dir(news20, \n                         full.names = TRUE)) %&gt;%\n  mutate(folder_out = map(folder, \n                          read_folder)) %&gt;%\n  unnest(cols = c(folder_out)) %&gt;%\n  transmute(newsgroup = basename(folder), id, text)\n\n\nwrite_rds(raw_text, \"data/rds/news20.rds\")\n\n\n\n\n\n\n\nNote\n\n\n\nread_lines() of readr package is used to read up to n_max lines from a file.\n\nmap() of purrr package is used to transform their input by applying a function to each element of a list and returning an object of the same length as the input.\nunnest() of dplyr package is used to flatten a list-column of data frames back out into regular columns.\nmutate() of dplyr is used to add new variables and preserves existing ones;\ntransmute() of dplyr is used to add new variables and drops existing ones.\nread_rds() is used to save the extracted and combined data frame as rds file for future use."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#initial-eda",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#initial-eda",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "",
    "text": "raw_text %&gt;%\n  group_by(newsgroup) %&gt;%\n  summarize(messages = n_distinct(id)) %&gt;%\n  ggplot(aes(messages, newsgroup)) +\n  geom_col(fill = \"lightblue\") +\n  labs(y = NULL)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#removing-header-and-automated-email-signatures",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#removing-header-and-automated-email-signatures",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "2.1 Removing header and automated email signatures",
    "text": "2.1 Removing header and automated email signatures\nNotice that each message has some structure and extra text that we don’t want to include in our analysis. For example, every message has a header, containing field such as “from:” or “in_reply_to:” that describe the message. Some also have automated email signatures, which occur after a line like “–”.\n\ncleaned_text &lt;- raw_text %&gt;%\n  group_by(newsgroup, id) %&gt;%\n  filter(cumsum(text == \"\") &gt; 0,\n         cumsum(str_detect(\n           text, \"^--\")) == 0) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nNote\n\n\n\n\ncumsum() of base R is used to return a vector whose elements are the cumulative sums of the elements of the argument.\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#removing-lines-with-nested-text-representing-quotes-from-other-users",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#removing-lines-with-nested-text-representing-quotes-from-other-users",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "2.2 Removing lines with nested text representing quotes from other users",
    "text": "2.2 Removing lines with nested text representing quotes from other users\nRegular expressions are used to remove with nested text representing quotes from other users.\nSee the link for more details: https://www.datacamp.com/tutorial/regex-r-regular-expressions-guide\n\ncleaned_text &lt;- cleaned_text %&gt;%\n  filter(str_detect(text, \"^[^&gt;]+[A-Za-z\\\\d]\")\n         | text == \"\",\n         !str_detect(text, \n                     \"writes(:|\\\\.\\\\.\\\\.)$\"),\n         !str_detect(text, \n                     \"^In article &lt;\")\n  )\n\n\n\n\n\n\n\nNote\n\n\n\n\nstr_detect() from stringr is used to detect the presence or absence of a pattern in a string.\nfilter() of dplyr package is used to subset a data frame, retaining all rows that satisfy the specified conditions."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#text-data-processing",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#text-data-processing",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "2.3 Text Data Processing",
    "text": "2.3 Text Data Processing\nIn this code chunk below, unnest_tokens() of tidytext package is used to split the dataset into tokens, while stop_words() is used to remove stop-words.\n\nusenet_words &lt;- cleaned_text %&gt;%\n  unnest_tokens(word, text) %&gt;%\n  filter(str_detect(word, \"[a-z']$\"),\n         !word %in% stop_words$word)\n\nNow that we’ve removed the headers, signatures, and formatting, we can start exploring common words. For starters, we could find the most common words in the entire dataset, or within particular newsgroups.\n\nusenet_words %&gt;%\n  count(word, sort = TRUE)\n\n# A tibble: 5,542 × 2\n   word           n\n   &lt;chr&gt;      &lt;int&gt;\n 1 people        57\n 2 time          50\n 3 jesus         47\n 4 god           44\n 5 message       40\n 6 br            27\n 7 bible         23\n 8 drive         23\n 9 homosexual    23\n10 read          22\n# ℹ 5,532 more rows\n\n\nInstead of counting individual word, you can also count words within by newsgroup by using the code chunk below.\n\nwords_by_newsgroup &lt;- usenet_words %&gt;%\n  count(newsgroup, word, sort = TRUE) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#visualising-words-in-newsgroups",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#visualising-words-in-newsgroups",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "2.4 Visualising words in newsgroups",
    "text": "2.4 Visualising words in newsgroups\nIn this code chunk below, wordcloud() of wordcloud package is used to plot a static wordcloud.\n\nwordcloud(words_by_newsgroup$word,\n          words_by_newsgroup$n,\n          max.words = 300)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#visualising-words-using-ggwordcloud-package",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#visualising-words-using-ggwordcloud-package",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "2.5 Visualising Words using ggwordcloud package",
    "text": "2.5 Visualising Words using ggwordcloud package\n\nset.seed(1234)\n\nwords_by_newsgroup %&gt;%\n  filter(n &gt; 0) %&gt;%\nggplot(aes(label = word,\n           size = n)) +\n  geom_text_wordcloud() +\n  theme_minimal() +\n  facet_wrap(~newsgroup)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#computing-tf-idf",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#computing-tf-idf",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "3.1 Computing tf-idf",
    "text": "3.1 Computing tf-idf\nThe code chunk below uses bind_tf_idf() of tidytext to compute and bind the term frequency, inverse document frequency and ti-idf of a tidy text dataset to the dataset.\n\ntf_idf &lt;- words_by_newsgroup %&gt;%\n  bind_tf_idf(word, newsgroup, n) %&gt;%\n  arrange(desc(tf_idf))"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#visualising-tf-idf-as-interactive-data-table",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#visualising-tf-idf-as-interactive-data-table",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "3.2 Visualising tf-idf as interactive data table",
    "text": "3.2 Visualising tf-idf as interactive data table\nThe code chunk below uses datatable() of DT package to create a html table that allows pagination of rows and columns.\n\nDT::datatable(tf_idf, filter = 'top') %&gt;% \n  formatRound(columns = c('tf', 'idf', \n                          'tf_idf'), \n              digits = 3) %&gt;%\n  formatStyle(0, \n              target = 'row', \n              lineHeight='25%')\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nfilter() argument is used to turn control the filter UI.\nformatRound() is used to customise the values format. The argument digits define the number of decimal places.\nformatStyle() is used to customise the output table. In this example, the arguments target and lineHeight are used to reduce the line height by 25%.\n\n\n\nTo learn more about customising DT’s table, visit this link."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#visualising-with-bar-charts",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#visualising-with-bar-charts",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "3.3 Visualising with bar charts",
    "text": "3.3 Visualising with bar charts\nFacet bar charts technique is used to visualise the tf-idf values of science related newsgroup.\n\ntf_idf %&gt;%\n  filter(str_detect(newsgroup, \"^sci\\\\.\")) %&gt;%\n  group_by(newsgroup) %&gt;%\n  slice_max(tf_idf, \n            n = 12) %&gt;%\n  ungroup() %&gt;%\n  mutate(word = reorder(word, \n                        tf_idf)) %&gt;%\n  ggplot(aes(tf_idf, \n             word, \n             fill = newsgroup)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~ newsgroup, \n             scales = \"free\") +\n  labs(x = \"tf-idf\", \n       y = NULL) +\n  theme_minimal()"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#counting-and-correlating-pairs-of-words-with-the-widyr-package",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#counting-and-correlating-pairs-of-words-with-the-widyr-package",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "3.4 Counting and correlating pairs of words with the widyr package",
    "text": "3.4 Counting and correlating pairs of words with the widyr package\n\nTo count the number of times that two words appear within the same document, or to see how correlated they are.\nMost operations for finding pairwise counts or correlations need to turn the data into a wide matrix first.\nwidyr package first ‘casts’ a tidy dataset into a wide matrix, performs an operation such as a correlation on it, then re-tidies the result.\n\n\nIn this code chunk below, pairwise_cor() of widyr package is used to compute the correlation between newsgroup based on the common words found.\n\nnewsgroup_cors &lt;- words_by_newsgroup %&gt;%\n  pairwise_cor(newsgroup, \n               word, \n               n, \n               sort = TRUE)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#visualising-correlation-as-network",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#visualising-correlation-as-network",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "3.5 Visualising correlation as network",
    "text": "3.5 Visualising correlation as network\n\nset.seed(2017)\n\nnewsgroup_cors %&gt;%\n  filter(correlation &gt; .025) %&gt;%\n  graph_from_data_frame() %&gt;%\n  ggraph(layout = \"fr\") +\n  geom_edge_link(aes(alpha = correlation, \n                     width = correlation)) +\n  geom_node_point(size = 6, \n                  color = \"lightblue\") +\n  geom_node_text(aes(label = name),\n                 color = \"red\",\n                 repel = TRUE) +\n  theme_void()"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#bigram",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#bigram",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "3.6 Bigram",
    "text": "3.6 Bigram\nBigram are two words coming together in the corpus(the entire collection of words/sentences).\n\nbigrams &lt;- cleaned_text %&gt;%\n  unnest_tokens(bigram, \n                text, \n                token = \"ngrams\", \n                n = 2)\n\n\nbigrams\n\n# A tibble: 28,827 × 3\n   newsgroup   id    bigram    \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;     \n 1 alt.atheism 54256 &lt;NA&gt;      \n 2 alt.atheism 54256 &lt;NA&gt;      \n 3 alt.atheism 54256 as i      \n 4 alt.atheism 54256 i don't   \n 5 alt.atheism 54256 don't know\n 6 alt.atheism 54256 know this \n 7 alt.atheism 54256 this book \n 8 alt.atheism 54256 book i    \n 9 alt.atheism 54256 i will    \n10 alt.atheism 54256 will use  \n# ℹ 28,817 more rows\n\n\nCounting bigrams:\n\nbigrams_count &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  count(bigram, sort = TRUE)\n\nbigrams_count\n\n# A tibble: 19,888 × 2\n   bigram       n\n   &lt;chr&gt;    &lt;int&gt;\n 1 of the     169\n 2 in the     113\n 3 to the      74\n 4 to be       59\n 5 for the     52\n 6 i have      48\n 7 that the    47\n 8 if you      40\n 9 on the      39\n10 it is       38\n# ℹ 19,878 more rows\n\n\nCleaning bigram:\nThe code chunk below is used to separate the bigram into two words:\n\nbigrams_separated &lt;- bigrams %&gt;%\n  filter(bigram != 'NA') %&gt;%\n  separate(bigram, c(\"word1\", \"word2\"), \n           sep = \" \")\n\nbigrams_filtered &lt;- bigrams_separated %&gt;%\n  filter(!word1 %in% stop_words$word) %&gt;%\n  filter(!word2 %in% stop_words$word)\n\nbigrams_filtered\n\n# A tibble: 4,607 × 4\n   newsgroup   id    word1        word2        \n   &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;        \n 1 alt.atheism 54256 defines      god          \n 2 alt.atheism 54256 term         preclues     \n 3 alt.atheism 54256 science      ideas        \n 4 alt.atheism 54256 ideas        drawn        \n 5 alt.atheism 54256 supernatural precludes    \n 6 alt.atheism 54256 scientific   assertions   \n 7 alt.atheism 54256 religious    dogma        \n 8 alt.atheism 54256 religion     involves     \n 9 alt.atheism 54256 involves     circumventing\n10 alt.atheism 54256 gain         absolute     \n# ℹ 4,597 more rows\n\n\nCount the bigram again:\n\nbigram_counts &lt;- bigrams_filtered %&gt;% \n  count(word1, word2, sort = TRUE)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#creating-a-network-graph-from-bigram-data-frame",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#creating-a-network-graph-from-bigram-data-frame",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "3.7 Creating a network graph from bigram data frame",
    "text": "3.7 Creating a network graph from bigram data frame\nIn the code chunk below, a network graph is created by using graph_from_data_frame() of igraph package.\n\nbigram_graph &lt;- bigram_counts %&gt;%\n  filter(n &gt; 3) %&gt;%\n  graph_from_data_frame()\nbigram_graph\n\nIGRAPH daa6008 DN-- 40 24 -- \n+ attr: name (v/c), n (e/n)\n+ edges from daa6008 (vertex names):\n [1] 1          -&gt;2           1          -&gt;3           static     -&gt;void       \n [4] time       -&gt;pad         1          -&gt;4           infield    -&gt;fly        \n [7] mat        -&gt;28          vv         -&gt;vv          1          -&gt;5          \n[10] cock       -&gt;crow        noticeshell-&gt;widget      27         -&gt;1993       \n[13] 3          -&gt;4           child      -&gt;molestation cock       -&gt;crew       \n[16] gun        -&gt;violence    heat       -&gt;sink        homosexual -&gt;male       \n[19] homosexual -&gt;women       include    -&gt;xol         mary       -&gt;magdalene  \n[22] read       -&gt;write       rev        -&gt;20          tt         -&gt;ee"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx5/handsonex5.html#plotting-the-bigram",
    "href": "HandsOnEx/HandsOnEx5/handsonex5.html#plotting-the-bigram",
    "title": "Hands On Ex 5 - Visualising and Anlysing Text with R",
    "section": "3.8 Plotting the bigram",
    "text": "3.8 Plotting the bigram\nggraph package is used to plot the bigram:\n\nset.seed(1234)\n\nggraph(bigram_graph, layout = \"fr\") +\n  geom_edge_link() +\n  geom_node_point() +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1)\n\n\n\n\n\n\n\n\nRevised Version:\n\nset.seed(1234)\n\na &lt;- grid::arrow(type = \"closed\", \n                 length = unit(.15,\n                               \"inches\"))\n\nggraph(bigram_graph, \n       layout = \"fr\") +\n  geom_edge_link(aes(edge_alpha = n), \n                 show.legend = FALSE,\n                 arrow = a, \n                 end_cap = circle(.07,\n                                  'inches')) +\n  geom_node_point(color = \"lightblue\", \n                  size = 5) +\n  geom_node_text(aes(label = name), \n                 vjust = 1, \n                 hjust = 1) +\n  theme_void()"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3-2/handson_ex3-2.html",
    "href": "HandsOnEx/HandsOnEx3-2/handson_ex3-2.html",
    "title": "Hands On Ex 3 - Part 2",
    "section": "",
    "text": "When telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\n\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.1.2 Terminology\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nNote\n\n\n\nMust think through whether animation is useful or not!!! Presentation?"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3-2/handson_ex3-2.html#basic-concepts-of-animation",
    "href": "HandsOnEx/HandsOnEx3-2/handson_ex3-2.html#basic-concepts-of-animation",
    "title": "Hands On Ex 3 - Part 2",
    "section": "",
    "text": "When creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.1.2 Terminology\n\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nNote\n\n\n\nMust think through whether animation is useful or not!!! Presentation?"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3-2/handson_ex3-2.html#importing-data",
    "href": "HandsOnEx/HandsOnEx3-2/handson_ex3-2.html#importing-data",
    "title": "Hands On Ex 3 - Part 2",
    "section": "2.1 Importing Data",
    "text": "2.1 Importing Data\nIn this exercise, we will be using the Global Population data.\n\ncol &lt;- c(\"Country\", \"Continent\")\n\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\", sheet = \"Data\") %&gt;%\n  mutate(across(all_of(col), factor)) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nNote\n\n\n\nReplaced the deprecated functions in dplyr, so the above is the latest."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3-2/handson_ex3-2.html#animated-bubble-plot-1",
    "href": "HandsOnEx/HandsOnEx3-2/handson_ex3-2.html#animated-bubble-plot-1",
    "title": "Hands On Ex 3 - Part 2",
    "section": "4.1 Animated Bubble Plot",
    "text": "4.1 Animated Bubble Plot\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem,  theme(legend.position='none')  should be used as shown in the plot and code chunk below.\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3-2/handson_ex3-2.html#using-plot_ly-method",
    "href": "HandsOnEx/HandsOnEx3-2/handson_ex3-2.html#using-plot_ly-method",
    "title": "Hands On Ex 3 - Part 2",
    "section": "4.2 using plot_ly() method",
    "text": "4.2 using plot_ly() method\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\n\nbp"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx2/handson_ex02.html",
    "href": "HandsOnEx/HandsOnEx2/handson_ex02.html",
    "title": "Hands On Ex 2",
    "section": "",
    "text": "In this exercise, we will look at using extensions to create more elegant and effective statistical graphics, mainly using these four packages:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2.\n\n\n\n\n\npacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse) \n\n\n\n\nWe will be using the data from Ex 1 - which is the exam grades of a cohort of Primary 3 students from a local school, which is stored in a csv file.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThe data comprises seven columns - 4 categorical (ID, Class, Gender and Race) and 3 continuous data (Scores for English, Maths and Science).\n\n\n\nOne of the key challenge in plotting is annotations, especially with a large number of data points.\nHere we use the ggplot2 to look at the English Score vs Maths Score.\n\n\nCode\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\nWhich is quite messy.\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples on the right.\nWe replace geom_text() with geom_text_repel() and geom_label() with geom_label_repel.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\n\n\nggplot comes with built-in themes refer to the link for more details. Below is an example using theme_gray().\n\n\nCode\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nIn the example below, The Economist theme is used.\n\n\nCode\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n\nIt also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\n\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\n\nCode\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum_rc()\n\n\n\n\n\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines.\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")\n\n\n\n\n\n\n\n\n\n\n\n\nSometimes we want to use multiple graphs to tell a story. We will learn how to do this using the patchwork package.\nBefore we start, we first create the three graphs that we want to use for our data storytelling.\n\nDistribution of Maths ScoresDistribution of English ScoresEnglish Scores vs Maths Scores for Primary 3\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np1\n\n\n\n\n\n\n\n\n\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np2\n\n\n\n\n\n\n\n\n\n\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English versus Maths scores\")\n\np3\n\n\n\n\n\n\n\n\n\n\n\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\n\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“/” operator to stack two ggplot2 graphs,\n“|” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\n(p1 / p2) | p3\n\n\n\n\n\n\n\n\nTo learn more about, refer to Plot Assembly.\n\n\n\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\n\n\n\n\n\n\n\nWe can combine patchwork and theme_economist() of ggthemes package:\nAlso note how to create the title and caption under patchwork.\n\npatchwork &lt;- ((p1 / p2) | p3) +\n  plot_annotation('English and Maths Scores of Primary 3 Students', caption = 'made with patchwork')\n\npatchwork & theme_economist() +\n  theme(title=element_text(size=8, face='bold'), axis.text.x = element_text(size = 6))"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx2/handson_ex02.html#overview",
    "href": "HandsOnEx/HandsOnEx2/handson_ex02.html#overview",
    "title": "Hands On Ex 2",
    "section": "",
    "text": "In this exercise, we will look at using extensions to create more elegant and effective statistical graphics, mainly using these four packages:\n\nggrepel: an R package provides geoms for ggplot2 to repel overlapping text labels.\nggthemes: an R package provides some extra themes, geoms, and scales for ‘ggplot2’.\nhrbrthemes: an R package provides typography-centric themes and theme components for ggplot2.\npatchwork: an R package for preparing composite figure created using ggplot2."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx2/handson_ex02.html#loading-the-packages",
    "href": "HandsOnEx/HandsOnEx2/handson_ex02.html#loading-the-packages",
    "title": "Hands On Ex 2",
    "section": "",
    "text": "pacman::p_load(ggrepel, patchwork, \n               ggthemes, hrbrthemes,\n               tidyverse)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx2/handson_ex02.html#importing-the-data",
    "href": "HandsOnEx/HandsOnEx2/handson_ex02.html#importing-the-data",
    "title": "Hands On Ex 2",
    "section": "",
    "text": "We will be using the data from Ex 1 - which is the exam grades of a cohort of Primary 3 students from a local school, which is stored in a csv file.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nThe data comprises seven columns - 4 categorical (ID, Class, Gender and Race) and 3 continuous data (Scores for English, Maths and Science)."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx2/handson_ex02.html#annotations-using-ggrepel",
    "href": "HandsOnEx/HandsOnEx2/handson_ex02.html#annotations-using-ggrepel",
    "title": "Hands On Ex 2",
    "section": "",
    "text": "One of the key challenge in plotting is annotations, especially with a large number of data points.\nHere we use the ggplot2 to look at the English Score vs Maths Score.\n\n\nCode\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  geom_label(aes(label = ID), \n             hjust = .5, \n             vjust = -.5) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")\n\n\n\n\n\n\n\n\n\nWhich is quite messy.\nggrepel is an extension of ggplot2 package which provides geoms for ggplot2 to repel overlapping text as in our examples on the right.\nWe replace geom_text() with geom_text_repel() and geom_label() with geom_label_repel.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  geom_label_repel(aes(label = ID), \n                   fontface = \"bold\") +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English scores versus Maths scores for Primary 3\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx2/handson_ex02.html#themes",
    "href": "HandsOnEx/HandsOnEx2/handson_ex02.html#themes",
    "title": "Hands On Ex 2",
    "section": "",
    "text": "ggplot comes with built-in themes refer to the link for more details. Below is an example using theme_gray().\n\n\nCode\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of Maths scores\") \n\n\n\n\n\n\n\n\n\n\n\nggthemes provides ‘ggplot2’ themes that replicate the look of plots by Edward Tufte, Stephen Few, Fivethirtyeight, The Economist, ‘Stata’, ‘Excel’, and The Wall Street Journal, among others.\nIn the example below, The Economist theme is used.\n\n\nCode\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_economist()\n\n\n\n\n\n\n\n\n\nIt also provides some extra geoms and scales for ‘ggplot2’. Consult this vignette to learn more.\n\n\n\nhrbrthemes package provides a base theme that focuses on typographic elements, including where various labels are placed as well as the fonts that are used.\n\n\nCode\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum_rc()\n\n\n\n\n\n\n\n\n\nThe second goal centers around productivity for a production workflow. In fact, this “production workflow” is the context for where the elements of hrbrthemes should be used. Consult this vignette to learn more.\n\naxis_title_size argument is used to increase the font size of the axis title to 18,\nbase_size argument is used to increase the default axis label to 15, and\ngrid argument is used to remove the x-axis grid lines.\n\n\nggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  ggtitle(\"Distribution of Maths scores\") +\n  theme_ipsum(axis_title_size = 18,\n              base_size = 15,\n              grid = \"Y\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx2/handson_ex02.html#creating-multiple-graphs",
    "href": "HandsOnEx/HandsOnEx2/handson_ex02.html#creating-multiple-graphs",
    "title": "Hands On Ex 2",
    "section": "",
    "text": "Sometimes we want to use multiple graphs to tell a story. We will learn how to do this using the patchwork package.\nBefore we start, we first create the three graphs that we want to use for our data storytelling.\n\nDistribution of Maths ScoresDistribution of English ScoresEnglish Scores vs Maths Scores for Primary 3\n\n\n\np1 &lt;- ggplot(data=exam_data, \n             aes(x = MATHS)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") + \n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of Maths scores\")\n\np1\n\n\n\n\n\n\n\n\n\n\n\np2 &lt;- ggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  coord_cartesian(xlim=c(0,100)) +\n  ggtitle(\"Distribution of English scores\")\n\np2\n\n\n\n\n\n\n\n\n\n\n\np3 &lt;- ggplot(data=exam_data, \n             aes(x= MATHS, \n                 y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              size=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100)) +\n  ggtitle(\"English versus Maths scores\")\n\np3\n\n\n\n\n\n\n\n\n\n\n\nThere are several ggplot2 extension’s functions support the needs to prepare composite figure by combining several graphs such as grid.arrange() of gridExtra package and plot_grid() of cowplot package. In this section, I am going to shared with you an ggplot2 extension called patchwork which is specially designed for combining separate ggplot2 graphs into a single figure.\nPatchwork package has a very simple syntax where we can create layouts super easily. Here’s the general syntax that combines:\n\nTwo-Column Layout using the Plus Sign +.\nParenthesis () to create a subplot group.\nTwo-Row Layout using the Division Sign /\n\n\n\n\np1 + p2\n\n\n\n\n\n\n\n\n\n\n\nWe can plot more complex composite by using appropriate operators. For example, the composite figure below is plotted by using:\n\n“/” operator to stack two ggplot2 graphs,\n“|” operator to place the plots beside each other,\n“()” operator the define the sequence of the plotting.\n\n\n(p1 / p2) | p3\n\n\n\n\n\n\n\n\nTo learn more about, refer to Plot Assembly.\n\n\n\nIn order to identify subplots in text, patchwork also provides auto-tagging capabilities as shown in the figure below.\n\n((p1 / p2) | p3) + \n  plot_annotation(tag_levels = 'I')\n\n\n\n\n\n\n\n\n\n\n\nBeside providing functions to place plots next to each other based on the provided layout. With inset_element() of patchwork, we can place one or several plots or graphic elements freely on top or below another plot.\n\np3 + inset_element(p2, \n                   left = 0.02, \n                   bottom = 0.7, \n                   right = 0.5, \n                   top = 1)\n\n\n\n\n\n\n\n\n\n\n\nWe can combine patchwork and theme_economist() of ggthemes package:\nAlso note how to create the title and caption under patchwork.\n\npatchwork &lt;- ((p1 / p2) | p3) +\n  plot_annotation('English and Maths Scores of Primary 3 Students', caption = 'made with patchwork')\n\npatchwork & theme_economist() +\n  theme(title=element_text(size=8, face='bold'), axis.text.x = element_text(size = 6))"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx1/handson_ex01.html",
    "href": "HandsOnEx/HandsOnEx1/handson_ex01.html",
    "title": "Hands-On Ex 1",
    "section": "",
    "text": "pacman::p_load(tidyverse)\n\n\n\n\nFor this exercise, we will be using the Year End Examination Grades of a cohort of Primary 3 students from a local school.\nWe will use the read_csv function of readr/tidyverse to read the provided data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nhead (exam_data)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16\n\n\nWe use the head() to take a look at the columns - which comprise seven columns - 4 categorical (ID, Class, Gender and Race) and 3 continuous data (Scores for English, Maths and Science).\n\n\n\nWe will first look at ggplot.\nggplot cheat sheet:\n\n\n\n\nComparing the choice of using R Graphics vs ggplot:\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\nGood to learn ggplot2 as it provides a more powerful tool that is customisable, although it means learning its way of language first. That said, we all need to do more customisation at some point in time - so just jump into it!\n\n\n\n\nGrammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer. The grammar of graphics is an answer to a question:\nWhat is a statistical graphic?\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. Figure below shows the seven grammars of ggplot2.\n\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background.\n\n\n\n\nLets break down the elements of ggplot2.\nWhen we use ggplot() , it initialises a ggplot object and creates a blank canvas. The data argument defines the dataset that we want to plot. If the dataset is not already a data.frame, it will be converted to one by fortify().\n\nggplot(data=exam_data)\n\n\n\n\n\n\n\n\n\n\n\nRefer to this linkfor more info.\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\nCode chunk below adds the aesthetic element into the plot.\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nggplot includes the x-axis and the axis’s label.\n\n\n\n\n\n\nGeometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\n\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\nFor complete list, please refer to here.\n\n\n\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the default bin is 30.\n\n\n\n\n\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric.\n\n\n\n\n\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\n\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\n\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)        \n\n\n\n\n\n\n\n\n\n\n\n\nThe Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat\n\n\n\n\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)          \n\n\n\n\n\n\n\n\n\n\n\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\n\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(linewidth=0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe default method used is loess.\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5)\n\n\n\n\n\n\n\n\n\n\n\n\nFacetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n\n\nThe Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n\ncoord_cartesian() - the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out).\ncoord_flip() - a cartesian system with the x and y flipped.\ncoord_fixed() - a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot).\ncoord_quickmap() - a coordinate system that approximates a good aspect ratio for maps.\n\n\n\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nThe scatterplot on the right is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, linewidth=0.5)\n\n\n\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\n\n\n\n\n\n\n\n\n\n\n\nThemes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\nHadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx1/handson_ex01.html#loading-of-the-required-packages",
    "href": "HandsOnEx/HandsOnEx1/handson_ex01.html#loading-of-the-required-packages",
    "title": "Hands-On Ex 1",
    "section": "",
    "text": "pacman::p_load(tidyverse)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx1/handson_ex01.html#loading-the-data-set",
    "href": "HandsOnEx/HandsOnEx1/handson_ex01.html#loading-the-data-set",
    "title": "Hands-On Ex 1",
    "section": "",
    "text": "For this exercise, we will be using the Year End Examination Grades of a cohort of Primary 3 students from a local school.\nWe will use the read_csv function of readr/tidyverse to read the provided data.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\n\nhead (exam_data)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16\n\n\nWe use the head() to take a look at the columns - which comprise seven columns - 4 categorical (ID, Class, Gender and Race) and 3 continuous data (Scores for English, Maths and Science)."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx1/handson_ex01.html#introducing-ggplot",
    "href": "HandsOnEx/HandsOnEx1/handson_ex01.html#introducing-ggplot",
    "title": "Hands-On Ex 1",
    "section": "",
    "text": "We will first look at ggplot.\nggplot cheat sheet:\n\n\n\n\nComparing the choice of using R Graphics vs ggplot:\n\nR Graphicsggplot2\n\n\n\nhist(exam_data$MATHS)\n\n\n\n\n\n\n\n\n\n\n\nggplot(data=exam_data, aes(x = MATHS)) +\n  geom_histogram(bins=10, \n                 boundary = 100,\n                 color=\"black\", \n                 fill=\"grey\") +\n  ggtitle(\"Distribution of Maths scores\")\n\n\n\n\n\n\n\n\n\n\n\nGood to learn ggplot2 as it provides a more powerful tool that is customisable, although it means learning its way of language first. That said, we all need to do more customisation at some point in time - so just jump into it!"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx1/handson_ex01.html#grammar-of-graphics",
    "href": "HandsOnEx/HandsOnEx1/handson_ex01.html#grammar-of-graphics",
    "title": "Hands-On Ex 1",
    "section": "",
    "text": "Grammar of Graphics is a general scheme for data visualization which breaks up graphs into semantic components such as scales and layers. It was introduced by Leland Wilkinson (1999) Grammar of Graphics, Springer. The grammar of graphics is an answer to a question:\nWhat is a statistical graphic?\nIn the nutshell, Grammar of Graphics defines the rules of structuring mathematical and aesthetic elements into a meaningful graph.\nThere are two principles in Grammar of Graphics, they are:\n\nGraphics = distinct layers of grammatical elements\nMeaningful plots through aesthetic mapping\n\nA good grammar of graphics will allow us to gain insight into the composition of complicated graphics, and reveal unexpected connections between seemingly different graphics (Cox 1978). It also provides a strong foundation for understanding a diverse range of graphics. Furthermore, it may also help guide us on what a well-formed or correct graphic looks like, but there will still be many grammatically correct but nonsensical graphics.\nggplot2 is an implementation of Leland Wilkinson’s Grammar of Graphics. Figure below shows the seven grammars of ggplot2.\n\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx1/handson_ex01.html#essential-elements-of-ggplot2",
    "href": "HandsOnEx/HandsOnEx1/handson_ex01.html#essential-elements-of-ggplot2",
    "title": "Hands-On Ex 1",
    "section": "",
    "text": "Lets break down the elements of ggplot2.\nWhen we use ggplot() , it initialises a ggplot object and creates a blank canvas. The data argument defines the dataset that we want to plot. If the dataset is not already a data.frame, it will be converted to one by fortify().\n\nggplot(data=exam_data)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx1/handson_ex01.html#aesthetic-mappings",
    "href": "HandsOnEx/HandsOnEx1/handson_ex01.html#aesthetic-mappings",
    "title": "Hands-On Ex 1",
    "section": "",
    "text": "Refer to this linkfor more info.\nThe aesthetic mappings take attributes of the data and and use them to influence visual characteristics, such as position, colour, size, shape, or transparency. Each visual characteristic can thus encode an aspect of the data and be used to convey information.\nAll aesthetics of a plot are specified in the aes() function call (in later part of this lesson, you will see that each geom layer can have its own aes specification)\nCode chunk below adds the aesthetic element into the plot.\n\nggplot(data=exam_data, \n       aes(x= MATHS))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nggplot includes the x-axis and the axis’s label."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx1/handson_ex01.html#geom",
    "href": "HandsOnEx/HandsOnEx1/handson_ex01.html#geom",
    "title": "Hands-On Ex 1",
    "section": "",
    "text": "Geometric objects are the actual marks we put on a plot. Examples include:\n\ngeom_point for drawing individual points (e.g., a scatter plot)\ngeom_line for drawing lines (e.g., for a line charts)\ngeom_smooth for drawing smoothed lines (e.g., for simple trends or approximations)\ngeom_bar for drawing bars (e.g., for bar charts)\ngeom_histogram for drawing binned values (e.g. a histogram)\ngeom_polygon for drawing arbitrary shapes\ngeom_map for drawing polygons in the shape of a map! (You can access the data to use for these maps by using the map_data() function).\n\n\n\nA plot must have at least one geom; there is no upper limit. You can add a geom to a plot using the + operator.\nFor complete list, please refer to here.\n\n\n\nThe code chunk below plots a bar chart by using geom_bar().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nIn a dot plot, the width of a dot corresponds to the bin width (or maximum width, depending on the binning algorithm), and dots are stacked, with each dot representing one observation.\nIn the code chunk below, geom_dotplot() of ggplot2 is used to plot a dot plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe y scale is not very useful, in fact it is very misleading.\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below performs the following two steps:\n\nscale_y_continuous() is used to turn off the y-axis, and\nbinwidth argument is used to change the binwidth to 2.5.\n\n\n\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(binwidth=2.5,         \n               dotsize = 0.5) +      \n  scale_y_continuous(NULL,           \n                     breaks = NULL)  \n\n\n\n\n\n\n\n\n\n\n\nIn the code chunk below, geom_histogram() is used to create a simple histogram by using values in MATHS field of exam_data.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_histogram()       \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the default bin is 30.\n\n\n\n\n\nIn the code chunk below,\n\nbins argument is used to change the number of bins to 20,\nfill argument is used to shade the histogram with light blue color, and\ncolor argument is used to change the outline colour of the bars in black\n\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20,            \n                 color=\"black\",      \n                 fill=\"light blue\")  \n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below changes the interior colour of the histogram (i.e. fill) by using sub-group of aesthetic().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           fill = GENDER)) +\n  geom_histogram(bins=20, \n                 color=\"grey30\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThis approach can be used to colour, fill and alpha of the geometric.\n\n\n\n\n\ngeom-density() computes and plots kernel density estimate, which is a smoothed version of the histogram.\nIt is a useful alternative to the histogram for continuous data that comes from an underlying smooth distribution.\nThe code below plots the distribution of Maths scores in a kernel density estimate plot.\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_density()           \n\n\n\n\n\n\n\n\nThe code chunk below plots two kernel density lines by using colour or fill arguments of aes()\n\nggplot(data=exam_data, \n       aes(x = MATHS, \n           colour = GENDER)) +\n  geom_density()\n\n\n\n\n\n\n\n\n\n\n\ngeom_boxplot() displays continuous value list. It visualises five summary statistics (the median, two hinges and two whiskers), and all “outlying” points individually.\nThe code chunk below plots boxplots by using geom_boxplot().\n\nggplot(data=exam_data, \n       aes(y = MATHS,       \n           x= GENDER)) +    \n  geom_boxplot()            \n\n\n\n\n\n\n\n\nNotches are used in box plots to help visually assess whether the medians of distributions differ. If the notches do not overlap, this is evidence that the medians are different.\nThe code chunk below plots the distribution of Maths scores by gender in notched plot instead of boxplot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot(notch=TRUE)\n\n\n\n\n\n\n\n\n\n\n\ngeom_violin is designed for creating violin plot. Violin plots are a way of comparing multiple data distributions. With ordinary density curves, it is difficult to compare more than just a few distributions because the lines visually interfere with each other. With a violin plot, it’s easier to compare several distributions since they’re placed side by side.\nThe code below plot the distribution of Maths score by gender in violin plot.\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_violin()\n\n\n\n\n\n\n\n\n\n\n\ngeom_point() is especially useful for creating scatterplot.\nThe code chunk below plots a scatterplot showing the Maths and English grades of pupils by using geom_point().\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point()            \n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below plots the data points on the boxplots by using both geom_boxplot() and geom_point().\n\nggplot(data=exam_data, \n       aes(y = MATHS, \n           x= GENDER)) +\n  geom_boxplot() +                    \n  geom_point(position=\"jitter\", \n             size = 0.5)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx1/handson_ex01.html#stat-function",
    "href": "HandsOnEx/HandsOnEx1/handson_ex01.html#stat-function",
    "title": "Hands-On Ex 1",
    "section": "",
    "text": "The Statistics functions statistically transform data, usually as some form of summary. For example:\n\nfrequency of values of a variable (bar graph)\n\na mean\na confidence limit\n\nThere are two ways to use these functions:\n\nadd a stat_() function and override the default geom, or\nadd a geom_() function and override the default stat\n\n\n\n\nThe boxplots below are incomplete because the positions of the means were not shown.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below adds mean values by using stat_summary() function and overriding the default geom.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  stat_summary(geom = \"point\",       \n               fun.y=\"mean\",         \n               colour =\"red\",        \n               size=4)               \n\n\n\n\n\n\n\n\n\n\n\nThe code chunk below adding mean values by using geom_() function and overriding the default stat.\n\nggplot(data=exam_data, \n       aes(y = MATHS, x= GENDER)) +\n  geom_boxplot() +\n  geom_point(stat=\"summary\",        \n             fun.y=\"mean\",           \n             colour =\"red\",          \n             size=4)          \n\n\n\n\n\n\n\n\n\n\n\nThe scatterplot below shows the relationship of Maths and English grades of pupils. The interpretability of this graph can be improved by adding a best fit curve.\n\n\n\nIn the code chunk below, geom_smooth() is used to plot a best fit curve on the scatterplot.\n\n\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(linewidth=0.5)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe default method used is loess.\n\n\n\nThe default smoothing method can be overridden as shown below.\n\nggplot(data=exam_data, \n       aes(x= MATHS, \n           y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx1/handson_ex01.html#facets",
    "href": "HandsOnEx/HandsOnEx1/handson_ex01.html#facets",
    "title": "Hands-On Ex 1",
    "section": "",
    "text": "Facetting generates small multiples (sometimes also called trellis plot), each displaying a different subset of the data. They are an alternative to aesthetics for displaying additional discrete variables. ggplot2 supports two types of factes, namely: facet_grid() and facet_wrap.\n\n\nfacet_wrap wraps a 1d sequence of panels into 2d. This is generally a better use of screen space than facet_grid because most displays are roughly rectangular.\nThe code chunk below plots a trellis plot using facet-wrap().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ CLASS)\n\n\n\n\n\n\n\n\n\n\n\nfacet_grid() forms a matrix of panels defined by row and column facetting variables. It is most useful when you have two discrete variables, and all combinations of the variables exist in the data.\nThe code chunk below plots a trellis plot using facet_grid().\n\nggplot(data=exam_data, \n       aes(x= MATHS)) +\n  geom_histogram(bins=20) +\n    facet_grid(~ CLASS)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx1/handson_ex01.html#coordinates",
    "href": "HandsOnEx/HandsOnEx1/handson_ex01.html#coordinates",
    "title": "Hands-On Ex 1",
    "section": "",
    "text": "The Coordinates functions map the position of objects onto the plane of the plot. There are a number of different possible coordinate systems to use, they are:\n\ncoord_cartesian() - the default cartesian coordinate systems, where you specify x and y values (e.g. allows you to zoom in or out).\ncoord_flip() - a cartesian system with the x and y flipped.\ncoord_fixed() - a cartesian system with a “fixed” aspect ratio (e.g. 1.78 for a “widescreen” plot).\ncoord_quickmap() - a coordinate system that approximates a good aspect ratio for maps.\n\n\n\nBy the default, the bar chart of ggplot2 is in vertical form.\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar()\n\n\n\n\n\n\n\n\nThe code chunk below flips the horizontal bar chart into vertical bar chart by using coord_flip().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\n\n\n\n\n\n\n\nThe scatterplot on the right is slightly misleading because the y-aixs and x-axis range are not equal.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, linewidth=0.5)\n\n\n\n\n\n\n\n\nThe code chunk below fixed both the y-axis and x-axis range from 0-100.\n\nggplot(data=exam_data, \n       aes(x= MATHS, y=ENGLISH)) +\n  geom_point() +\n  geom_smooth(method=lm, \n              linewidth=0.5) +  \n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx1/handson_ex01.html#themes",
    "href": "HandsOnEx/HandsOnEx1/handson_ex01.html#themes",
    "title": "Hands-On Ex 1",
    "section": "",
    "text": "Themes control elements of the graph not related to the data. For example:\n\nbackground colour\nsize of fonts\ngridlines\ncolour of labels\n\nBuilt-in themes include: - theme_gray() (default) - theme_bw() - theme_classic()\nA list of theme can be found at this link. Each theme element can be conceived of as either a line (e.g. x-axis), a rectangle (e.g. graph background), or text (e.g. axis title).\n\n\nThe code chunk below plot a horizontal bar chart using theme_gray().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_gray()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_classic().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_classic()\n\n\n\n\n\n\n\n\nA horizontal bar chart plotted using theme_minimal().\n\nggplot(data=exam_data, \n       aes(x=RACE)) +\n  geom_bar() +\n  coord_flip() +\n  theme_minimal()"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx1/handson_ex01.html#reference",
    "href": "HandsOnEx/HandsOnEx1/handson_ex01.html#reference",
    "title": "Hands-On Ex 1",
    "section": "",
    "text": "Hadley Wickham (2023) ggplot2: Elegant Graphics for Data Analysis. Online 3rd edition.\nWinston Chang (2013) R Graphics Cookbook 2nd edition. Online version.\nHealy, Kieran (2019) Data Visualization: A practical introduction. Online version\nLearning ggplot2 on Paper – Components\nLearning ggplot2 on Paper – Layer\nLearning ggplot2 on Paper – Scale"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#importing-data",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#importing-data",
    "title": "Hands-On Ex 3",
    "section": "1.1 Importing Data",
    "text": "1.1 Importing Data\nWe will be using the exam data again for this ex.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#tooltip-effect-with-tooltip-aesthetic",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#tooltip-effect-with-tooltip-aesthetic",
    "title": "Hands-On Ex 3",
    "section": "2.1 Tooltip Effect with tooltip aesthetic",
    "text": "2.1 Tooltip Effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, an ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\n\n\n\n\n\nNote\n\n\n\nHovering the mouse pointer over a data point will show the Student’s ID.\n\n\n\np &lt;- ggplot(data=exam_data,aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL,breaks = NULL)\n\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#multiple-information-on-tooltip",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#multiple-information-on-tooltip",
    "title": "Hands-On Ex 3",
    "section": "2.2 Multiple Information on tooltip",
    "text": "2.2 Multiple Information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\n\n\n\n\n\nNote\n\n\n\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\nexam_data$tooltip &lt;- c(paste0(\"Name = \", exam_data$ID, \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(ggobj = p,width_svg = 8, height_svg = 8*0.618)\n\n\n\n\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#customising-the-styles-of-the-tooltip",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#customising-the-styles-of-the-tooltip",
    "title": "Hands-On Ex 3",
    "section": "2.3 Customising the Styles of the Tooltip",
    "text": "2.3 Customising the Styles of the Tooltip\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; \nfont-style:bold; color:black;\" \n\nexam_data$tooltip &lt;- c(paste0(\"Name = \", exam_data$ID, \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(ggobj = p,width_svg = 8, height_svg = 8*0.618, \n       options = list(opts_tooltip(css = tooltip_css)))"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#displaying-statistics-on-tooltip",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#displaying-statistics-on-tooltip",
    "title": "Hands-On Ex 3",
    "section": "2.4 Displaying Statistics on Tooltip",
    "text": "2.4 Displaying Statistics on Tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data,aes(x = RACE)) +\n  stat_summary(aes(y = MATHS, tooltip = after_stat(tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point, width_svg = 8, height_svg = 8*0.618)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#hover-effect-with-data_id-aesthetic",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#hover-effect-with-data_id-aesthetic",
    "title": "Hands-On Ex 3",
    "section": "2.5 Hover Effect with data_id aesthetic",
    "text": "2.5 Hover Effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data, aes(x = MATHS))+ \n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(ggobj = p, width_svg = 8, height_svg = 8*0.618)          \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\nNote that the default value of the hover css is hover_css = “fill:orange;”."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#styling-hover-effect",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#styling-hover-effect",
    "title": "Hands-On Ex 3",
    "section": "2.6 Styling Hover Effect",
    "text": "2.6 Styling Hover Effect\n\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#combining-both-effects",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#combining-both-effects",
    "title": "Hands-On Ex 3",
    "section": "2.7 Combining both Effects",
    "text": "2.7 Combining both Effects\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#click-effect-with-onclick",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#click-effect-with-onclick",
    "title": "Hands-On Ex 3",
    "section": "2.8 Click effect with onclick",
    "text": "2.8 Click effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#coordinated-multiple-views-with-ggiraph",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#coordinated-multiple-views-with-ggiraph",
    "title": "Hands-On Ex 3",
    "section": "2.9 Coordinated Multiple Views with ggiraph",
    "text": "2.9 Coordinated Multiple Views with ggiraph\nWe can build a graph where data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       )"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#working-with-visual-variable",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#working-with-visual-variable",
    "title": "Hands-On Ex 3",
    "section": "3.1 Working with visual variable",
    "text": "3.1 Working with visual variable\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#using-ggplotly-method",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#using-ggplotly-method",
    "title": "Hands-On Ex 3",
    "section": "3.2 Using ggplotly() method",
    "text": "3.2 Using ggplotly() method\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\nNotice that the only extra line you need to include in the code chunk is ggplotly()."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#coordinated-multiple-views-with-plotly",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#coordinated-multiple-views-with-plotly",
    "title": "Hands-On Ex 3",
    "section": "3.3 Coordinated Multiple Views with plotly",
    "text": "3.3 Coordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nClick on a data point of one of the scatterplot and see how the corresponding point on the other scatterplot is selected.\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\nVisit this link to learn more about crosstalk"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#interactive-data-table-dt-package",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#interactive-data-table-dt-package",
    "title": "Hands-On Ex 3",
    "section": "4.1 Interactive Data Table: DT package",
    "text": "4.1 Interactive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#linked-brushing-crosstalk-method",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#linked-brushing-crosstalk-method",
    "title": "Hands-On Ex 3",
    "section": "4.2 Linked brushing: crosstalk method",
    "text": "4.2 Linked brushing: crosstalk method\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#ggiraph",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#ggiraph",
    "title": "Hands-On Ex 3",
    "section": "5.1 ggiraph",
    "text": "5.1 ggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx3/handson_ex03.html#plotly-for-r",
    "href": "HandsOnEx/HandsOnEx3/handson_ex03.html#plotly-for-r",
    "title": "Hands-On Ex 3",
    "section": "5.2 plotly for R",
    "text": "5.2 plotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "In this hands-on exercise, we will gain hands-on experience on using:\n\nggstatsplot package to create visual graphics with rich statistical information,\nperformance package to visualise model diagnostics, and\nparameters package to visualise model parameters\n\n\n\nggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. For example, here are results from a robust t-test:\n\n\n\n\n\n\n\n\npacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nhead(exam_data)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16\n\n\n\n\n\n\ngghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\n\nA Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\n\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor.\n\n\n\n\nA Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:\n\n\n\n\n\n\n\n\n ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary\n\n\n\nggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam_data,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\npairwise.display\n\nDecides which pairwise comparisons to display. Available options are:\n\n\"significant\" (abbreviation accepted: \"s\")\n\"non-significant\" (abbreviation accepted: \"ns\")\n\"all\"\n\nYou can use this argument to make sure that your plot is not uber-cluttered when you have multiple groups being compared and scores of pairwise comparisons being displayed. If set to \"none\", no pairwise comparisons will be displayed.\n\n\n\n\n\n\n\n\n\n\nggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\n\n\n\n\n\n\nThe Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam_data %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nggbarstats() is used to build a visual for Significant Test of Association.\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER,\n           palette = \"Blues\"\n           )\n\n\n\n\n\n\n\n\n\n\n\nIn this section, we will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\n\n\n\nThe code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\n\ncheck_collinearity() of performance package is used to check for multi correlation.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\n\nplot(check_c)\n\n\n\n\n\n\n\n\n\n\n\nWe will use check_normality() of performance package.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\n\n\n\n\n\n\ncheck_h &lt;- check_heteroscedasticity(model1)\n\nplot(check_h)\n\n\n\n\n\n\n\n\n\n\n\n\ncheck_model(model1)\n\n\n\n\n\n\n\n\n\n\n\nIn the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\n\n\n\nIn the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#using-ggstatsplot",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#using-ggstatsplot",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "ggstatsplot is an extension of ggplot2 package for creating graphics with details from statistical tests included in the information-rich plots themselves.\n\nTo provide alternative statistical inference methods by default\nTo follow best practices for statistical reporting. For all statistical tests reported in the plots, the default template abides by the [APA](https://my.ilstu.edu/~jhkahn/apastats.html) gold standard for statistical reporting. For example, here are results from a robust t-test:"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#getting-started",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#getting-started",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "pacman::p_load(ggstatsplot, tidyverse)\n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nhead(exam_data)\n\n# A tibble: 6 × 7\n  ID         CLASS GENDER RACE    ENGLISH MATHS SCIENCE\n  &lt;chr&gt;      &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1 Student321 3I    Male   Malay        21     9      15\n2 Student305 3I    Female Malay        24    22      16\n3 Student289 3H    Male   Chinese      26    16      16\n4 Student227 3F    Male   Chinese      27    77      31\n5 Student318 3I    Male   Malay        27    11      25\n6 Student306 3I    Female Malay        31    16      16"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#one-sample-test-gghistostats-method",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#one-sample-test-gghistostats-method",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "gghistostats() is used to to build an visual of one-sample test on English scores.\n\nset.seed(1234)\n\ngghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#unpacking-the-bayes-factor",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#unpacking-the-bayes-factor",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "A Bayes factor is the ratio of the likelihood of one particular hypothesis to the likelihood of another. It can be interpreted as a measure of the strength of evidence in favor of one theory among two competing theories.\nThat’s because the Bayes factor gives us a way to evaluate the data in favor of a null hypothesis, and to use external information to do so. It tells us what the weight of the evidence is in favor of a given hypothesis.\nWhen we are comparing two hypotheses, H1 (the alternate hypothesis) and H0 (the null hypothesis), the Bayes Factor is often written as B10. It can be defined mathematically as\n\n\n\n\n\n\n\nThe Schwarz criterion is one of the easiest ways to calculate rough approximation of the Bayes Factor."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#how-to-interpret-bayes-factor",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#how-to-interpret-bayes-factor",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "A Bayes Factor can be any positive number. One of the most common interpretations is this one—first proposed by Harold Jeffereys (1961) and slightly modified by Lee and Wagenmakers in 2013:"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#two-sample-mean-test-ggbetweenstats",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#two-sample-mean-test-ggbetweenstats",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "ggbetweenstats() is used to build a visual for two-sample mean test of Maths scores by gender.\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\nDefault information: - statistical details - Bayes Factor - sample sizes - distribution summary"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#one-way-anova-test-ggbetweenstats-method",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#one-way-anova-test-ggbetweenstats-method",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "ggbetweenstats() is used to build a visual for One-way ANOVA test on English score by race.\n\nggbetweenstats(\n  data = exam_data,\n  x = RACE, \n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE, \n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\n\n\npairwise.display\n\nDecides which pairwise comparisons to display. Available options are:\n\n\"significant\" (abbreviation accepted: \"s\")\n\"non-significant\" (abbreviation accepted: \"ns\")\n\"all\"\n\nYou can use this argument to make sure that your plot is not uber-cluttered when you have multiple groups being compared and scores of pairwise comparisons being displayed. If set to \"none\", no pairwise comparisons will be displayed."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#significant-test-of-correlation-ggscatterstats-method",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#significant-test-of-correlation-ggscatterstats-method",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "ggscatterstats() is used to build a visual for Significant Test of Correlation between Maths scores and English scores.\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#significant-test-of-association-depedence-ggbarstats-methods",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#significant-test-of-association-depedence-ggbarstats-methods",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "The Maths scores is binned into a 4-class variable by using cut().\n\nexam1 &lt;- exam_data %&gt;% \n  mutate(MATHS_bins = \n           cut(MATHS, \n               breaks = c(0,60,75,85,100))\n)\n\nggbarstats() is used to build a visual for Significant Test of Association.\n\nggbarstats(exam1, \n           x = MATHS_bins, \n           y = GENDER,\n           palette = \"Blues\"\n           )"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#visualising-models",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#visualising-models",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "In this section, we will learn how to visualise model diagnostic and model parameters by using parameters package.\n\nToyota Corolla case study will be used. The purpose of study is to build a model to discover factors affecting prices of used-cars by taking into consideration a set of explanatory variables.\n\n\n\n\npacman::p_load(readxl, performance, parameters, see)\n\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#multiple-regression-model-using-lm",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#multiple-regression-model-using-lm",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "The code chunk below is used to calibrate a multiple linear regression model by using lm() of Base Stats of R.\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#checking-for-multicoinearity",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#checking-for-multicoinearity",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "check_collinearity() of performance package is used to check for multi correlation.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term  VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n               KM 1.46 [ 1.37,  1.57]         1.21      0.68     [0.64, 0.73]\n           Weight 1.41 [ 1.32,  1.51]         1.19      0.71     [0.66, 0.76]\n Guarantee_Period 1.04 [ 1.01,  1.17]         1.02      0.97     [0.86, 0.99]\n\nHigh Correlation\n\n      Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n  Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\n\n\ncheck_c &lt;- check_collinearity(model)\n\nplot(check_c)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#checking-normality-assumption",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#checking-normality-assumption",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "We will use check_normality() of performance package.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#checking-for-homogeneity-of-variances",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#checking-for-homogeneity-of-variances",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "check_h &lt;- check_heteroscedasticity(model1)\n\nplot(check_h)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#complete-check-method",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#complete-check-method",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "check_model(model1)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#visualising-regression-parameters-see-methods",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#visualising-regression-parameters-see-methods",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "In the code below, plot() of see package and parameters() of parameters package is used to visualise the parameters of a regression model.\n\nplot(parameters(model1))"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#visualising-regression-parameters-ggcoefstats-method",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#visualising-regression-parameters-ggcoefstats-method",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "",
    "text": "In the code below, ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#getting-started-1",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#getting-started-1",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "2.1 Getting Started",
    "text": "2.1 Getting Started\nFor the purpose of this exercise, the following R packages will be used, they are:\n\ntidyverse, a family of R packages for data science process,\nplotly for creating interactive plot,\ngganimate for creating animation plot,\nDT for displaying interactive html table,\ncrosstalk for for implementing cross-widget interactions (currently, linked brushing and filtering), and\nggdist for visualising distribution and uncertainty.\n\n\ndevtools::install_github(\"wilkelab/ungeviz\")\n\n\npacman::p_load(ungeviz, plotly, crosstalk,\n               DT, ggdist, ggridges,\n               colorspace, gganimate, tidyverse)\n\nWe will be utilising the exam_data for this exercise."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#visualizing-the-uncertainty-of-point-estimates-ggplot2-methods",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "2.2 Visualizing the uncertainty of point estimates: ggplot2 methods",
    "text": "2.2 Visualizing the uncertainty of point estimates: ggplot2 methods\nA point estimate is a single number, such as a mean. Uncertainty, on the other hand, is expressed as standard error, confidence interval, or credible interval. Note: Don’t confuse the uncertainty of a point estimate with the variation in the sample.\n\n\n\n\n\n\nNote\n\n\n\nIn this section, you will learn how to plot error bars of maths scores by race by using data provided in exam tibble data frame.\n\n\nFirstly, code chunk below will be used to derive the necessary summary statistics.\n\nmy_sum &lt;- exam_data %&gt;%\n  group_by(RACE) %&gt;%\n  summarise(\n    n=n(),\n    mean=mean(MATHS),\n    sd=sd(MATHS)\n    ) %&gt;%\n  mutate(se=sd/sqrt(n-1))\n\n\n\n\n\n\n\nNote\n\n\n\n\ngroup_by() of dplyr package is used to group the observation by RACE,\nsummarise() is used to compute the count of observations, mean, standard deviation\nmutate() is used to derive standard error of Maths by RACE, and\nthe output is save as a tibble data table called my_sum.\n\n\n\nNext, the code chunk below will be used to display my_sum tibble data frame in an html table format.\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n\n\nRACE\nn\nmean\nsd\nse\n\n\n\n\nChinese\n193\n76.50777\n15.69040\n1.132357\n\n\nIndian\n12\n60.66667\n23.35237\n7.041005\n\n\nMalay\n108\n57.44444\n21.13478\n2.043177\n\n\nOthers\n9\n69.66667\n10.72381\n3.791438\n\n\n\n\n\n\n\n\n\n2.2.1 Plotting Standard Error Bars of Point Estimates\nNow we are ready to plot the standard error bars of mean maths score by race as shown below.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\n2.2.2 Plotting Confidence Interval of Point Estimates\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=reorder(RACE, -mean), \n        ymin=mean-1.96*se, \n        ymax=mean+1.96*se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  labs(x = \"Maths score\",\n       title = \"95% confidence interval of mean maths score by race\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe confidence intervals are computed by using the formula mean+/-1.96*se.\nThe error bars is sorted by using the average maths scores.\nlabs() argument of ggplot2 is used to change the x-axis label.\n\n\n\n\n\n2.2.3 Visualizing the uncertainty of point estimates with interactive error bars\n\nshared_df = SharedData$new(my_sum)\n\nbscols(widths = c(4,8),\n       ggplotly((ggplot(shared_df) +\n                   geom_errorbar(aes(\n                     x=reorder(RACE, -mean),\n                     ymin=mean-2.58*se, \n                     ymax=mean+2.58*se), \n                     width=0.2, \n                     colour=\"black\", \n                     alpha=0.9, \n                     size=0.5) +\n                   geom_point(aes(\n                     x=RACE, \n                     y=mean, \n                     text = paste(\"Race:\", `RACE`, \n                                  \"&lt;br&gt;N:\", `n`,\n                                  \"&lt;br&gt;Avg. Scores:\", round(mean, digits = 2),\n                                  \"&lt;br&gt;95% CI:[\", \n                                  round((mean-2.58*se), digits = 2), \",\",\n                                  round((mean+2.58*se), digits = 2),\"]\")),\n                     stat=\"identity\", \n                     color=\"red\", \n                     size = 1.5, \n                     alpha=1) + \n                   xlab(\"Race\") + \n                   ylab(\"Average Scores\") + \n                   theme_minimal() + \n                   theme(axis.text.x = element_text(\n                     angle = 45, vjust = 0.5, hjust=1)) +\n                   ggtitle(\"99% Confidence interval of average /&lt;br&gt;maths scores by race\")), \n                tooltip = \"text\"), \n       DT::datatable(shared_df, \n                     rownames = FALSE, \n                     class=\"compact\", \n                     width=\"100%\", \n                     options = list(pageLength = 10,\n                                    scrollX=T), \n                     colnames = c(\"No. of pupils\", \n                                  \"Avg Scores\",\n                                  \"Std Dev\",\n                                  \"Std Error\")) %&gt;%\n         formatRound(columns=c('mean', 'sd', 'se'),\n                     digits=2))"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#visualising-uncertainty-ggdist-package",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#visualising-uncertainty-ggdist-package",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "2.3 Visualising Uncertainty: ggdist package",
    "text": "2.3 Visualising Uncertainty: ggdist package\n\nggdist is an R package that provides a flexible set of ggplot2 geoms and stats designed especially for visualising distributions and uncertainty.\nIt is designed for both frequentist and Bayesian uncertainty visualization, taking the view that uncertainty visualization can be unified through the perspective of distribution visualization:\n\nfor frequentist models, one visualises confidence distributions or bootstrap distributions (see vignette(“freq-uncertainty-vis”));\nfor Bayesian models, one visualises probability distributions (see the tidybayes package, which builds on top of ggdist).\n\n\n\n2.3.1 Visualizing the uncertainty of point estimates: ggdist methods\n\nexam_data %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nFor example, in the code chunk below the following arguments are used:\n\n.width = 0.95\n.point = median\n.interval = qi\n\n\nexam_data %&gt;%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95,\n  .point = median,\n  .interval = qi) +\n  labs(\n    title = \"Visualising confidence intervals of median math score\",\n    subtitle = \"Median Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\nMakeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\nexam_data %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_pointinterval(\n    show.legend = FALSE) +   \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\n\n\n\n\n\n\n2.3.2 Using stat_gradientinterval() of ggdist\nIn the code chunk below, stat_gradientinterval() of ggdist is used to build a visual for displaying distribution of maths scores by race.\n\nexam_data %&gt;%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#visualising-uncertainty-with-hypothetical-outcome-plots-hops",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "2.4 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)",
    "text": "2.4 Visualising Uncertainty with Hypothetical Outcome Plots (HOPs)\n\nlibrary(ungeviz)\n\n\nggplot(data = exam_data, \n       (aes(x = factor(RACE), y = MATHS))) +\n  geom_point(position = position_jitter(\n    height = 0.3, width = 0.05), \n    size = 0.4, color = \"#0072B2\", alpha = 1/2) +\n  geom_hpline(data = sampler(25, group = RACE), height = 0.6, color = \"#D55E00\") +\n  theme_bw() + \n  # `.draw` is a generated column indicating the sample draw\n  transition_states(.draw, 1, 3)\n\nNULL"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#getting-started-2",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#getting-started-2",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "3.1 Getting Started",
    "text": "3.1 Getting Started\nIn this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.In this exercise, four R packages will be used. They are:\n\nreadr for importing csv into R.\nFunnelPlotR for creating funnel plot.\nggplot2 for creating funnel plot manually.\nknitr for building static html table.\nplotly for creating interactive funnel plot.\n\n\n\npacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#importing-data",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#importing-data",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "3.2 Importing Data",
    "text": "3.2 Importing Data\nIn this section, COVID-19_DKI_Jakarta will be used. The data was downloaded from Open Data Covid-19 Provinsi DKI Jakarta portal. For this hands-on exercise, we are going to compare the cumulative COVID-19 cases and death by sub-district (i.e. kelurahan) as at 31st July 2021, DKI Jakarta.\nThe code chunk below imports the data into R and save it into a tibble data frame object called covid19.\n\ncovid19 &lt;- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %&gt;%\n  mutate_if(is.character, as.factor)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#funnelplotr-methods",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#funnelplotr-methods",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "3.3 FunnelPlotR Methods",
    "text": "3.3 FunnelPlotR Methods\nFunnelPlotR package uses ggplot to generate funnel plots. It requires a numerator (events of interest), denominator (population to be considered) and group. The key arguments selected for customisation are:\n\nlimit: plot limits (95 or 99).\nlabel_outliers: to label outliers (true or false).\nPoisson_limits: to add Poisson limits to the plot.\nOD_adjust: to add overdispersed limits to the plot.\nxrange and yrange: to specify the range to display for axes, acts like a zoom function.\nOther aesthetic components such as graph title, axis labels etc.\n\n\n3.3.1 Basic Plot\n\nfunnel_plot(\n  covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\ngroup in this function is different from the scatterplot. Here, it defines the level of the points to be plotted i.e. Sub-district, District or City. If Cityc is chosen, there are only six data points.\nBy default, data_typeargument is “SR”.\nlimit: Plot limits, accepted values are: 95 or 99, corresponding to 95% or 99.8% quantiles of the distribution."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#funnelplotr-methods-makeover-1",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#funnelplotr-methods-makeover-1",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "3.4 FunnelPlotR methods: Makeover 1",
    "text": "3.4 FunnelPlotR methods: Makeover 1\n\nfunnel_plot(\n  covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = 'Sub-district',\n  data_type = \"RC\",\n  x_range = c(0, 150),  #&lt;&lt;\n  y_range = c(0, 500)\n  )\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 27 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\nfunnel_plot(\n  covid19,\n  numerator = Positive,\n  denominator = Death,\n  group = `Sub-district`,\n  data_type = \"RC\",   \n  x_range = c(0, 150),  #&lt;&lt;\n  y_range = c(0, 500),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #&lt;&lt;           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #&lt;&lt;\n  y_label = \"Cumulative Fatality Rate\"  #&lt;&lt;\n)\n\n\n\n\n\n\n\n\nA funnel plot object with 267 points of which 27 are outliers. \nPlot is adjusted for overdispersion. \n\n\nThings to learn from the code chunk above.\n\nlabel = NA argument is to removed the default label outliers feature.\ntitle argument is used to add plot title.\nx_label and y_label arguments are used to add/edit x-axis and y-axis titles."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#using-ggplot2-methods",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#using-ggplot2-methods",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "3.5 Using ggplot2 methods",
    "text": "3.5 Using ggplot2 methods\nIn this section, you will gain hands-on experience on building funnel plots step-by-step by using ggplot2. It aims to enhance you working experience of ggplot2 to customise speciallised data visualisation like funnel plot.\n\n3.5.1 Computing the basic derived fields\nTo plot the funnel plot from scratch, we need to derive cumulative death rate and standard error of cumulative death rate.\n\ndf &lt;- covid19 %&gt;%\n  mutate(rate = Death / Positive) %&gt;%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %&gt;%\n  filter(rate &gt; 0)\n\nNext, the fit.mean is computed by using the code chunk below.\n\nfit.mean &lt;- weighted.mean(df$rate, 1/df$rate.se^2)\n\nThe code chunk below is used to compute the lower and upper limits for 95% confidence interval.\n\nnumber.seq &lt;- seq(1, max(df$Positive), 1)\nnumber.ll95 &lt;- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 &lt;- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 &lt;- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 &lt;- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI &lt;- data.frame(number.ll95, number.ul95, number.ll999, \n                   number.ul999, number.seq, fit.mean)\n\nIn the code chunk below, ggplot2 functions are used to plot a static funnel plot.\n\np &lt;- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            size = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            size = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             size = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\np"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx4/handsonex4.html#interactive-funnel-plot-plotly-ggplot2",
    "href": "HandsOnEx/HandsOnEx4/handsonex4.html#interactive-funnel-plot-plotly-ggplot2",
    "title": "Hands On Ex 4 - Fundamentals of Visual Analytics",
    "section": "3.5 Interactive Funnel Plot: plotly + ggplot2",
    "text": "3.5 Interactive Funnel Plot: plotly + ggplot2\nThe funnel plot created using ggplot2 functions can be made interactive with ggplotly() of plotly r package.\n\nfp_ggplotly &lt;- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "In this hands-on exercise, we will learn how to model, analyse and visualise network data using R.\nBy the end of this hands-on exercise, you will be able to:\n\ncreate graph object data frames, manipulate them using appropriate functions of dplyr, lubridate, and tidygraph,\nbuild network graph visualisation using appropriate functions of ggraph,\ncompute network geometrics using tidygraph,\nbuild advanced graph visualisation by incorporating the network geometrics, and\nbuild interactive network visualisation using visNetwork package.\n\nIn this hands-on exercise, four network data modelling and visualisation packages will be installed and launched. They are igraph, tidygraph, ggraph and visNetwork. Beside these four packages, tidyverse and lubridate, an R package specially designed to handle and wrangling time data will be installed and launched too.\nThe code chunk:\n\npacman::p_load(igraph, tidygraph, ggraph, visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\n\n\nThe data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\n\nUsing glimpse() from dplyr package.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type.\n\n\n\n\nGAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nNote\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\nNotice that SendDate is now a date field.\n\n\n\nA close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nNote\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#data",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#data",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "The data sets used in this hands-on exercise is from an oil exploration and extraction company. There are two data sets. One contains the nodes data and the other contains the edges (also know as link) data.\n\nGAStech-email_edges.csv which consists of two weeks of 9063 emails correspondances between 55 employees.\nGAStech_email_nodes.csv which consist of the names, department and title of the 55 employees.\n\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges &lt;- read_csv(\"data/GAStech_email_edge-v2.csv\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#examine-the-data",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#examine-the-data",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "Using glimpse() from dplyr package.\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 8\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n\n\nThe output report of GAStech_edges above reveals that the SentDate is treated as “Character” data type instead of date data type. This is an error! Before we continue, it is important for us to change the data type of SentDate field back to “Date”” data type."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#adjusting-time-data",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#adjusting-time-data",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "GAStech_edges &lt;- GAStech_edges %&gt;%\n  mutate(SendDate = dmy(SentDate)) %&gt;%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n\n\n\n\n\nNote\n\n\n\n\nboth dmy() and wday() are functions of lubridate package. lubridate is an R package that makes it easier to work with dates and times.\ndmy() transforms the SentDate to Date data type.\nwday() returns the day of the week as a decimal number or an ordered factor if label is TRUE. The argument abbr is FALSE keep the daya spells in full, i.e. Monday. The function will create a new column in the data.frame i.e. Weekday and the output of wday() will save in this newly created field.\nthe values in the Weekday field are in ordinal scale.\n\n\n\n\nglimpse(GAStech_edges)\n\nRows: 9,063\nColumns: 10\n$ source      &lt;dbl&gt; 43, 43, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 26, 26, 26…\n$ target      &lt;dbl&gt; 41, 40, 51, 52, 53, 45, 44, 46, 48, 49, 47, 54, 27, 28, 29…\n$ SentDate    &lt;chr&gt; \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\", \"6/1/2014\"…\n$ SentTime    &lt;time&gt; 08:39:00, 08:39:00, 08:58:00, 08:58:00, 08:58:00, 08:58:0…\n$ Subject     &lt;chr&gt; \"GT-SeismicProcessorPro Bug Report\", \"GT-SeismicProcessorP…\n$ MainSubject &lt;chr&gt; \"Work related\", \"Work related\", \"Work related\", \"Work rela…\n$ sourceLabel &lt;chr&gt; \"Sven.Flecha\", \"Sven.Flecha\", \"Kanon.Herrero\", \"Kanon.Herr…\n$ targetLabel &lt;chr&gt; \"Isak.Baza\", \"Lucas.Alcazar\", \"Felix.Resumir\", \"Hideki.Coc…\n$ SendDate    &lt;date&gt; 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-06, 2014-01-0…\n$ Weekday     &lt;ord&gt; Friday, Friday, Friday, Friday, Friday, Friday, Friday, Fr…\n\n\nNotice that SendDate is now a date field."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#adjusting-the-attributes",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#adjusting-the-attributes",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "",
    "text": "A close examination of GAStech_edges data.frame reveals that it consists of individual e-mail flow records. This is not very useful for visualisation.\nIn view of this, we will aggregate the individual by date, senders, receivers, main subject and day of the week.\nThe code chunk:\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(source, target, Weekday) %&gt;%\n    summarise(Weight = n()) %&gt;%\n  filter(source!=target) %&gt;%\n  filter(Weight &gt; 1) %&gt;%\n  ungroup()\n\n\n\n\n\n\n\nNote\n\n\n\n\nfour functions from dplyr package are used. They are: filter(), group(), summarise(), and ungroup().\nThe output data.frame is called GAStech_edges_aggregated.\nA new field called Weight has been added in GAStech_edges_aggregated.\n\n\n\n\nglimpse(GAStech_edges_aggregated)\n\nRows: 1,372\nColumns: 4\n$ source  &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ target  &lt;dbl&gt; 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 6,…\n$ Weekday &lt;ord&gt; Sunday, Monday, Tuesday, Wednesday, Friday, Sunday, Monday, Tu…\n$ Weight  &lt;int&gt; 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5, 2, 3, 4, 6, 5,…"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#the-tbl_graph-object",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#the-tbl_graph-object",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "2.1 The tbl_graph object",
    "text": "2.1 The tbl_graph object\nTwo functions of tidygraph package can be used to create network objects, they are:\n\ntbl_graph() creates a tbl_graph network object from nodes and edges data.\nas_tbl_graph() converts network data and objects to a tbl_graph network. Below are network data and objects supported by as_tbl_graph()\n\na node data.frame and an edge data.frame,\ndata.frame, list, matrix from base,\nigraph from igraph,\nnetwork from network,\ndendrogram and hclust from stats,\nNode from data.tree,\nphylo and evonet from ape, and\ngraphNEL, graphAM, graphBAM from graph (in Bioconductor)."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#activate-verb",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#activate-verb",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "2.2 Activate() verb",
    "text": "2.2 Activate() verb\n\nactivate() verb from tidygraph serves as a switch between tibbles for nodes and edges. All dplyr verbs applied to tbl_graph object are applied to the active tibble.\n\ne.g.\n\n\nIn the above the .N() function is used to gain access to the node data while manipulating the edge data. Similarly .E() will give you the edge data and .G() will give you the tbl_graph object itself."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#building-the-graph-model",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#building-the-graph-model",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "2.3 Building the graph model",
    "text": "2.3 Building the graph model\nIn this section, you will use tbl_graph() of tidygraph package to build an tidygraph’s network graph data.frame.\nBefore typing the codes, you are recommended to review to reference guide of tbl_graph()\n\nGAStech_graph &lt;- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n      id label               Department     Title                               \n   &lt;dbl&gt; &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;                               \n 1     1 Mat.Bramar          Administration Assistant to CEO                    \n 2     2 Anda.Ribera         Administration Assistant to CFO                    \n 3     3 Rachel.Pantanal     Administration Assistant to CIO                    \n 4     4 Linda.Lagos         Administration Assistant to COO                    \n 5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Mana…\n 6     6 Carla.Forluniau     Administration Assistant to IT Group Manager       \n 7     7 Cornelia.Lais       Administration Assistant to Security Group Manager \n 8    44 Kanon.Herrero       Security       Badging Office                      \n 9    45 Varja.Lagos         Security       Badging Office                      \n10    46 Stenig.Fusil        Security       Building Control                    \n# ℹ 44 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  &lt;int&gt; &lt;int&gt; &lt;ord&gt;    &lt;int&gt;\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# ℹ 1,369 more rows\n\n\n\nThe output above reveals that GAStech_graph is a tbl_graph object with 54 nodes and 4541 edges.\nThe command also prints the first six rows of “Node Data” and the first three of “Edge Data”.\nIt states that the Node Data is active. The notion of an active tibble within a tbl_graph object makes it possible to manipulate the data in one tibble at a time."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#changing-the-active-object",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#changing-the-active-object",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "2.4 Changing the Active Object",
    "text": "2.4 Changing the Active Object\nThe nodes tibble data frame is activated by default, but you can change which tibble data frame is active with the activate() function. Thus, if we wanted to rearrange the rows in the edges tibble to list those with the highest “weight” first, we could use activate() and then arrange().\nFor example,\n\nGAStech_graph %&gt;%\n  activate(edges) %&gt;%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n    from    to Weekday   Weight\n   &lt;int&gt; &lt;int&gt; &lt;ord&gt;      &lt;int&gt;\n 1    40    41 Saturday      13\n 2    41    43 Monday        11\n 3    35    31 Tuesday       10\n 4    40    41 Monday        10\n 5    40    43 Monday        10\n 6    36    32 Sunday         9\n 7    40    43 Saturday       9\n 8    41    40 Monday         9\n 9    19    15 Wednesday      8\n10    35    38 Tuesday        8\n# ℹ 1,362 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;          &lt;chr&gt;           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# ℹ 51 more rows\n\n\nVisit the reference guide of activate() to find out more about the function."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#plotting-a-basic-network-graph",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#plotting-a-basic-network-graph",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "3.1 Plotting a basic network graph",
    "text": "3.1 Plotting a basic network graph\nThe code chunk below uses ggraph(), geom-edge_link() and geom_node_point() to plot a network graph by using GAStech_graph. Before your get started, it is advisable to read their respective reference guide at least once.\n\nggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nThe basic plotting function is ggraph(), which takes the data to be used for the graph and the type of layout desired. Both of the arguments for ggraph() are built around igraph. Therefore, ggraph() can use either an igraph object or a tbl_graph object."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#changing-theme",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#changing-theme",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "3.2 Changing theme",
    "text": "3.2 Changing theme\n\ng &lt;- ggraph(GAStech_graph) +\n  geom_edge_link() +\n  geom_node_point()\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nggraph introduces a special ggplot theme that provides better defaults for network graphs than the normal ggplot defaults. theme_graph(), besides removing axes, grids, and border, changes the font to Arial Narrow (this can be overridden).\nThe ggraph theme can be set for a series of plots with the set_graph_style() command run before the graphs are plotted or by using theme_graph() in the individual plots."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#changing-colour",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#changing-colour",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "3.3 Changing Colour",
    "text": "3.3 Changing Colour\nFurthermore, theme_graph() makes it easy to change the coloring of the plot.\n\ng &lt;- ggraph(GAStech_graph) + \n  geom_edge_link(aes(colour = 'grey50')) +\n  geom_node_point(aes(colour = 'grey40'))\n\ng + theme_graph(background = 'grey10',\n                text_colour = 'white')"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#working-with-layout",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#working-with-layout",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "3.4 Working with layout",
    "text": "3.4 Working with layout\nggraph support many layout for standard used, they are: star, circle, nicely (default), dh, gem, graphopt, grid, mds, spahere, randomly, fr, kk, drl and lgl. Figures below and on the right show layouts supported by ggraph()."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#fruchterman-and-reingold-layout",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#fruchterman-and-reingold-layout",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "3.5 Fruchterman and Reingold layout",
    "text": "3.5 Fruchterman and Reingold layout\nThe code chunks below will be used to plot the network graph using Fruchterman and Reingold layout.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"fr\") +\n  geom_edge_link(aes()) +\n  geom_node_point(aes())\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nlayout argument is used to define the layout to be used."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#modifying-network-nodes",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#modifying-network-nodes",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "3.6 Modifying Network Nodes",
    "text": "3.6 Modifying Network Nodes\nIn this section, you will colour each node by referring to their respective departments.\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes()) +\n  geom_node_point(aes(colour = Department, \n                      size = 3))\n\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunks above:\n\ngeom_node_point is equivalent in functionality to geo_point of ggplot2. It allows for simple plotting of nodes in different shapes, colours and sizes. In the codes chunk above - colour and size are used."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#modifying-edges",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#modifying-edges",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "3.7 Modifying Edges",
    "text": "3.7 Modifying Edges\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\n\n\n\n\ngeom_edge_link draws edges in the simplest way - as straight lines between the start and end nodes. But, it can do more that that. In the example above, argument width is used to map the width of the line in proportional to the Weight attribute and argument alpha is used to introduce opacity on the line."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#creating-facet-graphs",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#creating-facet-graphs",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "3.8 Creating facet graphs",
    "text": "3.8 Creating facet graphs\nAnother very useful feature of ggraph is faceting. In visualising network data, this technique can be used to reduce edge over-plotting in a very meaning way by spreading nodes and edges out based on their attributes. In this section, you will learn how to use faceting technique to visualise network data.\nThere are three functions in ggraph to implement faceting, they are:\n\nfacet_nodes() whereby edges are only draw in a panel if both terminal nodes are present here,\nfacet_edges() whereby nodes are always drawn in al panels even if the node data contains an attribute named the same as the one used for the edge facetting, and\nfacet_graph() faceting on two variables simultaneously.\n\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#working-with-facet_edges",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#working-with-facet_edges",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "3.9 Working with facet_edges()",
    "text": "3.9 Working with facet_edges()\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2) +\n  theme(legend.position = 'bottom')\n  \ng + facet_edges(~Weekday)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#framed-facet",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#framed-facet",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "3.10 Framed Facet",
    "text": "3.10 Framed Facet\n\nset_graph_style() \n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_edges(~Weekday) +\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#working-with-facet_nodes",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#working-with-facet_nodes",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "3.11 Working with facet_nodes()",
    "text": "3.11 Working with facet_nodes()\n\nset_graph_style()\n\ng &lt;- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n  \ng + facet_nodes(~Department)+\n  th_foreground(foreground = \"grey80\",  \n                border = TRUE) +\n  theme(legend.position = 'bottom')"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#computing-centrality-indices",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#computing-centrality-indices",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "4.1 Computing Centrality Indices",
    "text": "4.1 Computing Centrality Indices\nCentrality measures are a collection of statistical indices use to describe the relative important of the actors are to a network. There are four well-known centrality measures, namely: degree, betweenness, closeness and eigenvector. It is beyond the scope of this hands-on exercise to cover the principles and mathematics of these measure here. Students are encouraged to refer to Chapter 7: Actor Prominence of A User’s Guide to Network Analysis in R to gain better understanding of theses network measures.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(betweenness_centrality = centrality_betweenness()) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nmutate() of dplyr is used to perform the computation.\nthe algorithm used, on the other hand, is the centrality_betweenness() of tidygraph."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#visualising-network-metrics",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#visualising-network-metrics",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "4.2 Visualising network metrics",
    "text": "4.2 Visualising network metrics\nIt is important to note that from ggraph v2.0 onward tidygraph algorithms such as centrality measures can be accessed directly in ggraph calls. This means that it is no longer necessary to precompute and store derived node and edge centrality measures on the graph in order to use them in a plot.\n\ng &lt;- GAStech_graph %&gt;%\n  ggraph(layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department, \n                      size = centrality_betweenness()))\ng + theme_graph()"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#visualising-communities",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#visualising-communities",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "4.3 Visualising Communities",
    "text": "4.3 Visualising Communities\ntidygraph package inherits many of the community detection algorithms imbedded into igraph and makes them available to us, including Edge-betweenness (group_edge_betweenness), Leading eigenvector (group_leading_eigen), Fast-greedy (group_fast_greedy), Louvain (group_louvain), Walktrap (group_walktrap), Label propagation (group_label_prop), InfoMAP (group_infomap), Spinglass (group_spinglass), and Optimal (group_optimal). Some community algorithms are designed to take into account direction or weight, while others ignore it. Use this link to find out more about community detection functions provided by tidygraph,\nIn the code chunk below group_edge_betweenness() is used.\n\ng &lt;- GAStech_graph %&gt;%\n  mutate(community = as.factor(group_edge_betweenness(weights = Weight, directed = TRUE))) %&gt;%\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = community))  \n\ng + theme_graph()"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#data-prep",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#data-prep",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "5.1 Data Prep",
    "text": "5.1 Data Prep\n\nGAStech_edges_aggregated &lt;- GAStech_edges %&gt;%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %&gt;%\n  rename(from = id) %&gt;%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %&gt;%\n  rename(to = id) %&gt;%\n  filter(MainSubject == \"Work related\") %&gt;%\n  group_by(from, to) %&gt;%\n    summarise(weight = n()) %&gt;%\n  filter(from!=to) %&gt;%\n  filter(weight &gt; 1) %&gt;%\n  ungroup()"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#first-interactive-graph",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#first-interactive-graph",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "5.2 First interactive graph",
    "text": "5.2 First interactive graph\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") \n\n\n\n\n\nVisit Igraph to find out more about visIgraphLayout’s argument."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#working-with-visual-attributes---nodes",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#working-with-visual-attributes---nodes",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "5.3 Working with visual attributes - Nodes",
    "text": "5.3 Working with visual attributes - Nodes\nvisNetwork() looks for a field called “group” in the nodes object and colour the nodes according to the values of the group field.\nThe code chunk below rename Department field to group.\n\nGAStech_nodes &lt;- GAStech_nodes %&gt;%\n  rename(group = Department) \n\nWhen we rerun the code chunk below, visNetwork shades the nodes by assigning unique colour to each category in the group field.\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#working-with-visual-attributes---edges",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#working-with-visual-attributes---edges",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "5.4 Working with visual attributes - Edges",
    "text": "5.4 Working with visual attributes - Edges\nIn the code run below visEdges() is used to symbolise the edges.\n- The argument arrows is used to define where to place the arrow.\n- The smooth argument is used to plot the edges using a smooth curve.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visEdges(arrows = \"to\", \n           smooth = list(enabled = TRUE, \n                         type = \"curvedCW\")) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)\n\n\n\n\n\nVisit Option to find out more about visEdges’s argument."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#interactivity",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#interactivity",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "5.5 Interactivity",
    "text": "5.5 Interactivity\nIn the code chunk below, visOptions() is used to incorporate interactivity features in the data visualisation.\n\nThe argument highlightNearest highlights nearest when clicking a node.\nThe argument nodesIdSelection adds an id node selection creating an HTML select element.\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLegend() %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx6/handsonex6.html#creating-my-own-interactive-network-graph",
    "href": "HandsOnEx/HandsOnEx6/handsonex6.html#creating-my-own-interactive-network-graph",
    "title": "Hands On Ex 6 - Modelling, Visualising and Analysing Network Data with R",
    "section": "5.6 Creating my own Interactive Network Graph",
    "text": "5.6 Creating my own Interactive Network Graph\nThe legend looks a bit ugly. Let’s see how to make the graph nicers.\nUsing different fonts for R plots may take a little bit of work. This is especially true if you are using Windows - Mac & Linux users can most likely skip all of this.\nIn order to import fonts from the OS into R, we can use the ‘extrafont’ package:\n\ninstall.packages('extrafont')\nlibrary('extrafont')\n\n# Import system fonts - may take a while, so DO NOT run this during the workshop.\nfont_import() \nfonts() # See what font families are available to you now.\nloadfonts(device = \"win\") # use device = \"pdf\" for pdf plot output. \n\nFound a website that looks at manipulating the images of network graphs:\nhttps://kateto.net/polnet2017.html\n\nGAStech_nodes &lt;- read_csv(\"data/GAStech_email_node.csv\")\n\n\nGAStech_nodes$shape &lt;- \"dot\"  \nGAStech_nodes$shadow &lt;- TRUE # Nodes will drop shadow\nGAStech_nodes$title &lt;- GAStech_nodes$id # Text on click\nGAStech_nodes$borderWidth &lt;- 2 # Node border width\n\nGAStech_nodes$group &lt;- as.factor(GAStech_nodes$Department)\n\nGAStech_nodes$color.background &lt;- c(\"slategrey\", \"tomato\", \"gold\", \"darkblue\", \"brown\", \"pink\")[GAStech_nodes$group]\nGAStech_nodes$color.border &lt;- \"black\"\nGAStech_nodes$color.highlight.background &lt;- \"orange\"\nGAStech_nodes$color.highlight.border &lt;- \"darkred\"\n\n\nGAStech_edges_aggregated$width &lt;- 1+GAStech_edges_aggregated$weight/6 # line width\nGAStech_edges_aggregated$color &lt;- \"gray\"    # line color  \nGAStech_edges_aggregated$arrows &lt;- \"to\" # arrows: 'from', 'to', or 'middle'\nGAStech_edges_aggregated$smooth &lt;- TRUE    # should the edges be curved?\nGAStech_edges_aggregated$shadow &lt;- FALSE    # edge shadow\n\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated, \n           height = \"500px\", width = \"100%\",\n           main = \"Network Graph of Emails\", \n           submain = list(text = \"Custom subtitle\",\n                          style = \"font-family:Segoe UI;color:grey;font-size:10px;text-align:left;\"), \n           footer = \"Fig.1 minimal example\") %&gt;%\n  visIgraphLayout(layout = \"layout_with_fr\") %&gt;%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %&gt;%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html",
    "title": "Visualising Geospatial Data",
    "section": "",
    "text": "pacman::p_load(sf, tmap, readr, ggplot2, tidyverse)\n\n\n\n\nExtracted the necessary data sets from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\n\n\nmpsz = st_read(dsn = \"data/geospatial\", \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjjgithubb\\ISSS608VA\\HandsOnEx\\HandsOnEx8\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\n\n\nSimple data checking to verify that the data is correct.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nSimple plotting:\n\nplot(mpsz)\n\n\n\n\n\n\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\n\nNeed to ensure that the geospatial data are projected using a similar coordinate system. For Singapore data - we will use EPSG Code 3414 for Svy21.\nIn order to assign the correct EPSG code, we will utilise the st_set_crs() of the sf package.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the code is now 3414."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#loading-packages",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#loading-packages",
    "title": "Visualising Geospatial Data",
    "section": "",
    "text": "pacman::p_load(sf, tmap, readr, ggplot2, tidyverse)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#loading-dataset-geospatial-data",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#loading-dataset-geospatial-data",
    "title": "Visualising Geospatial Data",
    "section": "",
    "text": "Extracted the necessary data sets from the following sources:\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\n\n\nmpsz = st_read(dsn = \"data/geospatial\", \n               layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zjjgithubb\\ISSS608VA\\HandsOnEx\\HandsOnEx8\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#checking-the-data",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#checking-the-data",
    "title": "Visualising Geospatial Data",
    "section": "",
    "text": "Simple data checking to verify that the data is correct.\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nSimple plotting:\n\nplot(mpsz)\n\n\n\n\n\n\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\n\n\n\n\n\n\nNeed to ensure that the geospatial data are projected using a similar coordinate system. For Singapore data - we will use EPSG Code 3414 for Svy21.\nIn order to assign the correct EPSG code, we will utilise the st_set_crs() of the sf package.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the code is now 3414."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#utilising-data-on-planning-subzone-and-singapore-residents",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#utilising-data-on-planning-subzone-and-singapore-residents",
    "title": "Visualising Geospatial Data",
    "section": "2.1 Utilising Data on Planning Subzone and Singapore Residents",
    "text": "2.1 Utilising Data on Planning Subzone and Singapore Residents\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e. respopagesextod2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile.\n\nImporting Data:\nThe Planning Subzone data is already imported -&gt; mpsz\nImporting the attribute data:\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesextod2011to2020.csv\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#data-preparation",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#data-preparation",
    "title": "Visualising Geospatial Data",
    "section": "2.2 Data Preparation",
    "text": "2.2 Data Preparation\nBefore a thematic map can be prepared, we need to prepare data table with year 2020 values. The data table should include the variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, DEPENDENCY.\n\nYOUNG: age group 0 to 4 until age groyup 20 to 24,\nECONOMY ACTIVE: age group 25-29 until age group 60-64,\nAGED: age group 65 and above,\nTOTAL: all age group, and\nDEPENDENCY: the ratio between young and aged against economy active group\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#joining-the-data-with-geospatial-data",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#joining-the-data-with-geospatial-data",
    "title": "Visualising Geospatial Data",
    "section": "2.3 Joining the data with geospatial data",
    "text": "2.3 Joining the data with geospatial data\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nThing to learn from the code chunk above:\n\nleft_join() of dplyr package is used with mpsz simple feature data frame as the left data table is to ensure that the output will be a simple features data frame.\n\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#using-tmap",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#using-tmap",
    "title": "Visualising Geospatial Data",
    "section": "2.4 Using tmap",
    "text": "2.4 Using tmap\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n2.4.1 Using qtm()\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ntmap_mode() with “plot” option is used to produce a static map. For interactive mode, “view” option should be used.\nfill argument is used to map the attribute (i.e. DEPENDENCY)\n\n\n\n2.4.2 Using tmap elements\nDespite its usefulness of drawing a choropleth map quickly and easily, the disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map as shown in the figure below, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n\n2.4.3 Drawing a base map\nThe basic building block of tmap is tm_shape() followed by one or more layer elemments such as tm_fill() and tm_polygons().\nIn the code chunk below, tm_shape() is used to define the input data (i.e mpsz_pop2020) and tm_polygons() is used to draw the planning subzone polygons.\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n2.4.4 Drawing a choropleth map using tm_polygons()\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to learn from tm_polygons():\n\nThe default interval binning used to draw the choropleth map is called “pretty”. A detailed discussion of the data classification methods supported by tmap will be provided in sub-section 4.3.\nThe default colour scheme used is YlOrRd of ColorBrewer. You will learn more about the color scheme in sub-section 4.4.\nBy default, Missing value will be shaded in grey.\n\n\n\n2.4.5 Drawing a choropleth map using tm_fill() and *tm_border()*\nActually, tm_polygons() is a wraper of tm_fill() and tm_border(). tm_fill() shades the polygons by using the default colour scheme and tm_borders() adds the borders of the shapefile onto the choropleth map.\nThe code chunk below draws a choropleth map by using tm_fill() alone.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nTo add the boundary of the planning subzones, tm_borders will be used as shown in the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map.\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n2.4.6 Data Classification methods of tmap\nMost choropleth maps employ some methods of data classification. The point of classification is to take a large number of observations and group them into data ranges or classes.\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\nTo define a data classification method, the style argument of tm_fill() or tm_polygons() will be used.\n\n\n2.4.7 Plotting choropleth maps with built in classification methods\ntmap provides a total ten data classification methods, namely: fixed, sd, equal, pretty (default), quantile, kmeans, hclust, bclust, fisher, and jenks.\n\nFixed: You manually set the class breaks.\nSD (Standard Deviation): Classes are defined based on the standard deviation of the data values.\nEqual: Data is divided into equal intervals.\nPretty (default): This method aims to generate “pretty” breaks that are human-readable and visually appealing.\nQuantile: Data is divided into classes so that each class contains an equal number of observations.\nKmeans: Class breaks are determined using k-means clustering.\nHclust (Hierarchical Clustering): Uses hierarchical clustering to define class breaks.\nBclust (Balanced Clustering): Balances the number of observations in each class while using clustering.\nFisher: Class breaks are determined using Fisher’s Jenks optimization algorithm.\nJenks: Jenks natural breaks optimization algorithm is used to find class breaks.\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn the code chunk below, equal data classification method is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\nDIY - Using different Classification methods supported by tmap and compare their differences\nUsing quantile\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nUsing kmeans\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nDIY - Similar Classification methods but with different number of classes - what are the observations?\nUsing different classes\n\nclass2 &lt;- tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5) + \n  tm_layout(legend.outside = TRUE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE)\n\nclass4 &lt;- tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 4,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5) + \n  tm_layout(legend.outside = TRUE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE)\n\nclass6 &lt;- tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5) + \n  tm_layout(legend.outside = TRUE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE)\n\nclass10 &lt;- tm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5) + \n  tm_layout(legend.outside = TRUE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE)\n\ntmap_arrange(class2, class4, class6, class10, asp=2, ncol=2)\n\n\n\n\n\n\n\n\nSeems to have a wrong value in Loyang West, Pasir Ris where the dependency value is 19.0, about ten times the rest of the data.\n\n\n\n2.4.8 Plotting choropleth map with custom break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n2.4.9 Color Scheme\ntmap supports colour ramps either defined by the user or a set of predefined colour ramps from the RColorBrewer package.\nUsing Color Brewer Palette:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nNotice that the choropleth map is shaded in green.\nTo reverse the colour shading, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n2.4.10 Map Layouts\nMap layout refers to the combination of all map elements into a cohensive map. Map elements include among others the objects to be mapped, the title, the scale bar, the compass, margins and aspects ratios. Colour settings and data classification methods covered in the previous section relate to the palette and break-points are used to affect how the map looks.\n\nMap Legend\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nMap Style\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\nCartographic Furniture\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n2.4.11 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, also referred to as facet maps, are composed of many maps arrange side-by-side, and sometimes stacked vertically. Small multiple maps enable the visualisation of how spatial relationships change with respect to another variable, such as time.\nIn tmap, small multiple maps can be plotted in three ways:\n\nby assigning multiple values to at least one of the asthetic arguments,\nby defining a group-by variable in tm_facets(), and\nby creating multiple stand-alone maps with tmap_arrange().\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\n\nBy using tm_facets()\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\nBy using tmap_arrange()\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n2.4.12 Mapping Spatial Object meeting a Selection Criteria\nInstead of creating small multiple choropleth map, you can also use selection funtion to map spatial objects meeting the selection criterion.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#overview-1",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#overview-1",
    "title": "Visualising Geospatial Data",
    "section": "3.1 Overview",
    "text": "3.1 Overview\nProportional symbol maps (also known as graduate symbol maps) are a class of maps that use the visual variable of size to represent differences in the magnitude of a discrete, abruptly changing phenomenon, e.g. counts of people. Like choropleth maps, you can create classed or unclassed versions of these maps. The classed ones are known as range-graded or graduated symbols, and the unclassed are called proportional symbols, where the area of the symbols are proportional to the values of the attribute being mapped. In this hands-on exercise, you will learn how to create a proportional symbol map showing the number of wins by Singapore Pools’ outlets using an R package called tmap."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#wrangling-with-the-data",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#wrangling-with-the-data",
    "title": "Visualising Geospatial Data",
    "section": "3.2 Wrangling with the data",
    "text": "3.2 Wrangling with the data\nThe data set use for this hands-on exercise is called SGPools_svy21. The data is in csv file format.\nFigure below shows the first 15 records of SGPools_svy21.csv. It consists of seven columns. The XCOORD and YCOORD columns are the x-coordinates and y-coordinates of SingPools outlets and branches. They are in Singapore SVY21 Projected Coordinates System.\nThe code chunk below uses read_csv() function of readr package to import SGPools_svy21.csv into R as a tibble data frame called sgpools.\n\nsgpools &lt;- read_csv(\"data/aspatial/SGPools_svy21.csv\")\n\n\nlist(sgpools)\n\n[[1]]\n# A tibble: 306 × 7\n   NAME           ADDRESS POSTCODE XCOORD YCOORD `OUTLET TYPE` `Gp1Gp2 Winnings`\n   &lt;chr&gt;          &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Mar… 2 Bayf…    18972 30842. 29599. Branch                        5\n 2 Livewire (Res… 26 Sen…    98138 26704. 26526. Branch                       11\n 3 SportsBuzz (K… Lotus …   738078 20118. 44888. Branch                        0\n 4 SportsBuzz (P… 1 Sele…   188306 29777. 31382. Branch                       44\n 5 Prime Serango… Blk 54…   552542 32239. 39519. Branch                        0\n 6 Singapore Poo… 1A Woo…   731001 21012. 46987. Branch                        3\n 7 Singapore Poo… Blk 64…   370064 33990. 34356. Branch                       17\n 8 Singapore Poo… Blk 88…   370088 33847. 33976. Branch                       16\n 9 Singapore Poo… Blk 30…   540308 33910. 41275. Branch                       21\n10 Singapore Poo… Blk 20…   560202 29246. 38943. Branch                       25\n# ℹ 296 more rows\n\n\nNotice that the sgpools data in tibble data frame and not the common R data frame."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#creating-a-sf-data-frame-from-an-aspatial-data-frame",
    "title": "Visualising Geospatial Data",
    "section": "3.3 Creating a sf data frame from an aspatial data frame",
    "text": "3.3 Creating a sf data frame from an aspatial data frame\nThe code chunk below converts sgpools data frame into a simple feature data frame by using st_as_sf() of sf packages:\n\nsgpools_sf &lt;- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\nThings to learn from the arguments above:\n\nThe coords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\nThe crs argument required you to provide the coordinates system in epsg format. EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by refering to epsg.io.\n\nNotice that a new column called geometry has been added into the data frame.\n\nlist(sgpools_sf)\n\n[[1]]\nSimple feature collection with 306 features and 5 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 7844.194 ymin: 26525.7 xmax: 45176.57 ymax: 47987.13\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 306 × 6\n   NAME                         ADDRESS POSTCODE `OUTLET TYPE` `Gp1Gp2 Winnings`\n * &lt;chr&gt;                        &lt;chr&gt;      &lt;dbl&gt; &lt;chr&gt;                     &lt;dbl&gt;\n 1 Livewire (Marina Bay Sands)  2 Bayf…    18972 Branch                        5\n 2 Livewire (Resorts World Sen… 26 Sen…    98138 Branch                       11\n 3 SportsBuzz (Kranji)          Lotus …   738078 Branch                        0\n 4 SportsBuzz (PoMo)            1 Sele…   188306 Branch                       44\n 5 Prime Serangoon North        Blk 54…   552542 Branch                        0\n 6 Singapore Pools Woodlands C… 1A Woo…   731001 Branch                        3\n 7 Singapore Pools 64 Circuit … Blk 64…   370064 Branch                       17\n 8 Singapore Pools 88 Circuit … Blk 88…   370088 Branch                       16\n 9 Singapore Pools Anchorvale … Blk 30…   540308 Branch                       21\n10 Singapore Pools Ang Mo Kio … Blk 20…   560202 Branch                       25\n# ℹ 296 more rows\n# ℹ 1 more variable: geometry &lt;POINT [m]&gt;\n\n\nThe output shows that sgppols_sf is in point feature class. It’s epsg ID is 3414. The bbox provides information of the extend of the geospatial data."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#drawing-proportional-symbol-map",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#drawing-proportional-symbol-map",
    "title": "Visualising Geospatial Data",
    "section": "3.4 Drawing proportional symbol map",
    "text": "3.4 Drawing proportional symbol map\nTo create an interactive proportional symbol map in R, the view mode of tmap will be used.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\nThe code chunks below are used to create an interactive point symbol map.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\nTo draw a proportional symbol map, we need to assign a numerical variable to the size visual attribute. The code chunks below show that the variable Gp1Gp2Winnings is assigned to size visual attribute.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"red\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\n\n3.4.1 Giving it different colors\nThe proportional symbol map can be further improved by using the colour visual attribute. In the code chunks below, OUTLET_TYPE variable is used as the colour attribute variable.\n\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1)\n\n\n\n\n\n\n\n3.4.2 Faceted Plots\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nBefore you end the session, it is wiser to switch tmap’s Viewer back to plot mode by using the code chunk below.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#overview-2",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#overview-2",
    "title": "Visualising Geospatial Data",
    "section": "4.1 Overview",
    "text": "4.1 Overview\nIn this in-class exercise, we will gain hands-on experience on using appropriate R methods to plot analytical maps.\n\nImporting geospatial data in rds format into R environment.\nCreating cartographic quality choropleth maps by using appropriate tmap functions.\nCreating rate map\nCreating percentile map\nCreating boxmap"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#data",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#data",
    "title": "Visualising Geospatial Data",
    "section": "4.2 Data",
    "text": "4.2 Data\nFor the purpose of this hands-on exercise, a prepared data set called NGA_wp.rds will be used. The data set is a polygon feature data.frame providing information on water point of Nigeria at the LGA level. You can find the data set in the rds sub-direct of the hands-on data folder.\n\nNGA_wp &lt;- read_rds(\"data/rds/NGA_wp.rds\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#basic-mapping",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#basic-mapping",
    "title": "Visualising Geospatial Data",
    "section": "4.3 Basic Mapping",
    "text": "4.3 Basic Mapping\n\np1 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\np2 &lt;- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total water point by LGAs\",\n            legend.outside = FALSE)\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#choropleth-map-for-rates",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#choropleth-map-for-rates",
    "title": "Visualising Geospatial Data",
    "section": "4.4. Choropleth Map for Rates",
    "text": "4.4. Choropleth Map for Rates\nIn much of our readings we have now seen the importance to map rates rather than counts of things, and that is for the simple reason that water points are not equally distributed in space. That means that if we do not account for how many water points are somewhere, we end up mapping total water point size rather than our topic of interest.\nWe will tabulate the proportion of functional water points and the proportion of non-functional water points in each LGA. In the following code chunk, mutate() from dplyr package is used to derive two fields, namely pct_functional and pct_nonfunctional.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  mutate(pct_functional = wp_functional/total_wp) %&gt;%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\ntm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"Blues\",\n          legend.hist = TRUE) +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Rate map of functional water point by LGAs\",\n            legend.outside = TRUE)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#extreme-value-maps",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#extreme-value-maps",
    "title": "Visualising Geospatial Data",
    "section": "4.5 Extreme Value Maps",
    "text": "4.5 Extreme Value Maps\nExtreme value maps are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers. These maps were developed in the spirit of spatializing EDA, i.e., adding spatial features to commonly used approaches in non-spatial EDA (Anselin 1994).\n\n4.5.1 Percentile Map\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\n\nNGA_wp &lt;- NGA_wp %&gt;%\n  drop_na()\n\nCreating custom classification and extracting values:\n\npercent &lt;- c(0,.01,.1,.5,.9,.99,1)\nvar &lt;- NGA_wp[\"pct_functional\"] %&gt;%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n\n\n\n\n\n\nNote\n\n\n\nWhen variables are extracted from an sf data.frame, the geometry is extracted as well. For mapping and spatial manipulation, this is the expected behavior, but many base R functions cannot deal with the geometry. Specifically, the quantile() gives an error. As a result st_set_geomtry(NULL) is used to drop geomtry field.\n\n\nWriting a function has three big advantages over using copy-and-paste:\n\nYou can give a function an evocative name that makes your code easier to understand.\nAs requirements change, you only need to update code in one place, instead of many.\nYou eliminate the chance of making incidental mistakes when you copy and paste (i.e. updating a variable name in one place, but not in another).\n\nSource: Chapter 19: Functions of R for Data Science.\n\nCreating the get.var function\nFirstly, we will write an R function as shown below to extract a variable (i.e. wp_nonfunctional) as a vector out of an sf data.frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\nA percentile mapping function\nNext, we will write a percentile mapping function by using the code chunk below.\n\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\n\nTest drive the percentile mapping function\nTo run the function, type the code chunk as shown below.\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\nNote that this is just a bare bones implementation. Additional arguments such as the title, legend positioning just to name a few of them, could be passed to customise various features of the map."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#box-map",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#box-map",
    "title": "Visualising Geospatial Data",
    "section": "4.5.2 Box Map",
    "text": "4.5.2 Box Map\nIn essence, a box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,        \n       aes(x = \"\",            \n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\nDisplaying summary statistics on a choropleth map by using the basic principles of boxplot.\nTo create a box map, a custom breaks specification will be used. However, there is a complication. The break points for the box map vary depending on whether lower or upper outliers are present.\n\n\nCreating the boxbreaks function\nThe code chunk below is an R function that creating break points for a box map.\n\narguments:\n\nv: vector with observations\nmult: multiplier for IQR (default 1.5)\n\nreturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\n\n\n\nCreating the get.var function\nThe code chunk below is an R function to extract a variable as a vector out of an sf data frame.\n\narguments:\n\nvname: variable name (as character, in quotes)\ndf: name of sf data frame\n\nreturns:\n\nv: vector with values (without a column name)\n\n\n\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\n\n\n\nTest drive the newly created function\nLet’s test the newly created function:\n\nvar &lt;- get.var(\"wp_nonfunctional\", NGA_wp) \n\nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\nBoxmap function\nThe code chunk below is an R function to create a box map. - arguments: - vnam: variable name (as character, in quotes) - df: simple features polygon layer - legtitle: legend title - mtitle: map title - mult: multiplier for IQR - returns: - a tmap-element (plots a map):\n\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#all-about-tmap-package",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#all-about-tmap-package",
    "title": "Visualising Geospatial Data",
    "section": "All about tmap package",
    "text": "All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#geospatial-data-wrangling",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#geospatial-data-wrangling",
    "title": "Visualising Geospatial Data",
    "section": "Geospatial data wrangling",
    "text": "Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx8/handsonex8.html#data-wrangling",
    "href": "HandsOnEx/HandsOnEx8/handsonex8.html#data-wrangling",
    "title": "Visualising Geospatial Data",
    "section": "Data wrangling",
    "text": "Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html",
    "href": "InClassEx/Ex02/inclassex02.html",
    "title": "In Class Ex 02",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggdist, ggthemes, ggridges, colorspace)\n\n\n\n\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html#loading-the-required-packages",
    "href": "InClassEx/Ex02/inclassex02.html#loading-the-required-packages",
    "title": "In Class Ex 02",
    "section": "",
    "text": "pacman::p_load(tidyverse, ggdist, ggthemes, ggridges, colorspace)"
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html#loading-exam-data",
    "href": "InClassEx/Ex02/inclassex02.html#loading-exam-data",
    "title": "In Class Ex 02",
    "section": "",
    "text": "exam_data &lt;- read_csv(\"data/Exam_data.csv\")"
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html#typical-way---using-histogram",
    "href": "InClassEx/Ex02/inclassex02.html#typical-way---using-histogram",
    "title": "In Class Ex 02",
    "section": "2.1 Typical way - Using Histogram",
    "text": "2.1 Typical way - Using Histogram\n\nggplot(data=exam_data, \n             aes(x = ENGLISH)) +\n  geom_histogram(bins=20, \n                 boundary = 100,\n                 color=\"grey25\", \n                 fill=\"grey90\") +\n  theme_gray() +\n  ggtitle(\"Distribution of English scores\") \n\n\n\n\n\n\n\n\nBy using histogram - the underlying code will bin the data to create the histogram - because they are to be represented in bars."
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html#using-probability-density-plot-instead",
    "href": "InClassEx/Ex02/inclassex02.html#using-probability-density-plot-instead",
    "title": "In Class Ex 02",
    "section": "2.2 Using Probability Density Plot Instead",
    "text": "2.2 Using Probability Density Plot Instead\n\nggplot(data=exam_data, aes(x = ENGLISH)) +\n  geom_density(color=\"darkblue\", adjust =.65, alpha = .6, linewidth = 1) +\n  theme_minimal() +\n  ggtitle(\"Distribution of English scores\")"
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html#the-alternative-design",
    "href": "InClassEx/Ex02/inclassex02.html#the-alternative-design",
    "title": "In Class Ex 02",
    "section": "2.3 The alternative design",
    "text": "2.3 The alternative design\n\nmedian_eng &lt;- median(exam_data$ENGLISH)\nmean_eng &lt;- mean(exam_data$ENGLISH)\nstd_eng &lt;- sd(exam_data$ENGLISH)\n\nggplot(data=exam_data, aes(x = ENGLISH)) +\n  geom_density(color=\"darkblue\", adjust =.65, alpha = .6, linewidth = 1) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = mean_eng, sd = std_eng),\n    col =\"darkgrey\",\n    linewdith = 0.8\n  ) +\n  geom_vline (aes(xintercept = mean_eng), col = \"red\", linewidth = 0.6) + \n  annotate(\"text\", x= mean_eng - 12, y=0.04, label= paste0(\"Mean ENGLISH: \", round((mean_eng),2)), color=\"red\") + \n  annotate(\"text\", x= median_eng + 12, y=0.04, label= paste0(\"Median ENGLISH: \", round((median_eng),2)), color=\"red\") +\n  geom_vline (aes(xintercept = median_eng), col = \"red\", linewidth = 0.6, linetype = \"dashed\") +\n  theme_minimal() +\n  ggtitle(\"Distribution of English scores\")"
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html#plotting-using-ggridges-method",
    "href": "InClassEx/Ex02/inclassex02.html#plotting-using-ggridges-method",
    "title": "In Class Ex 02",
    "section": "3.1 Plotting using ggridges method",
    "text": "3.1 Plotting using ggridges method\nggridges package provides two main geom to plot gridgeline plots, they are: geom_ridgeline() and geom_density_ridges(). The former takes height values directly to draw the ridgelines, and the latter first estimates data densities and then draws those using ridgelines.\nThe ridgeline plot below is plotted by using geom_density_ridges().\n\n\nCode\nggplot(exam_data, \n       aes(x = ENGLISH, \n           y = CLASS)) +\n  geom_density_ridges(\n    scale = 3,\n    rel_min_height = 0.01,\n    bandwidth = 3.4,\n    fill = lighten(\"#7097BB\", .3),\n    color = \"white\"\n  ) +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n    ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()"
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html#varying-gradient-in-the-ridges",
    "href": "InClassEx/Ex02/inclassex02.html#varying-gradient-in-the-ridges",
    "title": "In Class Ex 02",
    "section": "3.2 Varying Gradient in the Ridges",
    "text": "3.2 Varying Gradient in the Ridges\nWe can adjust the color in the ridges using a gradient - this can be done via either geom_ridgeline_gradient() or geom_density_ridges_gradient(). Both geoms work just like geom_ridgeline() and geom_density_ridges(), except that they allow for varying fill colors. However, they do not allow for alpha transparency in the fill. For technical reasons, we can have changing fill colors or transparency but not both.\n\n\n\nCode\nggplot(exam_data, \n       aes(x = ENGLISH, \n           y = CLASS,\n           fill = stat(x))) +\n  geom_density_ridges_gradient(\n    scale = 3,\n    rel_min_height = 0.01) +\n  scale_fill_viridis_c(name = \"Scores\",\n                       option = \"C\") +\n  scale_x_continuous(\n    name = \"English grades\",\n    expand = c(0, 0)\n  ) +\n  scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  theme_ridges()"
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html#mapping-the-probability-directly-onto-colour",
    "href": "InClassEx/Ex02/inclassex02.html#mapping-the-probability-directly-onto-colour",
    "title": "In Class Ex 02",
    "section": "3.3 Mapping the Probability directly onto Colour",
    "text": "3.3 Mapping the Probability directly onto Colour\nBeside providing additional geom objects to support the need to plot ridgeline plot, ggridges package also provides a stat function called stat_density_ridges() that replaces stat_density() of ggplot2.\nFigure below is plotted by mapping the probabilities calculated by using stat(ecdf) which represent the empirical cumulative density function for the distribution of English score.\n\n\n\n\n\n\nCaution\n\n\n\nIt is important include the argument calc_ecdf = TRUE in stat_density_ridges().\n\n\n\n\nCode\nggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = 0.5 - abs(0.5-stat(ecdf)))) +\n  stat_density_ridges(geom = \"density_ridges_gradient\", \n                      calc_ecdf = TRUE) +\n  scale_fill_viridis_c(name = \"Tail probability\",\n                       direction = -1) +\n  theme_ridges()"
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html#to-include-quantile-lines",
    "href": "InClassEx/Ex02/inclassex02.html#to-include-quantile-lines",
    "title": "In Class Ex 02",
    "section": "3.4 To Include Quantile Lines",
    "text": "3.4 To Include Quantile Lines\nBy using geom_density_ridges_gradient(), we can colour the ridgeline plot by quantile, via the calculated stat(quantile) aesthetic as shown in the figure below.\n\n\nCode\nggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = 4,\n    quantile_lines = TRUE) +\n  scale_fill_brewer(palette= \"Blues\", name = \"Quartiles\") +\n  theme_ridges()\n\n\n\n\n\n\n\n\n\nInstead of using number to define the quantiles, we can also specify quantiles by cut points such as 2.5% and 97.5% tails to colour the ridgeline plot as shown in the figure below.\n\nggplot(exam_data,\n       aes(x = ENGLISH, \n           y = CLASS, \n           fill = factor(stat(quantile))\n           )) +\n  stat_density_ridges(\n    geom = \"density_ridges_gradient\",\n    calc_ecdf = TRUE, \n    quantiles = c(0.025, 0.975)\n    ) +\n  scale_fill_manual(\n    name = \"Probability\",\n    values = c(\"lightblue\", \"lightgrey\", \"darkblue\"),\n    labels = c(\"(0, 0.025]\", \"(0.025, 0.975]\", \"(0.975, 1]\"),\n    ) +\n  theme_ridges()"
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html#plotting-a-half-eye-graph",
    "href": "InClassEx/Ex02/inclassex02.html#plotting-a-half-eye-graph",
    "title": "In Class Ex 02",
    "section": "4.1 Plotting a Half Eye Graph",
    "text": "4.1 Plotting a Half Eye Graph\nFirst, we will plot a Half-Eye graph by using stat_halfeye() of ggdist package.\nThis produces a Half Eye visualization, which is contains a half-density and a slab-interval.\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe remove the slab interval by setting .width = 0 and point_colour = NA."
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html#adding-in-the-boxplot",
    "href": "InClassEx/Ex02/inclassex02.html#adding-in-the-boxplot",
    "title": "In Class Ex 02",
    "section": "4.2 Adding in the boxplot",
    "text": "4.2 Adding in the boxplot\nNext, we will add the second geometry layer using geom_boxplot() of ggplot2. This produces a narrow boxplot. We reduce the width and adjust the opacity.\n\n#|code-fold: true\n\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA)"
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html#adding-the-dot-plots",
    "href": "InClassEx/Ex02/inclassex02.html#adding-the-dot-plots",
    "title": "In Class Ex 02",
    "section": "4.3 Adding the dot plots",
    "text": "4.3 Adding the dot plots\nNext, we will add the third geometry layer using stat_dots() of ggdist package. This produces a half-dotplot, which is similar to a histogram that indicates the number of samples (number of dots) in each bin. We select side = “left” to indicate we want it on the left-hand side.\n\n\nCode\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 2)"
  },
  {
    "objectID": "InClassEx/Ex02/inclassex02.html#finishing-touches",
    "href": "InClassEx/Ex02/inclassex02.html#finishing-touches",
    "title": "In Class Ex 02",
    "section": "4.4 Finishing Touches",
    "text": "4.4 Finishing Touches\nLastly, coord_flip() of ggplot2 package will be used to flip the raincloud chart horizontally to give it the raincloud appearance. At the same time, theme_economist() of ggthemes package is used to give the raincloud chart a professional publishing standard look.\n\n\nCode\nggplot(exam_data, \n       aes(x = RACE, \n           y = ENGLISH)) +\n  stat_halfeye(adjust = 0.5,\n               justification = -0.2,\n               .width = 0,\n               point_colour = NA) +\n  geom_boxplot(width = .20,\n               outlier.shape = NA) +\n  stat_dots(side = \"left\", \n            justification = 1.2, \n            binwidth = .5,\n            dotsize = 1.5) +\n  coord_flip() +\n  theme_economist()"
  },
  {
    "objectID": "InClassEx/Ex04/inclassex4.html#makeover-of-histogram-plot",
    "href": "InClassEx/Ex04/inclassex4.html#makeover-of-histogram-plot",
    "title": "In Class Ex 4",
    "section": "2.1 Makeover of Histogram Plot",
    "text": "2.1 Makeover of Histogram Plot\nThe code chunk:\n\ntype - allow us to choose which test - whether parametric, nonparametric, robust or bayes\n\ne.g. if you select np (non-parametric) - will auto select median instead of mean\n\ntest.value - number indicating the true value of the mean\n\n\n\np &lt;- gghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  conf.level = 0.95,\n  bin.args = list( color = \"darkblue\",\n                   fill = \"lightblue\",\n                   alpha = 0.7),\n  normal.curve = FALSE,\n  normal.curve.args = list(linewidth =2),\n  xlab = \"English scores\"\n)\n\np\n\n\n\n\n\n\n\n\nExtracting the stats from the plot:\n\nextract_stats(p)\n\n$subtitle_data\n# A tibble: 1 × 16\n  term       effectsize      estimate conf.level conf.low conf.high    pd\n  &lt;chr&gt;      &lt;chr&gt;              &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 Difference Bayesian t-test     7.16       0.95     5.54      8.75     1\n  prior.distribution prior.location prior.scale    bf10 method         \n  &lt;chr&gt;                       &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;          \n1 cauchy                          0       0.707 4.54e13 Bayesian t-test\n  conf.method log_e_bf10 n.obs expression\n  &lt;chr&gt;            &lt;dbl&gt; &lt;int&gt; &lt;list&gt;    \n1 ETI               31.4   322 &lt;language&gt;\n\n$caption_data\nNULL\n\n$pairwise_comparisons_data\nNULL\n\n$descriptive_data\nNULL\n\n$one_sample_data\nNULL\n\n$tidy_data\nNULL\n\n$glance_data\nNULL"
  },
  {
    "objectID": "InClassEx/Ex04/inclassex4.html#to-show-the-normal-distribution-curve",
    "href": "InClassEx/Ex04/inclassex4.html#to-show-the-normal-distribution-curve",
    "title": "In Class Ex 4",
    "section": "2.2 To show the Normal Distribution Curve",
    "text": "2.2 To show the Normal Distribution Curve\n\nnormal.curve - set to TRUE to show the curve\nand it also allows for further customisation\n\n\ngghistostats(\n  data = exam,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  conf.level = 0.95,\n  bin.args = list( color = \"darkblue\",\n                   fill = \"lightblue\",\n                   alpha = 0.7),\n  normal.curve = TRUE,\n  normal.curve.args = list(linewidth = 1,\n                           color = \"grey\"),\n  xlab = \"English scores\"\n)"
  },
  {
    "objectID": "InClassEx/Ex04/inclassex4.html#dot-plot",
    "href": "InClassEx/Ex04/inclassex4.html#dot-plot",
    "title": "In Class Ex 4",
    "section": "2.3 Dot Plot",
    "text": "2.3 Dot Plot\n\nggdotplotstats(\n  data = exam,\n  x = ENGLISH,\n  y= CLASS,\n  title = \"Mean of English Scores across Classes\",\n  xlab = \"English Scores\",\n  ylab = \"Class\"\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nNotice that the classes are sorted according to their mean - here we notice that students in Class 3D perform better than Class 3C on average."
  },
  {
    "objectID": "InClassEx/Ex04/inclassex4.html#within-sample-stats",
    "href": "InClassEx/Ex04/inclassex4.html#within-sample-stats",
    "title": "In Class Ex 4",
    "section": "2.4 Within Sample Stats",
    "text": "2.4 Within Sample Stats\n\nexam_long &lt;- exam %&gt;%\n              pivot_longer(cols = c(MATHS, SCIENCE, ENGLISH),\n                           names_to = \"SUBJECT\",\n                           values_to = \"SCORE\") %&gt;%\n              filter(CLASS == \"3A\")\n\n\nggwithinstats(\n  data = filter(exam_long, SUBJECT %in% c(\"MATHS\", \"SCIENCE\")),\n  x = SUBJECT, \n  y = SCORE,\n  type = \"p\",\n  messages = FALSE,\n  pairwise.display = \"significant\"\n)"
  },
  {
    "objectID": "InClassEx/Ex04/inclassex4.html#scatterstats",
    "href": "InClassEx/Ex04/inclassex4.html#scatterstats",
    "title": "In Class Ex 4",
    "section": "2.5 Scatterstats",
    "text": "2.5 Scatterstats\n\nmarginal = TRUE - plotting the histogram/distribution by the sides\nlabel - to highlight the labels within the plots\n\n\nPlotsStatistics\n\n\n\ng &lt;- ggscatterstats(\n  data = exam,\n  x = MATHS,\n  y = ENGLISH, \n  marginal = TRUE, \n  label.var = ID, \n  label.expression = ENGLISH &gt; 90 & MATHS &gt; 90\n)\n\ng\n\n\n\n\n\n\n\n\n\n\n\nextract_stats(g)\n\n$subtitle_data\n# A tibble: 1 × 14\n  parameter1 parameter2 effectsize          estimate conf.level conf.low\n  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;                  &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 MATHS      ENGLISH    Pearson correlation    0.831       0.95    0.794\n  conf.high statistic df.error  p.value method              n.obs conf.method\n      &lt;dbl&gt;     &lt;dbl&gt;    &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               &lt;int&gt; &lt;chr&gt;      \n1     0.862      26.7      320 1.70e-83 Pearson correlation   322 normal     \n  expression\n  &lt;list&gt;    \n1 &lt;language&gt;\n\n$caption_data\n# A tibble: 1 × 17\n  parameter1 parameter2 effectsize                   estimate conf.level\n  &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;                           &lt;dbl&gt;      &lt;dbl&gt;\n1 MATHS      ENGLISH    Bayesian Pearson correlation    0.829       0.95\n  conf.low conf.high    pd rope.percentage prior.distribution prior.location\n     &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt;           &lt;dbl&gt; &lt;chr&gt;                       &lt;dbl&gt;\n1    0.794     0.860     1               0 beta                         1.41\n  prior.scale    bf10 method                       n.obs conf.method expression\n        &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt;                        &lt;int&gt; &lt;chr&gt;       &lt;list&gt;    \n1        1.41 5.21e79 Bayesian Pearson correlation   322 HDI         &lt;language&gt;\n\n$pairwise_comparisons_data\nNULL\n\n$descriptive_data\nNULL\n\n$one_sample_data\nNULL\n\n$tidy_data\nNULL\n\n$glance_data\nNULL"
  },
  {
    "objectID": "InClassEx/Ex04/inclassex4.html#importing-data",
    "href": "InClassEx/Ex04/inclassex4.html#importing-data",
    "title": "In Class Ex 4",
    "section": "3.1 Importing data",
    "text": "3.1 Importing data\nUsing read_xl to import excel data\n\ncan specify the specific worksheet or row/columns\n\n\ncar_resale &lt;- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model    Price Age_08_04 Mfg_Month Mfg_Year     KM Quarterly_Tax Weight\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;\n 1    81 TOYOTA … 18950        25         8     2002  20019           100   1180\n 2     1 TOYOTA … 13500        23        10     2002  46986           210   1165\n 3     2 TOYOTA … 13750        23        10     2002  72937           210   1165\n 4     3  TOYOTA… 13950        24         9     2002  41711           210   1165\n 5     4 TOYOTA … 14950        26         7     2002  48000           210   1165\n 6     5 TOYOTA … 13750        30         3     2002  38500           210   1170\n 7     6 TOYOTA … 12950        32         1     2002  61000           210   1170\n 8     7  TOYOTA… 16900        27         6     2002  94612           210   1245\n 9     8 TOYOTA … 18600        30         3     2002  75889           210   1245\n10    44 TOYOTA … 16950        27         6     2002 110404           234   1255\n# ℹ 1,426 more rows\n# ℹ 29 more variables: Guarantee_Period &lt;dbl&gt;, HP_Bin &lt;chr&gt;, CC_bin &lt;chr&gt;,\n#   Doors &lt;dbl&gt;, Gears &lt;dbl&gt;, Cylinders &lt;dbl&gt;, Fuel_Type &lt;chr&gt;, Color &lt;chr&gt;,\n#   Met_Color &lt;dbl&gt;, Automatic &lt;dbl&gt;, Mfr_Guarantee &lt;dbl&gt;,\n#   BOVAG_Guarantee &lt;dbl&gt;, ABS &lt;dbl&gt;, Airbag_1 &lt;dbl&gt;, Airbag_2 &lt;dbl&gt;,\n#   Airco &lt;dbl&gt;, Automatic_airco &lt;dbl&gt;, Boardcomputer &lt;dbl&gt;, CD_Player &lt;dbl&gt;,\n#   Central_Lock &lt;dbl&gt;, Powered_Windows &lt;dbl&gt;, Power_Steering &lt;dbl&gt;, …\n\n\n\nmodel &lt;- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\ncheck_c &lt;- check_collinearity(model)\n\nplot(check_c)\n\n\n\n\n\n\n\n\nBy looking at the plot - we can see that the Age and the Mfg_year are highly correlated - and hence we need to exclude on of them. Here, we use a simple visualisation to help us to see instead of looking through a table.\n\nmodel1 &lt;- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\ncheck_n &lt;- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\n\n\n\nplot(parameters(model1))\n\n\n\n\n\n\n\n\nSimilarly, we can use the ggcoefstats:\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "InClassEx/Ex06/inclassex6.html",
    "href": "InClassEx/Ex06/inclassex6.html",
    "title": "In Class Ex 6",
    "section": "",
    "text": "pacman::p_load(corporaexplorer, tidyverse, stringi, rvest)\n\nUsing the example from the documentation:\nhttps://kgjerde.github.io/corporaexplorer/articles/bible.html\n\nbible &lt;- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")\n\n\n\n\nNeed to collapse the data into one string\n\nbible &lt;- paste(bible, collapse = \"\\n\")\n\nIdentifying the beginning and end of the Bible / stripping PJ metadata # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).\n\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\nIn the file, every book in the bible is preceded by five newlines, which we use to split our string into a vector where each element is a book.\n\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40]  \n\n# Removing the heading \"The New Testament of the King James Bible\",\n# which also was preceded by five newlines.\n\nBecause of the structure of the text in the file: # Replacing double or more newlines with two newlines, and a single newline with space.\n\nbooks &lt;- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %&gt;%\n    str_replace_all(\"\\n\", \" \") %&gt;%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]  # The two first elements are not books\n\nIdentifying new chapters within each book and split the text into chapters. (The first characters in chapter 2 will e.g. be 2:1)\n\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %&gt;%\n    stri_split_regex(\"NEW_CHAPTER\")\n\n# Removing the chapter headings from the text (we want them as metadata).\nchapters &lt;- lapply(chapters, function(x) x[-1])\n\nWe are not quite happy with the long book titles in the King James Bible, so we retrieve shorter versions from esv.org which will take up less space in the corpus map plot.\n\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n# We add a column indicating whether a book belongs to the Old or New Testament,\n#   knowing that they contain respectively 39 and 27 books.\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))\n\n\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n# We want each chapter to be one row, but keep the metadata (book and which testament).\n\nbible_df &lt;- tidyr::unnest(bible_df, Text)\n\n\n\n\nThe three most important arguments are:\n\ndataset: a data frame with, as a minimum, a Text column. If date_based_corpus is TRUE (the default), dataset must also contain a column “Date” (of class Date).\ndate_based_corpus. Default is TRUE. Set to FALSE if the corpus is not to be organised according to document dates.\ngrouping_variable. If date_based_corpus is TRUE, this argument is ignored. If date_based_corpus is FALSE, this argument can be used to group the documents, e.g. if dataset consists of chapters belonging to different books, and the book indicated in a “Book” column, set this argument to \"Book\"\n\n\n\n\n\n\n\nNote\n\n\n\nText column - must be named as Text (with capital T)\nDate field - must be in date format that R can read (cannot be 1, 2, 3, 4, 5 etc)\n\n\nAs this is a corpus which is not organised by date, we set date_based_corpus to FALSE. # Because we want to organise our exploration around the books in the Bible, we pass \"Book\" to the grouping_variable argument. We specify which metadata columns we want to be displayed in the “Document information” tab, using the columns_doc_info argument.\n\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n\nRun corpus explorer:\nhttps://kgjerde.github.io/corporaexplorer/articles/usage.html\n\nclass(KJB)\n\n[1] \"corporaexplorerobject\"\n\n\n\nexplore(KJB)\n\nShiny applications not supported in static R Markdown documents\n\n\n\n\n\nhttps://github.com/cbail/textnets\n\n\n\nhttps://github.com/cpsievert/LDAvis"
  },
  {
    "objectID": "InClassEx/Ex06/inclassex6.html#getting-started",
    "href": "InClassEx/Ex06/inclassex6.html#getting-started",
    "title": "In Class Ex 6",
    "section": "",
    "text": "pacman::p_load(corporaexplorer, tidyverse, stringi, rvest)\n\nUsing the example from the documentation:\nhttps://kgjerde.github.io/corporaexplorer/articles/bible.html\n\nbible &lt;- readr::read_lines(\"http://www.gutenberg.org/cache/epub/10/pg10.txt\")"
  },
  {
    "objectID": "InClassEx/Ex06/inclassex6.html#preparing-the-data",
    "href": "InClassEx/Ex06/inclassex6.html#preparing-the-data",
    "title": "In Class Ex 6",
    "section": "",
    "text": "Need to collapse the data into one string\n\nbible &lt;- paste(bible, collapse = \"\\n\")\n\nIdentifying the beginning and end of the Bible / stripping PJ metadata # (technique borrowed from https://quanteda.io/articles/pkgdown/replication/digital-humanities.html).\n\nstart_v &lt;- stri_locate_first_fixed(bible, \"The First Book of Moses: Called Genesis\")[1]\nend_v &lt;- stri_locate_last_fixed(bible, \"Amen.\")[2]\nbible &lt;- stri_sub(bible, start_v, end_v)\n\nIn the file, every book in the bible is preceded by five newlines, which we use to split our string into a vector where each element is a book.\n\nbooks &lt;- stri_split_regex(bible, \"\\n{5}\") %&gt;%\n    unlist %&gt;%\n    .[-40]  \n\n# Removing the heading \"The New Testament of the King James Bible\",\n# which also was preceded by five newlines.\n\nBecause of the structure of the text in the file: # Replacing double or more newlines with two newlines, and a single newline with space.\n\nbooks &lt;- str_replace_all(books, \"\\n{2,}\", \"NEW_PARAGRAPH\") %&gt;%\n    str_replace_all(\"\\n\", \" \") %&gt;%\n    str_replace_all(\"NEW_PARAGRAPH\", \"\\n\\n\")\nbooks &lt;- books[3:68]  # The two first elements are not books\n\nIdentifying new chapters within each book and split the text into chapters. (The first characters in chapter 2 will e.g. be 2:1)\n\nchapters &lt;- str_replace_all(books, \"(\\\\d+:1 )\", \"NEW_CHAPTER\\\\1\") %&gt;%\n    stri_split_regex(\"NEW_CHAPTER\")\n\n# Removing the chapter headings from the text (we want them as metadata).\nchapters &lt;- lapply(chapters, function(x) x[-1])\n\nWe are not quite happy with the long book titles in the King James Bible, so we retrieve shorter versions from esv.org which will take up less space in the corpus map plot.\n\nbook_titles &lt;- read_html(\"https://www.esv.org/resources/esv-global-study-bible/list-of-abbreviations\") %&gt;%\n  html_nodes(\"td:nth-child(1)\") %&gt;%\n  html_text() %&gt;%\n  .[13:78]  # Removing irrelevant elements after manual inspection.\n\n# We add a column indicating whether a book belongs to the Old or New Testament,\n#   knowing that they contain respectively 39 and 27 books.\ntestament &lt;- c(rep(\"Old\", 39), rep(\"New\", 27))\n\n\n# Data frame with one book as one row.\nbible_df &lt;- tibble::tibble(Text = chapters,\n                           Book = book_titles,\n                           Testament = testament)\n\n# We want each chapter to be one row, but keep the metadata (book and which testament).\n\nbible_df &lt;- tidyr::unnest(bible_df, Text)"
  },
  {
    "objectID": "InClassEx/Ex06/inclassex6.html#using-corporaexplorer",
    "href": "InClassEx/Ex06/inclassex6.html#using-corporaexplorer",
    "title": "In Class Ex 6",
    "section": "",
    "text": "The three most important arguments are:\n\ndataset: a data frame with, as a minimum, a Text column. If date_based_corpus is TRUE (the default), dataset must also contain a column “Date” (of class Date).\ndate_based_corpus. Default is TRUE. Set to FALSE if the corpus is not to be organised according to document dates.\ngrouping_variable. If date_based_corpus is TRUE, this argument is ignored. If date_based_corpus is FALSE, this argument can be used to group the documents, e.g. if dataset consists of chapters belonging to different books, and the book indicated in a “Book” column, set this argument to \"Book\"\n\n\n\n\n\n\n\nNote\n\n\n\nText column - must be named as Text (with capital T)\nDate field - must be in date format that R can read (cannot be 1, 2, 3, 4, 5 etc)\n\n\nAs this is a corpus which is not organised by date, we set date_based_corpus to FALSE. # Because we want to organise our exploration around the books in the Bible, we pass \"Book\" to the grouping_variable argument. We specify which metadata columns we want to be displayed in the “Document information” tab, using the columns_doc_info argument.\n\nKJB &lt;- prepare_data(dataset = bible_df,\n                    date_based_corpus = FALSE,\n                    grouping_variable = \"Book\",\n                    columns_doc_info = c(\"Testament\", \"Book\"))\n\nRun corpus explorer:\nhttps://kgjerde.github.io/corporaexplorer/articles/usage.html\n\nclass(KJB)\n\n[1] \"corporaexplorerobject\"\n\n\n\nexplore(KJB)\n\nShiny applications not supported in static R Markdown documents"
  },
  {
    "objectID": "InClassEx/Ex06/inclassex6.html#using-textnets",
    "href": "InClassEx/Ex06/inclassex6.html#using-textnets",
    "title": "In Class Ex 6",
    "section": "",
    "text": "https://github.com/cbail/textnets"
  },
  {
    "objectID": "InClassEx/Ex06/inclassex6.html#using-ldavis",
    "href": "InClassEx/Ex06/inclassex6.html#using-ldavis",
    "title": "In Class Ex 6",
    "section": "",
    "text": "https://github.com/cpsievert/LDAvis"
  },
  {
    "objectID": "InClassEx/Ex06/inclassex6.html#loading-the-packages",
    "href": "InClassEx/Ex06/inclassex6.html#loading-the-packages",
    "title": "In Class Ex 6",
    "section": "1. Loading the Packages",
    "text": "1. Loading the Packages\n\npacman::p_load(jsonlite, tidygraph, ggraph, visNetwork, graphlayouts, ggforce, skimr, tidytext, tidyverse)"
  },
  {
    "objectID": "InClassEx/Ex06/inclassex6.html#importing-the-data",
    "href": "InClassEx/Ex06/inclassex6.html#importing-the-data",
    "title": "In Class Ex 6",
    "section": "2. Importing the data",
    "text": "2. Importing the data\nHere, we are using the data from VAST Challenge in 2023.\nhttps://vast-challenge.github.io/2023/MC3.html\nFor our data - we need to rename the columns that we want to have a source and target under links.\n\nmc3_data &lt;- fromJSON (\"data/MC3.json\")\n\n\nclass(mc3_data)\n\n[1] \"list\"\n\n\n\nmc3_edges &lt;-\n  as_tibble(mc3_data$links) %&gt;%\n  distinct() %&gt;%\n  mutate(source = as.character(source),\n         target = as.character(target),\n         type = as.character(type)) %&gt;%\n  group_by(source,target, type) %&gt;%\n  summarise(weights=n()) %&gt;%\n  filter(source!=target) %&gt;%\n  ungroup()\n\n\nmc3_nodes &lt;-\n  as_tibble(mc3_data$nodes) %&gt;%\n  distinct() %&gt;%\n  mutate(id = as.character(id),\n         country = as.character(country),\n         type = as.character(type),\n         product_services = as.character(product_services),\n         revenue_omu = as.numeric(as.character(revenue_omu))) %&gt;%\n  select(id, country, type, revenue_omu, product_services)\n\n\nid1 &lt;- mc3_edges %&gt;%\n  select(source) %&gt;%\n  rename(id = source)\n\nid2 &lt;- mc3_edges %&gt;%\n  select(target) %&gt;%\n  rename (id=target)\n\nmc3_nodes1 &lt;- rbind(id1,id2) %&gt;%\n  distinct() %&gt;%\n  left_join(mc3_nodes,\n            by =join_by(id),\n            unmatched = \"drop\")\n\n\nmc3_graph &lt;- tbl_graph (nodes = mc3_nodes1,\n                        edges = mc3_edges,\n                        directed = FALSE) %&gt;%\n  mutate (betweeness_centrality = centrality_betweenness(),\n          closeness_centrality = centrality_closeness()\n)\n\n\nmc3_graph %&gt;%\n  filter(betweeness_centrality &gt;= 300000) %&gt;%\nggraph(layout = \"fr\") +\n  geom_edge_link (aes(alpha=0.5)) +\n  geom_node_point( aes(\n    size = betweeness_centrality,\n    colors = \"lightblue\",\n    alpha = 0.5  )) +\n  scale_size_continuous(range=c(1,10)) +\n  theme_graph()"
  },
  {
    "objectID": "InClassEx/Ex08/inclassex8.html",
    "href": "InClassEx/Ex08/inclassex8.html",
    "title": "In Class Ex - Geospatial",
    "section": "",
    "text": "Prepare the data using Tableau - using the drag and drop function to union the various datasets\n\nMay have issues - sometimes adjust the number of rows to overcome the issue of 0 rows.\n\nTableau can auto detect the postal code and set as zipcode/postcode geographical data.\nDrag and drop the postal code into the center:\n\n\n\nThere can be unknown postal code - as the SLA records are real -time and some postal codes could have been deleted. Will need to download the postal code and search via Google (they maintain the historical data).\n\n\n\n\n\n\nInclude filters to the map:\n\n\n\nTableau can auto-recognise the planning areas - but may not be 100% correct.\nRight click and select Geographical Role -&gt; Province / State.\n\n\n\n\n\nhttps://public.tableau.com/app/profile/chun.chieh.cheng/viz/PropertyExplorer_17178269666590/Dashboard1?publish=yes"
  },
  {
    "objectID": "InClassEx/Ex08/inclassex8.html#using-realis-2023-data",
    "href": "InClassEx/Ex08/inclassex8.html#using-realis-2023-data",
    "title": "In Class Ex - Geospatial",
    "section": "",
    "text": "Prepare the data using Tableau - using the drag and drop function to union the various datasets\n\nMay have issues - sometimes adjust the number of rows to overcome the issue of 0 rows.\n\nTableau can auto detect the postal code and set as zipcode/postcode geographical data.\nDrag and drop the postal code into the center:\n\n\n\nThere can be unknown postal code - as the SLA records are real -time and some postal codes could have been deleted. Will need to download the postal code and search via Google (they maintain the historical data)."
  },
  {
    "objectID": "InClassEx/Ex08/inclassex8.html#looking-at-the-median-price-etc",
    "href": "InClassEx/Ex08/inclassex8.html#looking-at-the-median-price-etc",
    "title": "In Class Ex - Geospatial",
    "section": "",
    "text": "Include filters to the map:"
  },
  {
    "objectID": "InClassEx/Ex08/inclassex8.html#chloropleth-maps",
    "href": "InClassEx/Ex08/inclassex8.html#chloropleth-maps",
    "title": "In Class Ex - Geospatial",
    "section": "",
    "text": "Tableau can auto-recognise the planning areas - but may not be 100% correct.\nRight click and select Geographical Role -&gt; Province / State."
  },
  {
    "objectID": "InClassEx/Ex08/inclassex8.html#creating-the-dashboard",
    "href": "InClassEx/Ex08/inclassex8.html#creating-the-dashboard",
    "title": "In Class Ex - Geospatial",
    "section": "",
    "text": "https://public.tableau.com/app/profile/chun.chieh.cheng/viz/PropertyExplorer_17178269666590/Dashboard1?publish=yes"
  },
  {
    "objectID": "TakehomeEx/ex01/takehomeex1.html",
    "href": "TakehomeEx/ex01/takehomeex1.html",
    "title": "Take Home Ex 1",
    "section": "",
    "text": "Creating data visualisation beyond default\n\n\nAssuming the role of a graphical editor of a median company, you are requested to prepare minimum two and maximum three data visualisation to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024."
  },
  {
    "objectID": "TakehomeEx/ex01/takehomeex1.html#the-task",
    "href": "TakehomeEx/ex01/takehomeex1.html#the-task",
    "title": "Take Home Ex 1",
    "section": "",
    "text": "Assuming the role of a graphical editor of a median company, you are requested to prepare minimum two and maximum three data visualisation to reveal the private residential market and sub-markets of Singapore for the 1st quarter of 2024."
  },
  {
    "objectID": "TakehomeEx/ex01/takehomeex1.html#loading-the-required-packages",
    "href": "TakehomeEx/ex01/takehomeex1.html#loading-the-required-packages",
    "title": "Take Home Ex 1",
    "section": "1.1 Loading the Required Packages",
    "text": "1.1 Loading the Required Packages\n\npacman::p_load(plotly, patchwork, hrbrthemes, ggridges, ggrepel, tidyverse, ggpubr, scales, colorspace, ggdist)"
  },
  {
    "objectID": "TakehomeEx/ex01/takehomeex1.html#examining-and-preparing-the-data",
    "href": "TakehomeEx/ex01/takehomeex1.html#examining-and-preparing-the-data",
    "title": "Take Home Ex 1",
    "section": "1.2 Examining and Preparing the Data",
    "text": "1.2 Examining and Preparing the Data\nWe first read the 5 .csv files provided. These are separate csv files containing data of each of the quarters from 2023 to Mar 2024.\nAs such, we will use the following code chunk to import the data and combine them into a single dataset.\n\ndf &lt;- list.files(path=\"data/csv\", full.names = TRUE) %&gt;% \n  lapply(read_csv) %&gt;% \n  bind_rows \n\nAfter combining the dataset into df, we will also extract the Sale Date and code it accordingly to the quarters. E.g. Jan to Mar 23 will be Q1Y23 and so on.\n\ndf &lt;- df %&gt;%\n  mutate(sale_date = as.Date(`Sale Date`, format = \"%d %b %Y\"),  \n         quarter = paste0(\"Q\", quarter(sale_date), \"Y\", format(sale_date, \"%y\")))%&gt;%\n  mutate(\n    quarter = factor(quarter, levels = c(\"Q1Y23\", \"Q2Y23\", \"Q3Y23\", \"Q4Y23\", \"Q1Y24\"))\n  )\n\nI also like to rename some of the columns headers so that it is easier to type into the codes later, especially removing the space in between.\n\nrealis2324 &lt;- df %&gt;% \n  rename(\n    unit_psm = 'Unit Price ($ PSM)',\n    unit_area = 'Area (SQM)',\n    property_type = `Property Type`,\n    sale_type = `Type of Sale`,\n    planning_region = `Planning Region`,\n    planning_area = `Planning Area`,\n    trans_price = `Transacted Price ($)`,\n    project = `Project Name`\n      )"
  },
  {
    "objectID": "TakehomeEx/ex01/takehomeex1.html#check-data-for-duplicated-missing-values",
    "href": "TakehomeEx/ex01/takehomeex1.html#check-data-for-duplicated-missing-values",
    "title": "Take Home Ex 1",
    "section": "1.3 Check Data for Duplicated, Missing Values",
    "text": "1.3 Check Data for Duplicated, Missing Values\nFirst, we check if there are any missing values in the dataset.\n\n# Check for missing values\nmissing_values &lt;- realis2324 %&gt;%\n  summarise_all(~ sum(is.na(.)))\n\n# Display columns with missing values\nprint(missing_values)\n\n# A tibble: 1 × 23\n  project trans_price `Area (SQFT)` `Unit Price ($ PSF)` `Sale Date` Address\n    &lt;int&gt;       &lt;int&gt;         &lt;int&gt;                &lt;int&gt;       &lt;int&gt;   &lt;int&gt;\n1       0           0             0                    0           0       0\n# ℹ 17 more variables: sale_type &lt;int&gt;, `Type of Area` &lt;int&gt;, unit_area &lt;int&gt;,\n#   unit_psm &lt;int&gt;, `Nett Price($)` &lt;int&gt;, property_type &lt;int&gt;,\n#   `Number of Units` &lt;int&gt;, Tenure &lt;int&gt;, `Completion Date` &lt;int&gt;,\n#   `Purchaser Address Indicator` &lt;int&gt;, `Postal Code` &lt;int&gt;,\n#   `Postal District` &lt;int&gt;, `Postal Sector` &lt;int&gt;, planning_region &lt;int&gt;,\n#   planning_area &lt;int&gt;, sale_date &lt;int&gt;, quarter &lt;int&gt;\n\n\nAnd also for any duplicated values.\n\n# Check for duplicate rows\nduplicate_rows &lt;- realis2324 %&gt;%\n  filter(duplicated(.))\n\n# Display duplicate rows\nprint(duplicate_rows)\n\n# A tibble: 0 × 23\n# ℹ 23 variables: project &lt;chr&gt;, trans_price &lt;dbl&gt;, Area (SQFT) &lt;dbl&gt;,\n#   Unit Price ($ PSF) &lt;dbl&gt;, Sale Date &lt;chr&gt;, Address &lt;chr&gt;, sale_type &lt;chr&gt;,\n#   Type of Area &lt;chr&gt;, unit_area &lt;dbl&gt;, unit_psm &lt;dbl&gt;, Nett Price($) &lt;chr&gt;,\n#   property_type &lt;chr&gt;, Number of Units &lt;dbl&gt;, Tenure &lt;chr&gt;,\n#   Completion Date &lt;chr&gt;, Purchaser Address Indicator &lt;chr&gt;,\n#   Postal Code &lt;chr&gt;, Postal District &lt;chr&gt;, Postal Sector &lt;chr&gt;,\n#   planning_region &lt;chr&gt;, planning_area &lt;chr&gt;, sale_date &lt;date&gt;, …"
  },
  {
    "objectID": "TakehomeEx/ex01/takehomeex1.html#focusing-on-individual-sales-i.e.-remove-en-bloc",
    "href": "TakehomeEx/ex01/takehomeex1.html#focusing-on-individual-sales-i.e.-remove-en-bloc",
    "title": "Take Home Ex 1",
    "section": "1.4 Focusing on Individual Sales (i.e. Remove En Bloc)",
    "text": "1.4 Focusing on Individual Sales (i.e. Remove En Bloc)\nBecause we are looking at transaction data of the properties, we also want to check the number of units sold in each row is equal to 1. Because any sales with more than 1 unit can indicate other sales types, like en-bloc etc.\n\nall_units_equal_to_1 &lt;- all(realis2324$`Number of Units` == 1)\n\nif (all_units_equal_to_1) {\n  print(\"All values in the 'Number of Units' column are equal to 1.\")\n} else {\n  # Print values above 1\n  units_above_1 &lt;- realis2324 %&gt;%\n    filter(`Number of Units` &gt; 1)\n\n  print(\"Values in the 'Number of Units' column above 1:\")\n  print(units_above_1)\n}\n\n[1] \"Values in the 'Number of Units' column above 1:\"\n# A tibble: 12 × 23\n   project    trans_price `Area (SQFT)` `Unit Price ($ PSF)` `Sale Date` Address\n   &lt;chr&gt;            &lt;dbl&gt;         &lt;dbl&gt;                &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;  \n 1 N.A.          32200000        14123.                 2280 02 May 2023 \"29,29…\n 2 KEW LODGE     66800000        25177                  2653 23 May 2023 \"34,34…\n 3 N.A.           6150000         4342.                 1416 19 Jun 2023 \"87 LO…\n 4 N.A.          10600000         6747.                 1571 26 Jun 2023 \"1,1A,…\n 5 CLAYMORE …     7000000         4209.                 1663 27 Feb 2024 \"6 CLA…\n 6 BAGNALL C…   115280000        68491.                 1683 04 Jan 2023 \"813,8…\n 7 MONDO MAN…     6280000         5490.                 1144 18 Jan 2023 \"543,5…\n 8 MEYER PARK   392180000       144883.                 2707 09 Feb 2023 \"81,83…\n 9 N.A.          61080008        32149.                 1900 21 Mar 2023 \"14,14…\n10 EAST VIEW…     6100000         8338.                  732 17 Jul 2023 \"43,45…\n11 N.A.           8000000         3659.                 2187 28 Jul 2023 \"4,6 L…\n12 KARTAR AP…    18000000         6964.                 2585 11 Oct 2023 \"41A,4…\n# ℹ 17 more variables: sale_type &lt;chr&gt;, `Type of Area` &lt;chr&gt;, unit_area &lt;dbl&gt;,\n#   unit_psm &lt;dbl&gt;, `Nett Price($)` &lt;chr&gt;, property_type &lt;chr&gt;,\n#   `Number of Units` &lt;dbl&gt;, Tenure &lt;chr&gt;, `Completion Date` &lt;chr&gt;,\n#   `Purchaser Address Indicator` &lt;chr&gt;, `Postal Code` &lt;chr&gt;,\n#   `Postal District` &lt;chr&gt;, `Postal Sector` &lt;chr&gt;, planning_region &lt;chr&gt;,\n#   planning_area &lt;chr&gt;, sale_date &lt;date&gt;, quarter &lt;fct&gt;\n\n\nWe have 12 rows with the number of units &gt; 1. Given that we are not able to divide the sales data accordingly by the number of units etc, we will remove these data instead.\n\nrealis2324_cleaned &lt;- realis2324 %&gt;%\n  filter(`Number of Units` &lt;= 1)"
  },
  {
    "objectID": "TakehomeEx/ex01/takehomeex1.html#reviewing-the-property-type",
    "href": "TakehomeEx/ex01/takehomeex1.html#reviewing-the-property-type",
    "title": "Take Home Ex 1",
    "section": "1.5 Reviewing the Property Type",
    "text": "1.5 Reviewing the Property Type\nWhen we look at the data, we can see that there are five property types indicated:\n\nApartment\nCondominium\nDetached House\nExecutive Condominium\nSemi-Detached House\nTerrace House\n\nExecutive Condominium is a mix between public and private housing so we will leave it as such in case we want to exclude it from further analysis. However, when we look at Apartment and Condominium, we realised that there is not much difference; e.g. one of the Apartment is Lentor Modern which is actually listed as a Condominium on its website. For the purpose of our study, we can therefore combine apartment and condominium as one same group - condo.\n\nrealis2324_cleaned$property_type &lt;- ifelse(realis2324_cleaned$property_type == \"Apartment\", \"Condominium\", realis2324_cleaned$property_type)\n\nrealis2324_cleaned &lt;- realis2324_cleaned %&gt;%\n  mutate(\n    property_type = factor(property_type, levels = c(\"Condominium\", \"Executive Condominium\", \"Terrace House\", \"Semi-Detached House\", \"Detached House\"))\n  )"
  },
  {
    "objectID": "TakehomeEx/ex01/takehomeex1.html#writing-the-data-to-rds-file",
    "href": "TakehomeEx/ex01/takehomeex1.html#writing-the-data-to-rds-file",
    "title": "Take Home Ex 1",
    "section": "1.6 Writing the data to rds file",
    "text": "1.6 Writing the data to rds file\nWe will then write the data into a rds format.\n\nwrite_rds(realis2324_cleaned, \"data/rds/realis2324_cleaned.rds\")"
  },
  {
    "objectID": "TakehomeEx/ex01/takehomeex1.html#overview-of-the-private-property-transactions-in-q1y24",
    "href": "TakehomeEx/ex01/takehomeex1.html#overview-of-the-private-property-transactions-in-q1y24",
    "title": "Take Home Ex 1",
    "section": "2.1 Overview of the Private Property Transactions in Q1Y24",
    "text": "2.1 Overview of the Private Property Transactions in Q1Y24\nWe will first start by providing an overview of the private property transactions in the Quarter 1 2024, by trying to answer the following questions:\n\nWhat is the proportion of sales in terms of property type across the quarters? We know that the bulk of transactions would involve Condominiums given their availability as compared to landed properties, but we also want to know the difference between resales/sub-sale as compared to new sales.\n\n\n\nCode\ng1 &lt;- ggplot(subset(realis2324_cleaned, sale_type %in% c(\"Resale\", \"Sub Sale\")), aes(x = quarter, fill = property_type)) +\n  geom_bar(position = \"dodge\", color = \"black\") +\n  geom_text(\n    aes(label = ..count.., y = ..count.. + 50 ),\n    stat = \"count\",\n    size = 2,\n    position = position_dodge(0.9),\n    vjust=0)+\n  theme(legend.position=\"none\")+\n  geom_hline(aes(yintercept = 2555), col=\"darkblue\", linewidth=0.2, linetype = \"dashed\") +\n   labs(\n    title = \"Resale Transactions for Condos in Q1Y24 is comparable to Q1Y23\",\n    x = \"Quarters\",\n    y = \"Number of Transactions\"\n  ) +\n  scale_fill_brewer(palette = \"Blues\", name = \"Property Type\") \n\ng1\n\n\n\n\n\n\n\n\n\n\n\nCode\ng2 &lt;- ggplot(subset(realis2324_cleaned, sale_type %in% \"New Sale\"), aes(x = quarter, fill = property_type)) +\n  geom_bar(position = \"dodge\", color = \"black\") +\n  geom_text(\n    aes(label = ..count.., y = ..count.. + 50 ),\n    stat = \"count\",\n    size = 2,\n    position = position_dodge(0.9),\n    vjust=0)+\n  geom_hline(aes(yintercept = 1154), col=\"darkblue\", linewidth=0.2, linetype = \"dashed\") +\n  labs(\n    title = \"New Sale Transactions for Condos in Q1Y24 is comparable to Q1Y23\",\n    x = \"Quarters\",\n    y = \"Number of Transactions\"\n  ) +\n  scale_fill_brewer(palette = \"Blues\", name = \"Property Type\") \n\ng2\n\n\n\n\n\n\n\n\n\n\np = (g1 / g2) +\n  plot_annotation('Number of Condo Transactions for Q1Y24 is comparable to Q1Y23')\n\np & theme_minimal()+\n  theme(legend.key.size = unit(0.3, 'cm'), #change legend key size\n        legend.key.height = unit(0.3, 'cm'), #change legend key height\n        legend.key.width = unit(0.3, 'cm'), #change legend key width\n        legend.title = element_text(size=6), #change legend title font size\n        legend.text = element_text(size=6),\n        title=element_text(size=8, face='bold'), \n        axis.text.x = element_text(size = 6),\n        axis.text.y = element_text(size = 8),\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFrom the graph, we can see that the number of transactions for condominiums is a lot higher as compared to landed properties, with the number of both resale and new sales in Q1Y24 comparable to that in Q1Y23.\nThere are a higher number of new sales in Q2 and Q3 of the year, which is probably explained by the period when the developers like to launch their sales. We can also see that the new sales of landed properties pale in comparison to that of condominiums.\nWhile the new sales in Q1Y24 is comparable to that in Q4Y23, the number of resale transactions decreased by about 305 which is about 10% decrease."
  },
  {
    "objectID": "TakehomeEx/ex01/takehomeex1.html#transaction-price-on-resale-condos",
    "href": "TakehomeEx/ex01/takehomeex1.html#transaction-price-on-resale-condos",
    "title": "Take Home Ex 1",
    "section": "2.2 Transaction Price on Resale Condos",
    "text": "2.2 Transaction Price on Resale Condos\nNext, we ask the following questions about the resale prices of condos:\n\nHas the overall transaction price of properties, focusing on resale Condominiums increased across the quarter, and year on year comparison for Q1Y24 as compared to Q1Y23?\n\nFirst we look at the data in 2023 and compute some statistical values.\n\ncondo_subset23 &lt;- realis2324_cleaned %&gt;%\n  filter(sale_type %in% c(\"Resale\", \"Sub Sale\"), \n         property_type == \"Condominium\",\n         quarter %in% c(\"Q1Y23\", \"Q2Y23\", \"Q3Y23\", \"Q4Y23\") )\n\n\nresale23_mean &lt;- round(mean(condo_subset23$trans_price))\nresale23_median &lt;- round(median(condo_subset23$trans_price))\n\n\ncondo_subset24 &lt;- realis2324_cleaned %&gt;%\n  filter(sale_type %in% c(\"Resale\", \"Sub Sale\"), \n         property_type == \"Condominium\",\n         quarter %in% c(\"Q1Y24\") )\n\nresale24_mean &lt;- round(mean(condo_subset24$trans_price))\nresale24_median &lt;- round(median(condo_subset24$trans_price))\n\nresaleunit24_median &lt;- round(median(condo_subset24$unit_psm))\nresalesize24_median &lt;- round(median(condo_subset24$unit_area)) \n\n\nymax &lt;- as.numeric(round((IQR(condo_subset24$trans_price)*1.5) +\n                quantile(condo_subset24$trans_price,0.75)))\nymin &lt;- as.integer(min(condo_subset24$trans_price))\n\nNext, we plot the histogram and box plots of the transaction prices of the resale condos (including those sub set sales), up to a limit of $5 million.\n\n\nCode\nh_price &lt;- ggplot(data= condo_subset24, aes(x= trans_price)) +\n  geom_histogram(bins=30) +\n  geom_vline(aes(xintercept = resale23_mean), col=\"darkgrey\", linewidth=0.5, linetype = \"dashed\") +\n  annotate(\"text\", x=2500000, y=360, label=\"Mean Price in 2023:\", \n           size=3, color=\"darkgrey\") +\n  annotate(\"text\", x=2500000, y=330, label=format(resale23_mean, big.mark = \",\"),\n           size=3, color=\"darkgrey\") +\n  geom_vline(aes(xintercept = resale23_median), col=\"darkgrey\", linewidth=0.5, linetype = \"dashed\") +\n  annotate(\"text\", x=900000, y=360, label=\"Median Price in 2023\", \n           size=3, color=\"darkgrey\") +\n  annotate(\"text\", x=900000, y=330, label=format(resale23_median, big.mark = \",\"),\n           size=3, color=\"darkgrey\") +\n  geom_vline(aes(xintercept = resale24_median), col=\"darkblue\", linewidth=0.5, linetype = \"dashed\") +\n  annotate(\"text\", x=900000, y=300, label=\"Median Price in Q1Y24\", \n           size=3, color=\"darkblue\") +\n  annotate(\"text\", x=900000, y=270, label=format(resale24_median, big.mark = \",\"),\n           size=3, color=\"darkblue\")+\n    geom_vline(aes(xintercept = resale24_mean), col=\"darkblue\", linewidth=0.5, linetype = \"dashed\") +\n  annotate(\"text\", x=2500000, y=300, label=\"Mean Price in Q1Y24\", \n           size=3, color=\"darkblue\") +\n  annotate(\"text\", x=2500000, y=270, label=format(resale24_mean, big.mark = \",\"),\n           size=3, color=\"darkblue\") +\n  scale_x_continuous(limits = c(0,5000000),labels = unit_format(unit = \"M\", scale = 1e-6)) +\n  labs(\n    x = \"Transaction Price\",\n    y = \"Number of Transactions\"\n  )\n\n\n\n\nCode\nb_price &lt;- ggplot(data = condo_subset24, aes(y = trans_price)) + \n  geom_boxplot(outlier.colour=\"firebrick\", outlier.shape=16,\n               outlier.size=0.6, notch=FALSE, width = 0.25) + \n  coord_flip() + labs(y = \"\", x = \"\") + \n  scale_y_continuous(limits = c(0,5000000), labels = unit_format(unit = \"M\", scale = 1e-6)) +\n  theme(axis.text = element_blank(), axis.ticks = element_blank()) + \n  stat_boxplot(geom=\"errorbar\", width=0.25) + \n  annotate(\"text\", x=0.15, y=ymax, label=format(ymax, big.mark = \",\"), \n           size=3, color=\"lightpink4\") +\n  annotate(\"text\", x=0.15, y=ymin, label=format(ymin, big.mark = \",\"), \n           size=3, color=\"lightpink4\") +\n  annotate(\"text\", x=-0.15, y=3000000, label=format(resale24_median, big.mark = \",\"),\n           size=3, color=\"lightpink4\") +\n  annotate(\"text\", x=-0.15, y=1000000, label=\"Median Price =\",\n           size=3, color=\"lightpink4\")+\n  labs(title=\"Transaction Price in Q1Y24\")\n\n\n\n\nCode\ncondo_subset2324 &lt;- realis2324_cleaned %&gt;%\n  filter(sale_type %in% c(\"Resale\", \"Sub Sale\"), \n         property_type == \"Condominium\")\n\nbp_price &lt;- ggplot(data=condo_subset2324, \n       aes(y = trans_price, x= quarter)) +\n  geom_boxplot(colour =\"black\", fill=\"#88abff\", alpha=0.5) +\n  geom_hline(aes(yintercept = resale24_median), col=\"darkblue\", linewidth=0.5, linetype = \"dashed\") +\n  geom_point(stat=\"summary\",        \n             fun=mean,           \n             colour =\"darkblue\",          \n             size=2) +\n  scale_y_continuous(limits = c(0,3000000),labels = unit_format(unit = \"M\", scale = 1e-6))+\n  labs(title=\"Transaction Price across Quarters\")\n\n\n\nresale_price24 &lt;- (b_price | bp_price) / h_price\n\np1 &lt;- resale_price24 + plot_annotation(title = \"Both Mean and Median Prices of Resale Transactions are higher in Q1Y24 compared to 2023\")\n\np1 & theme_minimal() +\n  theme(title=element_text(size=8, face='bold'), \n        axis.text.x = element_text(size = 6),\n        axis.text.y = element_text(size = 8),\n        axis.title.y = element_blank(),\n        axis.title.x = element_blank(),\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nFrom the graphs, we can observe that both the median and mean prices in Q1Y24 are higher as compared to that of 2023. The distribution of prices is also more right-skewed with the mean prices &gt; median prices. When we look across the quarters, there also seem to be a gradual increase in the prices.\nWhile the majority of the prices would fall between $1M to $2.2M, there are also quite a number of properties going for higher prices.\nThis is expected given that the transaction prices of properties are dependent on a variety of factors, mainly location, size of the units, age and many more."
  },
  {
    "objectID": "TakehomeEx/ex01/takehomeex1.html#resale-condo-prices-across-planning-regions-in-q1y24",
    "href": "TakehomeEx/ex01/takehomeex1.html#resale-condo-prices-across-planning-regions-in-q1y24",
    "title": "Take Home Ex 1",
    "section": "2.3 Resale Condo Prices across Planning Regions in Q1Y24",
    "text": "2.3 Resale Condo Prices across Planning Regions in Q1Y24\nNext we will zoom into Q1Y24 to examine the data and see if there is any trend relating to the number of transactions and prices.\n\n\nCode\nregion_number &lt;- ggplot(data = condo_subset24, aes(x = fct_infreq(planning_region))) +\n  geom_bar(stat = 'count', position = \"dodge\", color = \"black\", fill = \"#88abff\") +\n  labs(\n    title = \"Higher number of sales in Central Region\",\n    y = \"Number of Transactions\", x = \"Planning Region\"\n  ) \n\nregion_number\n\n\n\n\n\n\n\n\n\n\n\nCode\nregion_size &lt;- ggplot(data=condo_subset2324, \n       aes(y = unit_area, x= fct_infreq(planning_region))) +\n  geom_boxplot(colour =\"black\", fill=\"#88abff\", alpha=0.5) +\n  geom_point(stat=\"summary\",        \n             fun=mean,           \n             colour =\"darkblue\",          \n             size=2) +\n  geom_hline(aes(yintercept = resalesize24_median), col=\"red\", linewidth=0.5, linetype = \"dashed\") +\n  annotate(\"text\", x=4.6, y=150, label=\"Median Unit Size\", \n           size=3, color=\"red\") +\n  annotate(\"text\", x=4.6, y=130, label=format(resalesize24_median, big.mark = \",\"),\n           size=3, color=\"red\")+\n  ylim(0,200) +\n  labs(title=\"Unit Area of Condos Comparable\", y = \"Unit Area (sqm)\", x = \"Planning Region\")\n\nregion_size\n\n\n\n\n\n\n\n\n\n\n\nCode\nregion_unitprice &lt;- ggplot(data=condo_subset2324, \n       aes(y = unit_psm, x= fct_infreq(planning_region))) +\n  geom_boxplot(colour =\"black\", fill=\"#88abff\", alpha=0.5) +\n  geom_hline(aes(yintercept = resaleunit24_median), col=\"red\", linewidth=0.5, linetype = \"dashed\") +\n  geom_point(stat=\"summary\",        \n             fun=mean,           \n             colour =\"darkblue\",          \n             size=2) +\n  annotate(\"text\", x=4.6, y=30000, label=\"Median Unit Price\", \n           size=3, color=\"red\") +\n  annotate(\"text\", x=4.6, y=27000, label=format(resaleunit24_median, big.mark = \",\"),\n           size=3, color=\"red\")+\n  ylim(0,40000) +\n  labs(title=\"Unit Price ($ sqm) higher in Central Region\", y = \"Unit Price ($ sqm)\", x = \"Planning Region\")\n\nregion_unitprice\n\n\n\n\n\n\n\n\n\n\n\nCode\nresale_unitprice24 &lt;- region_number | (region_size / region_unitprice)\n\np2 &lt;- resale_unitprice24 + plot_annotation(title = \"Number of Transactions and Prices higher for Central Region\")\n\np2 & theme_minimal() +\n  theme(title=element_text(size=8, face='bold'), \n        axis.text.x = element_text(size = 6),\n        axis.text.y = element_text(size = 8),\n        axis.title.y = element_blank(),\n        axis.title.x = element_blank(),\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nHere we see that the number of transactions for resale condos in the central region is a lot higher compared to the other regions, and the median price in the central region is also higher compared to the overall median price.\nThe size of the units remain somewhat comparable across the regions, indicating the preference of buyers in this current climate."
  },
  {
    "objectID": "TakehomeEx/ex03/data/shp/Oceanus Geography.html",
    "href": "TakehomeEx/ex03/data/shp/Oceanus Geography.html",
    "title": "Visual Analytics",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#plot-the-path-of-gurnard-grabber",
    "href": "TakehomeEx/ex03/takehomeex3.html#plot-the-path-of-gurnard-grabber",
    "title": "Take Home Ex 3",
    "section": "7.1 Plot the Path of Gurnard Grabber",
    "text": "7.1 Plot the Path of Gurnard Grabber\n\n\nCode\nvessel_trajectory_gurnard &lt;- vessel_trajectory %&gt;%\n  filter(target == \"gurnardgrabberd9a\")\n\npoints_data_gurnard &lt;- vessel_movement_sf %&gt;%\n  filter (target == \"gurnardgrabberd9a\") %&gt;%\n  group_by(target, geometry) %&gt;%\n  summarize(dwell_time = sum(dwell)/60)\n\n# Ensure the geometry column is retained as a 'geometry' class\nst_geometry(points_data_gurnard) &lt;- points_data_gurnard$geometry\n\n\n\n\nCode\nggplot() +\n  geom_sf(data = OceanusGeography) +\n  geom_sf_text(data = OceanusGeography, aes(label = Name), nudge_y = 0.1, size = 2) + \n  geom_sf(data = vessel_trajectory_gurnard, \n          color = \"blue\",  # Set the color of the trajectory\n          linewidth = 1.2, alpha = 0.5) +\n  geom_point(data = points_data_gurnard, \n             aes(x = st_coordinates(geometry)[, \"X\"], \n                 y = st_coordinates(geometry)[, \"Y\"], \n                 size = dwell_time, color = dwell_time), \n             alpha = 1) +  # Add points with size based on dwell time\n  scale_size_continuous(name = \"Dwell Time (mins)\") +  \n  scale_color_gradient(name = \"Dwell Time (mins)\", low = \"mediumpurple1\", high = \"mediumpurple4\") +  \n  theme_minimal() +\n  labs(title = \"Gurnard Grabber - at Ghoti Preserve, Nav points and Exit East\", \n       subtitle = \"Dwell Time at these areas seem high - can investigate further\", \n       x = \"Longitude\", y = \"Latitude\")\n\n\n\n\n\n\n\n\n\n\n\nCode\ngurnard &lt;- other_trespassers %&gt;%\n  filter(vessel == \"Gurnard Grabber\")\n\n\n\n\nCode\nggplot(gurnard, aes(x = time, y = stay_duration)) +\n  geom_bar(stat = \"identity\", position = position_dodge(width = 0.9), fill = \"azure4\") +\n  geom_text(aes(label = round(stay_duration, 2)), position = position_dodge(width = 0.9), vjust = -0.5, size = 3) +  # Add labels above the bars\n  labs(title = \"Gurnard Grabber's stay in Ghoti Preserve\",\n       x = \"Month\",\n       y = \"Average Stay Duration\",\n       subtitle = \"Long duration in Oct corresponds to higher deliveries in Ports\", \n       fill = \"Month\") +\n  ylim (0,170) +\n  theme_minimal()"
  },
  {
    "objectID": "TakehomeEx/ex03/takehomeex3.html#investigate-vessels-from-the-same-company",
    "href": "TakehomeEx/ex03/takehomeex3.html#investigate-vessels-from-the-same-company",
    "title": "Take Home Ex 3",
    "section": "7.2 Investigate vessels from the same company",
    "text": "7.2 Investigate vessels from the same company\nAfter plotting the path, we can investigate further based on the vessels from the same company, e.g. in this case Schmidt Ltd, with another vessel, Black Bullhead Bandit (blackbullheadbandit801), similarly by plotting the paths, can checking the dwell times of the vessels at the suspected areas.\n\n\nCode\nvessel_trajectory_bandit &lt;- vessel_trajectory %&gt;%\n  filter(target == \"blackbullheadbandit801\")\n\npoints_data_bandit &lt;- vessel_movement_sf %&gt;%\n  filter (target == \"blackbullheadbandit801\") %&gt;%\n  group_by(target, geometry) %&gt;%\n  summarize(dwell_time = sum(dwell)/60)\n\n# Ensure the geometry column is retained as a 'geometry' class\nst_geometry(points_data_bandit) &lt;- points_data_bandit$geometry\n\n\n\n\nCode\ncombined_path_gb &lt;- bind_rows(vessel_trajectory_gurnard, vessel_trajectory_bandit)\n\npoints_data_gb &lt;- bind_rows(points_data_gurnard, points_data_bandit)\n\nwrapped_subtitle &lt;- str_wrap(\"Transshipment could have occured at these locations\", width = 60)\n\nggplot() +\n  geom_sf(data = OceanusGeography) +\n  geom_sf_text(data = OceanusGeography, aes(label = Name), nudge_y = 0.1, size = 2) + \n  geom_sf(data = combined_path_gb, aes(color = target), linewidth = 1.2, alpha = 0.2) +\n  \n  scale_color_manual(name = \"Path\", \n                     values = c(\"gurnardgrabberd9a\" = \"blue\", \"blackbullheadbandit801\" = \"red\")) +\n  \n  geom_point(data = points_data_gb, aes(x = st_coordinates(geometry)[, \"X\"], \n                                              y = st_coordinates(geometry)[, \"Y\"], \n                                              size = dwell_time), \n             alpha = 0.7) +  \n   \n  scale_size_continuous(name = \"Dwell Time (mins)\") +\n  \n  theme_minimal() +\n  labs(title = \"Common Points at East of Oceanus\", \n       subtitle = wrapped_subtitle, \n       x = \"Longitude\", y = \"Latitude\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package.\n\n\n\n\nFor this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\nIn this exercise, version 3.2.1 of ggplot2 will be installed instead of the latest version of ggplot2. This is because the current version of ggtern package is not compatible to the latest version of ggplot2.\nThe code chunks below will accomplish the task.\n\n\nCode\npacman::p_load(plotly, ggtern, tidyverse)\n\n\n\n\n\nFor the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\nWe will use read_csv to import the data.\n\n\nCode\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n\nCode\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)\n\n\n\n\n\n\n\n\n\n\nCode\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#overview",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#overview",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "",
    "text": "Ternary plots are a way of displaying the distribution and variability of three-part compositional data. (For example, the proportion of aged, economy active and young population or sand, silt, and clay in soil.) It’s display is a triangle with sides scaled from 0 to 1. Each side represents one of the three components. A point is plotted so that a line drawn perpendicular from the point to each leg of the triangle intersect at the component values of the point.\nIn this hands-on, you will learn how to build ternary plot programmatically using R for visualising and analysing population structure of Singapore.\nThe hands-on exercise consists of four steps:\n\nInstall and launch tidyverse and ggtern packages.\nDerive three new measures using mutate() function of dplyr package.\nBuild a static ternary plot using ggtern() function of ggtern package.\nBuild an interactive ternary plot using plot-ly() function of Plotly R package."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#packages",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#packages",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "",
    "text": "For this exercise, two main R packages will be used in this hands-on exercise, they are:\n\nggtern, a ggplot extension specially designed to plot ternary diagrams. The package will be used to plot static ternary plots.\nPlotly R, an R package for creating interactive web-based graphs via plotly’s JavaScript graphing library, plotly.js . The plotly R libary contains the ggplotly function, which will convert ggplot2 figures into a Plotly object.\n\nWe will also need to ensure that selected tidyverse family packages namely: readr, dplyr and tidyr are also installed and loaded.\nIn this exercise, version 3.2.1 of ggplot2 will be installed instead of the latest version of ggplot2. This is because the current version of ggtern package is not compatible to the latest version of ggplot2.\nThe code chunks below will accomplish the task.\n\n\nCode\npacman::p_load(plotly, ggtern, tidyverse)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#data",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#data",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "",
    "text": "For the purpose of this hands-on exercise, the Singapore Residents by Planning AreaSubzone, Age Group, Sex and Type of Dwelling, June 2000-2018 data will be used. The data set has been downloaded and included in the data sub-folder of the hands-on exercise folder. It is called respopagsex2000to2018_tidy.csv and is in csv file format.\nWe will use read_csv to import the data.\n\n\nCode\npop_data &lt;- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \n\n\n\n\nNext, use the mutate() function of dplyr package to derive three new measures, namely: young, active, and old.\n\n\nCode\nagpop_mutated &lt;- pop_data %&gt;%\n  mutate(`Year` = as.character(Year))%&gt;%\n  spread(AG, Population) %&gt;%\n  mutate(YOUNG = rowSums(.[4:8]))%&gt;%\n  mutate(ACTIVE = rowSums(.[9:16]))  %&gt;%\n  mutate(OLD = rowSums(.[17:21])) %&gt;%\n  mutate(TOTAL = rowSums(.[22:24])) %&gt;%\n  filter(Year == 2018)%&gt;%\n  filter(TOTAL &gt; 0)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#plotting-the-ternary-plot",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#plotting-the-ternary-plot",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "",
    "text": "Code\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\nCode\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# reusable function for creating annotation object\nlabel &lt;- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\n# reusable function for axis formatting\naxis &lt;- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes &lt;- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\n# Initiating a plotly visualization \nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %&gt;%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#overview-1",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#overview-1",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "2.1 Overview",
    "text": "2.1 Overview\nCorrelation coefficient is a popular statistic that use to measure the type and strength of the relationship between two variables. The values of a correlation coefficient ranges between -1.0 and 1.0. A correlation coefficient of 1 shows a perfect linear relationship between the two variables, while a -1.0 shows a perfect inverse relationship between the two variables. A correlation coefficient of 0.0 shows no linear relationship between the two variables.\nWhen multivariate data are used, the correlation coefficeints of the pair comparisons are displayed in a table form known as correlation matrix or scatterplot matrix.\nThere are three broad reasons for computing a correlation matrix.\n\nTo reveal the relationship between high-dimensional variables pair-wisely.\nTo input into other analyses. For example, people commonly use correlation matrices as inputs for exploratory factor analysis, confirmatory factor analysis, structural equation models, and linear regression when excluding missing values pairwise.\nAs a diagnostic when checking other analyses. For example, with linear regression a high amount of correlations suggests that the linear regression’s estimates will be unreliable.\n\nWhen the data is large, both in terms of the number of observations and the number of variables, Corrgram tend to be used to visually explore and analyse the structure and the patterns of relations among variables. It is designed based on two main schemes:\n\nRendering the value of a correlation to depict its sign and magnitude, and\nReordering the variables in a correlation matrix so that “similar” variables are positioned adjacently, facilitating perception.\n\nIn this hands-on exercise, you will learn how to plot data visualisation for visualising correlation matrix with R. It consists of three main sections. First, you will learn how to create correlation matrix using pairs() of R Graphics. Next, you will learn how to plot corrgram using corrplot package of R. Lastly, you will learn how to create an interactive correlation matrix using plotly R."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#packages-1",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#packages-1",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "2.2 Packages",
    "text": "2.2 Packages\nIn this hands-on exercise, the Wine Quality Data Set of UCI Machine Learning Repository will be used. The data set consists of 13 variables and 6497 observations. For the purpose of this exercise, we have combined the red wine and white wine data into one data file. It is called wine_quality and is in csv file format.\n\n\nCode\npacman::p_load(corrplot, ggstatsplot, tidyverse)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#data-1",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#data-1",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "2.3 Data",
    "text": "2.3 Data\n\n\nCode\nwine &lt;- read_csv(\"data/wine_quality.csv\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#building-correlation-matrix-pairs-method",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#building-correlation-matrix-pairs-method",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "2.4 Building Correlation Matrix: pairs() method",
    "text": "2.4 Building Correlation Matrix: pairs() method\nThere are more than one way to build scatterplot matrix with R. In this section, you will learn how to create a scatterplot matrix by using the pairs function of R Graphics.\nBefore you continue to the next step, you should read the syntax description of pairsfunction.\n\n2.4.1 Basic Correlation Matrix\n\n\nCode\npairs(wine[,1:11])\n\n\n\n\n\n\n\n\n\nThe required input of pairs() can be a matrix or data frame. The code chunk used to create the scatterplot matrix is relatively simple. It uses the default pairs function. Columns 2 to 12 of wine dataframe is used to build the scatterplot matrix. The variables are: fixed acidity, volatile acidity, citric acid, residual sugar, chlorides, free sulfur dioxide, total sulfur dioxide, density, pH, sulphates and alcohol.\n\n\nCode\npairs(wine[,2:12])\n\n\n\n\n\n\n\n\n\n\n\n2.4.2 Drawing the Lower Corner\npairs function of R Graphics provided many customisation arguments. For example, it is a common practice to show either the upper half or lower half of the correlation matrix instead of both. This is because a correlation matrix is symmetric.\nTo show the lower half of the correlation matrix, the upper.panel argument will be used as shown in the code chunk below.\n\n\nCode\npairs(wine[,2:12], upper.panel = NULL)\n\n\n\n\n\n\n\n\n\nSimilarly, you can display the upper half of the correlation matrix by using the code chunk below.\n\n\nCode\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\n\n\n\n\n\n\n\n2.4.3 Including with correlation coefficients\nTo show the correlation coefficient of each pair of variables instead of a scatter plot, panel.cor function will be used. This will also show higher correlations in a larger font.\nDon’t worry about the details for now-just type this code into your R session or script. Let’s have more fun way to display the correlation matrix.\n\n\nCode\npanel.cor &lt;- function(x, y, digits=2, prefix=\"\", cex.cor, ...) {\nusr &lt;- par(\"usr\")\non.exit(par(usr))\npar(usr = c(0, 1, 0, 1))\nr &lt;- abs(cor(x, y, use=\"complete.obs\"))\ntxt &lt;- format(c(r, 0.123456789), digits=digits)[1]\ntxt &lt;- paste(prefix, txt, sep=\"\")\nif(missing(cex.cor)) cex.cor &lt;- 0.8/strwidth(txt)\ntext(0.5, 0.5, txt, cex = cex.cor * (1 + r) / 2)\n}\n\npairs(wine[,2:12], \n      upper.panel = panel.cor)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#visualising-correlation-matrix-ggcormat",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#visualising-correlation-matrix-ggcormat",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "2.5 Visualising Correlation Matrix: ggcormat()",
    "text": "2.5 Visualising Correlation Matrix: ggcormat()\nOne of the major limitation of the correlation matrix is that the scatter plots appear very cluttered when the number of observations is relatively large (i.e. more than 500 observations). To over come this problem, Corrgram data visualisation technique suggested by D. J. Murdoch and E. D. Chow (1996) and Friendly, M (2002) and will be used.\nThe are at least three R packages provide function to plot corrgram, they are:\n\ncorrgram\nellipse\ncorrplot\n\nOn top that, some R package like ggstatsplot package also provides functions for building corrgram.\nIn this section, you will learn how to visualising correlation matrix by using ggcorrmat() of ggstatsplot package.\n\n2.5.1 Basic Plot\nOn of the advantage of using ggcorrmat() over many other methods to visualise a correlation matrix is it’s ability to provide a comprehensive and yet professional statistical report as shown in the figure below.\n\n\nCode\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11)\n\n\n\n\n\n\n\n\n\n\n\nCode\nggstatsplot::ggcorrmat(\n  data = wine, \n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  title    = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p &lt; 0.05\"\n)\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\ncor.vars argument is used to compute the correlation matrix needed to build the corrgram.\nggcorrplot.args argument provide additional (mostly aesthetic) arguments that will be passed to ggcorrplot::ggcorrplot function. The list should avoid any of the following arguments since they are already internally being used: corr, method, p.mat, sig.level, ggtheme, colors, lab, pch, legend.title, digits.\n\nThe sample sub-code chunk can be used to control specific component of the plot such as the font size of the x-axis, y-axis, and the statistical report.\n\n\nCode\nggplot.component = list(\n    theme(text=element_text(size=5),\n      axis.text.x = element_text(size = 8),\n      axis.text.y = element_text(size = 8)))"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#building-multiple-plots",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#building-multiple-plots",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "2.6 Building Multiple Plots",
    "text": "2.6 Building Multiple Plots\nSince ggstasplot is an extension of ggplot2, it also supports faceting. However the feature is not available in ggcorrmat() but in the grouped_ggcorrmat() of ggstatsplot.\n\n\nCode\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nto build a facet plot, the only argument needed is grouping.var.\nBehind group_ggcorrmat(), patchwork package is used to create the multiplot. plotgrid.args argument provides a list of additional arguments passed to patchwork::wrap_plots, except for guides argument which is already separately specified earlier.\nLikewise, annotation.args argument is calling plot annotation arguments of patchwork package."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#visualising-correlation-matrix-using-corrplot-package",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#visualising-correlation-matrix-using-corrplot-package",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "2.7 Visualising Correlation Matrix using corrplot Package",
    "text": "2.7 Visualising Correlation Matrix using corrplot Package\nBefore getting started, you are required to read An Introduction to corrplot Package in order to gain basic understanding of corrplot package.\n\n2.7.1 Getting Started with corrplot\nBefore we can plot a corrgram using corrplot(), we need to compute the correlation matrix of wine data frame.\nIn the code chunk below, cor() of R Stats is used to compute the correlation matrix of wine data frame.\n\n\nCode\nwine.cor &lt;- cor(wine[, 1:11])\n\n\n\n\nCode\ncorrplot(wine.cor)\n\n\n\n\n\n\n\n\n\nNotice that the default visual object used to plot the corrgram is circle. The default layout of the corrgram is a symmetric matrix. The default colour scheme is diverging blue-red. Blue colours are used to represent pair variables with positive correlation coefficients and red colours are used to represent pair variables with negative correlation coefficients. The intensity of the colour or also know as saturation is used to represent the strength of the correlation coefficient. Darker colours indicate relatively stronger linear relationship between the paired variables. On the other hand, lighter colours indicates relatively weaker linear relationship.\n\n\n2.7.2 Working with visual geometrics\nIn corrplot package, there are seven visual geometrics (parameter method) can be used to encode the attribute values. They are: circle, square, ellipse, number, shade, color and pie. The default is circle. As shown in the previous section, the default visual geometric of corrplot matrix is circle. However, this default setting can be changed by using the method argument as shown in the code chunk below.\n\n\nCode\ncorrplot(wine.cor, \n         method = \"ellipse\") \n\n\n\n\n\n\n\n\n\nFeel free to change the method argument to other supported visual geometrics.\n\n\n2.7.3 Working with layout\ncorrplor() supports three layout types, namely: “full”, “upper” or “lower”. The default is “full” which display full matrix. The default setting can be changed by using the type argument of corrplot().\n\n\nCode\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\")\n\n\n\n\n\n\n\n\n\nThe default layout of the corrgram can be further customised. For example, arguments diag and tl.col are used to turn off the diagonal cells and to change the axis text label colour to black colour respectively as shown in the code chunk and figure below.\n\n\nCode\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\n\n\n\n\nPlease feel free to experiment with other layout design argument such as tl.pos, tl.cex, tl.offset, cl.pos, cl.cex and cl.offset, just to mention a few of them.\n\n\n2.7.4 Working with mixed layout\nWith corrplot package, it is possible to design corrgram with mixed visual matrix of one half and numerical matrix on the other half. In order to create a coorgram with mixed layout, the corrplot.mixed(), a wrapped function for mixed visualisation style will be used.\nFigure below shows a mixed layout corrgram plotted using wine quality data.\n\n\nCode\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\nThe code chunk used to plot the corrgram are shown below.\n\n\nCode\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\nNotice that argument lower and upper are used to define the visualisation method used. In this case ellipse is used to map the lower half of the corrgram and numerical matrix (i.e. number) is used to map the upper half of the corrgram. The argument tl.pos, on the other, is used to specify the placement of the axis label. Lastly, the diag argument is used to specify the glyph on the principal diagonal of the corrgram.\n\n\n2.7.5 Combining corrgram with the significant test\nIn statistical analysis, we are also interested to know which pair of variables their correlation coefficients are statistically significant.\nFigure below shows a corrgram combined with the significant test. The corrgram reveals that not all correlation pairs are statistically significant. For example the correlation between total sulfur dioxide and free surfur dioxide is statistically significant at significant level of 0.1 but not the pair between total sulfur dioxide and citric acid.\nWith corrplot package, we can use the cor.mtest() to compute the p-values and confidence interval for each pair of variables.\n\n\nCode\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\n\n\n\nCode\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\n\n\n\n\n\n\n2.7.6 Reorder a corrgram\nMatrix reorder is very important for mining the hiden structure and pattern in a corrgram. By default, the order of attributes of a corrgram is sorted according to the correlation matrix (i.e. “original”). The default setting can be over-write by using the order argument of corrplot(). Currently, corrplot package support four sorting methods, they are:\n\n“AOE” is for the angular order of the eigenvectors. See Michael Friendly (2002) for details.\n“FPC” for the first principal component order.\n“hclust” for hierarchical clustering order, and “hclust.method” for the agglomeration method to be used.\n\n“hclust.method” should be one of “ward”, “single”, “complete”, “average”, “mcquitty”, “median” or “centroid”.\n\n“alphabet” for alphabetical order.\n\n“AOE”, “FPC”, “hclust”, “alphabet”. More algorithms can be found in seriation package.\n\n\nCode\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\n\n\n\n2.7.7 Reordering a correlation matrix using hclust\nIf using hclust, corrplot() can draw rectangles around the corrgram based on the results of hierarchical clustering.\n\n\nCode\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#references",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#references",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "2.8 References",
    "text": "2.8 References\nMichael Friendly (2002). “Corrgrams: Exploratory displays for correlation matrices”. The American Statistician, 56, 316–324.\nD.J. Murdoch, E.D. Chow (1996). “A graphical display of large correlation matrices”. The American Statistician, 50, 178–180.\n\nggcormat() of ggstatsplot package\nggscatmat and ggpairs of GGally.\ncorrplot. A graphical display of a correlation matrix or general matrix. It also contains some algorithms to do matrix reordering. In addition, corrplot is good at details, including choosing color, text labels, color labels, layout, etc.\ncorrgram calculates correlation of variables and displays the results graphically. Included panel functions can display points, shading, ellipses, and correlation values with confidence intervals."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#overview-2",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#overview-2",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "3.1 Overview",
    "text": "3.1 Overview\nHeatmaps visualise data through variations in colouring. When applied to a tabular format, heatmaps are useful for cross-examining multivariate data, through placing variables in the columns and observation (or records) in rowa and colouring the cells within the table. Heatmaps are good for showing variance across multiple variables, revealing any patterns, displaying whether any variables are similar to each other, and for detecting if any correlations exist in-between them.\nIn this hands-on exercise, you will gain hands-on experience on using R to plot static and interactive heatmap for visualising and analysing multivariate data."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#packages-2",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#packages-2",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "3.2 Packages",
    "text": "3.2 Packages\nNext, you will use the code chunk below to install and launch seriation, heatmaply, dendextend and tidyverse in RStudio.\n\n\nCode\npacman::p_load(seriation, dendextend, heatmaply, tidyverse)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#data-2",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#data-2",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "3.3 Data",
    "text": "3.3 Data\nIn this hands-on exercise, the data of World Happines 2018 report will be used. The data set is downloaded from here. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\n\n\nCode\nwh &lt;- read_csv(\"data/WHData-2018.csv\")\n\n\n\n\nCode\nrow.names(wh) &lt;- wh$Country\n\n\n\n3.3.1 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform wh data frame into a data matrix.\n\n\nCode\nwh1 &lt;- dplyr::select(wh, c(3, 7:12))\nwh_matrix &lt;- data.matrix(wh)\n\n\nNotice that wh_matrix is in R matrix format."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#static-heatmap",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#static-heatmap",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "3.4 Static Heatmap",
    "text": "3.4 Static Heatmap\nThere are many R packages and functions can be used to drawing static heatmaps, they are:\n\nheatmap()of R stats package. It draws a simple heatmap.\nheatmap.2() of gplots R package. It draws an enhanced heatmap compared to the R base function.\npheatmap() of pheatmap R package. pheatmap package also known as Pretty Heatmap. The package provides functions to draws pretty heatmaps and provides more control to change the appearance of heatmaps.\nComplexHeatmap package of R/Bioconductor package. The package draws, annotates and arranges complex heatmaps (very useful for genomic data analysis). The full reference guide of the package is available here.\nsuperheat package: A Graphical Tool for Exploring Complex Datasets Using Heatmaps. A system for generating extendable and customizable heatmaps for exploring complex datasets, including big data and data with multiple data types. The full reference guide of the package is available here.\n\nIn this section, you will learn how to plot static heatmaps by using heatmap() of R Stats package.\n\n3.4.1 heatmap() of R Stats\nIn this sub-section, we will plot a heatmap by using heatmap() of Base Stats. The code chunk is given below.\n\n\nCode\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      Rowv=NA, Colv=NA)\n\n\n\n\n\n\n\n\n\nNote:\n\nBy default, heatmap() plots a cluster heatmap. The arguments Rowv=NA and Colv=NA are used to switch off the option of plotting the row and column dendrograms.\n\nTo plot a cluster heatmap, we just have to use the default as shown in the code chunk below.\n\n\nCode\nwh_heatmap &lt;- heatmap(wh_matrix)\n\n\n\n\n\n\n\n\n\nNote:\n\nThe order of both rows and columns is different compare to the native wh_matrix. This is because heatmap do a reordering using clusterisation: it calculates the distance between each pair of rows and columns and try to order them by similarity. Moreover, the corresponding dendrogram are provided beside the heatmap.\n\nHere, red cells denotes small values, and red small ones. This heatmap is not really informative. Indeed, the Happiness Score variable have relatively higher values, what makes that the other variables with small values all look the same. Thus, we need to normalize this matrix. This is done using the scale argument. It can be applied to rows or to columns following your needs.\nThe code chunk below normalises the matrix column-wise.\n\n\nCode\nwh_heatmap &lt;- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\n\n\n\nNotice that the values are scaled now. Also note that margins argument is used to ensure that the entire x-axis labels are displayed completely and, cexRow and cexCol arguments are used to define the font size used for y-axis and x-axis labels respectively."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#interactive-heatmap",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#interactive-heatmap",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "3.5 Interactive Heatmap",
    "text": "3.5 Interactive Heatmap\nheatmaply is an R package for building interactive cluster heatmap that can be shared online as a stand-alone HTML file. It is designed and maintained by Tal Galili.\nBefore we get started, you should review the Introduction to Heatmaply to have an overall understanding of the features and functions of Heatmaply package. You are also required to have the user manualof the package handy with you for reference purposes.\nIn this section, you will gain hands-on experience on using heatmaply to design an interactive cluster heatmap. We will still use the wh_matrix as the input data.\n\n3.5.1 Working with heatmaply\n\n\nCode\nheatmaply(mtcars)\n\n\n\n\n\n\nThe code chunk below shows the basic syntax needed to create n interactive heatmap by using heatmaply package.\n\n\nCode\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)])\n\n\n\n\n\n\nNote that:\n\nDifferent from heatmap(), for heatmaply() the default horizontal dendrogram is placed on the left hand side of the heatmap.\nThe text label of each raw, on the other hand, is placed on the right hand side of the heat map.\nWhen the x-axis marker labels are too long, they will be rotated by 135 degree from the north.\n\n\n\n3.5.2 Data trasformation\nWhen analysing multivariate data set, it is very common that the variables in the data sets includes values that reflect different types of measurement. In general, these variables’ values have their own range. In order to ensure that all the variables have comparable values, data transformation are commonly used before clustering.\nThree main data transformation methods are supported by heatmaply(), namely: scale, normalise and percentilse.\n\n3.5.2.1 Scaling Method\n\nWhen all variables are came from or assumed to come from some normal distribution, then scaling (i.e.: subtract the mean and divide by the standard deviation) would bring them all close to the standard normal distribution.\nIn such a case, each value would reflect the distance from the mean in units of standard deviation.\nThe scale argument in heatmaply() supports column and row scaling.\n\nThe code chunk below is used to scale variable values columewise.\n\n\nCode\nheatmaply(wh_matrix[, -c(1, 2, 4, 5)],\n          scale = \"column\")\n\n\n\n\n\n\n\n\n3.5.2.2 Normalising Method\n\nWhen variables in the data comes from possibly different (and non-normal) distributions, the normalize function can be used to bring data to the 0 to 1 scale by subtracting the minimum and dividing by the maximum of all observations.\nThis preserves the shape of each variable’s distribution while making them easily comparable on the same “scale”.\n\nDifferent from Scaling, the normalise method is performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n3.5.2.3 Percentising Method\n\nThis is similar to ranking the variables, but instead of keeping the rank values, divide them by the maximal rank.\nThis is done by using the ecdf of the variables on their own values, bringing each value to its empirical percentile.\nThe benefit of the percentize function is that each value has a relatively clear interpretation, it is the percent of observations that got that value or below it.\n\nSimilar to Normalize method, the Percentize method is also performed on the input data set i.e. wh_matrix as shown in the code chunk below.\n\n\nCode\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))\n\n\n\n\n\n\n\n\n\n3.5.3 Clustering algorithm\nheatmaply supports a variety of hierarchical clustering algorithm. The main arguments provided are:\n\ndistfun: function used to compute the distance (dissimilarity) between both rows and columns. Defaults to dist. The options “pearson”, “spearman” and “kendall” can be used to use correlation-based clustering, which uses as.dist(1 - cor(t(x))) as the distance metric (using the specified correlation method).\nhclustfun: function used to compute the hierarchical clustering when Rowv or Colv are not dendrograms. Defaults to hclust.\ndist_method default is NULL, which results in “euclidean” to be used. It can accept alternative character strings indicating the method to be passed to distfun. By default distfun is “dist”” hence this can be one of “euclidean”, “maximum”, “manhattan”, “canberra”, “binary” or “minkowski”.\nhclust_method default is NULL, which results in “complete” method to be used. It can accept alternative character strings indicating the method to be passed to hclustfun. By default hclustfun is hclust hence this can be one of “ward.D”, “ward.D2”, “single”, “complete”, “average” (= UPGMA), “mcquitty” (= WPGMA), “median” (= WPGMC) or “centroid” (= UPGMC).\n\nIn general, a clustering model can be calibrated either manually or statistically.\n\n\n3.5.4 Manual Approach\nIn the code chunk below, the heatmap is plotted by using hierachical clustering algorithm with “Euclidean distance” and “ward.D” method.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\")\n\n\n\n\n\n\n\n\n3.5.5 Statistical Approach\nIn order to determine the best clustering method and number of cluster the dend_expend() and find_k() functions of dendextend package will be used.\nFirst, the dend_expend() will be used to determine the recommended clustering method to be used.\n\n\nCode\nwh_d &lt;- dist(normalize(wh_matrix[, -c(1, 2, 4, 5)]), method = \"euclidean\")\ndend_expend(wh_d)[[3]]\n\n\n  dist_methods hclust_methods     optim\n1      unknown         ward.D 0.6137851\n2      unknown        ward.D2 0.6289186\n3      unknown         single 0.4774362\n4      unknown       complete 0.6434009\n5      unknown        average 0.6701688\n6      unknown       mcquitty 0.5020102\n7      unknown         median 0.5901833\n8      unknown       centroid 0.6338734\n\n\nThe output table shows that “average” method should be used because it gave the high optimum value.\nNext, find_k() is used to determine the optimal number of cluster.\n\n\nCode\nwh_clust &lt;- hclust(wh_d, method = \"average\")\nnum_k &lt;- find_k(wh_clust)\nplot(num_k)\n\n\n\n\n\n\n\n\n\nFigure above shows that k=3 would be good.\nWith reference to the statistical analysis results, we can prepare the code chunk as shown below.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\n\n\n3.5.6 Seriation\nOne of the problems with hierarchical clustering is that it doesn’t actually place the rows in a definite order, it merely constrains the space of possible orderings. Take three items A, B and C. If you ignore reflections, there are three possible orderings: ABC, ACB, BAC. If clustering them gives you ((A+B)+C) as a tree, you know that C can’t end up between A and B, but it doesn’t tell you which way to flip the A+B cluster. It doesn’t tell you if the ABC ordering will lead to a clearer-looking heatmap than the BAC ordering.\nheatmaply uses the seriation package to find an optimal ordering of rows and columns. Optimal means to optimize the Hamiltonian path length that is restricted by the dendrogram structure. This, in other words, means to rotate the branches so that the sum of distances between each adjacent leaf (label) will be minimized. This is related to a restricted version of the travelling salesman problem.\nHere we meet our first seriation algorithm: Optimal Leaf Ordering (OLO). This algorithm starts with the output of an agglomerative clustering algorithm and produces a unique ordering, one that flips the various branches of the dendrogram around so as to minimize the sum of dissimilarities between adjacent leaves. Here is the result of applying Optimal Leaf Ordering to the same clustering result as the heatmap above.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"OLO\")\n\n\n\n\n\n\nThe default options is “OLO” (Optimal leaf ordering) which optimizes the above criterion (in O(n^4)). Another option is “GW” (Gruvaeus and Wainer) which aims for the same goal but uses a potentially faster heuristic.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"GW\")\n\n\n\n\n\n\nThe option “mean” gives the output we would get by default from heatmap functions in other packages such as gplots::heatmap.2.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"mean\")\n\n\n\n\n\n\nThe option “none” gives us the dendrograms without any rotation that is based on the data matrix.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\")\n\n\n\n\n\n\n\n\n3.5.7 Working with colour palettes\nThe default colour palette uses by heatmaply is viridis. heatmaply users, however, can use other colour palettes in order to improve the aestheticness and visual friendliness of the heatmap.\nIn the code chunk below, the Blues colour palette of rColorBrewer is used.\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          seriate = \"none\",\n          colors = Blues)\n\n\n\n\n\n\n\n\n3.5.8 The finishing touch\nBeside providing a wide collection of arguments for meeting the statistical analysis needs, heatmaply also provides many plotting features to ensure cartographic quality heatmap can be produced.\nIn the code chunk below the following arguments are used:\n\nk_row is used to produce 5 groups.\nmargins is used to change the top margin to 60 and row margin to 200.\nfontsizw_row and fontsize_col are used to change the font size for row and column labels to 4.\nmain is used to write the main title of the plot.\nxlab and ylab are used to write the x-axis and y-axis labels respectively.\n\n\n\nCode\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#overview-3",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#overview-3",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "4.1 Overview",
    "text": "4.1 Overview\nParallel coordinates plot is a data visualisation specially designed for visualising and analysing multivariate, numerical data. It is ideal for comparing multiple variables together and seeing the relationships between them. For example, the variables contribute to Happiness Index. Parallel coordinates was invented by Alfred Inselberg in the 1970s as a way to visualize high-dimensional data. This data visualisation technique is more often found in academic and scientific communities than in business and consumer data visualizations. As pointed out by Stephen Few(2006), “This certainly isn’t a chart that you would present to the board of directors or place on your Web site for the general public. In fact, the strength of parallel coordinates isn’t in their ability to communicate some truth in the data to others, but rather in their ability to bring meaningful multivariate patterns and comparisons to light when used interactively for analysis.” For example, parallel coordinates plot can be used to characterise clusters detected during customer segmentation.\nBy the end of this hands-on exercise, you will gain hands-on experience on:\n\nplotting statistic parallel coordinates plots by using ggparcoord() of GGally package,\nplotting interactive parallel coordinates plots by using parcoords package, and\nplotting interactive parallel coordinates plots by using parallelPlot package."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#packages-3",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#packages-3",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "4.2 Packages",
    "text": "4.2 Packages\nFor this exercise, the GGally, parcoords, parallelPlot and tidyverse packages will be used.\nThe code chunks below are used to install and load the packages in R.\n\n\nCode\npacman::p_load(GGally, parallelPlot, tidyverse)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#data-prep",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#data-prep",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "4.3 Data Prep",
    "text": "4.3 Data Prep\nIn this hands-on exercise, the World Happinees 2018 (http://worldhappiness.report/ed/2018/) data will be used. The data set is download at https://s3.amazonaws.com/happiness-report/2018/WHR2018Chapter2OnlineData.xls. The original data set is in Microsoft Excel format. It has been extracted and saved in csv file called WHData-2018.csv.\nThis has already been read earlier."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#plotting-static-parallel-coordinates-plot",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#plotting-static-parallel-coordinates-plot",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "4.4 Plotting Static Parallel Coordinates Plot",
    "text": "4.4 Plotting Static Parallel Coordinates Plot\nIn this section, you will learn how to plot static parallel coordinates plot by using ggparcoord() of GGally package. Before getting started, it is a good practice to read the function description in detail.\n\n4.4.1 Plotting a simple parallel coordinates\nCode chunk below shows a typical syntax used to plot a basic static parallel coordinates plot by using ggparcoord().\n\n\nCode\nggparcoord(data = wh, \n           columns = c(7:12))\n\n\n\n\n\n\n\n\n\nNotice that only two argument namely data and columns is used. Data argument is used to map the data object (i.e. wh) and columns is used to select the columns for preparing the parallel coordinates plot.\n\n\n4.4.2 Plotting a parallel coordinates with boxplot\nThe basic parallel coordinates failed to reveal any meaning understanding of the World Happiness measures. In this section, you will learn how to makeover the plot by using a collection of arguments provided by ggparcoord().\n\n\nCode\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above.\n\ngroupColumn argument is used to group the observations (i.e. parallel lines) by using a single variable (i.e. Region) and colour the parallel coordinates lines by region name.\nscale argument is used to scale the variables in the parallel coordinate plot by using uniminmax method. The method univariately scale each variable so the minimum of the variable is zero and the maximum is one.\nalphaLines argument is used to reduce the intensity of the line colour to 0.2. The permissible value range is between 0 to 1.\nboxplot argument is used to turn on the boxplot by using logical TRUE. The default is FALSE.\ntitle argument is used to provide the parallel coordinates plot a title.\n\n\n\n4.4.3 Parallel coordinates with facet\nSince ggparcoord() is developed by extending ggplot2 package, we can combination use some of the ggplot2 function when plotting a parallel coordinates plot.\nIn the code chunk below, facet_wrap() of ggplot2 is used to plot 10 small multiple parallel coordinates plots. Each plot represent one geographical region such as East Asia.\n\n\nCode\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region)\n\n\n\n\n\n\n\n\n\nOne of the aesthetic defect of the current design is that some of the variable names overlap on x-axis.\n\n\n4.4.4 Rotating x-axis text label\n\n\nCode\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nTo rotate x-axis text labels, we use axis.text.x as argument to theme() function. And we specify element_text(angle = 30) to rotate the x-axis text by an angle 30 degree.\n\n\n\n4.4.5 Adjusting the rotated x-axis text label\nRotating x-axis text labels to 30 degrees makes the label overlap with the plot and we can avoid this by adjusting the text location using hjust argument to theme’s text element with element_text(). We use axis.text.x as we want to change the look of x-axis text.\n\n\nCode\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30, hjust=1))"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#plotting-interactive-parallel-coordinates-plot-parallelplot-methods",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "4.5 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods",
    "text": "4.5 Plotting Interactive Parallel Coordinates Plot: parallelPlot methods\nparallelPlot is an R package specially designed to plot a parallel coordinates plot by using ‘htmlwidgets’ package and d3.js. In this section, you will learn how to use functions provided in parallelPlot package to build interactive parallel coordinates plot.\n\n4.5.1 Basic Plot\nThe code chunk below plot an interactive parallel coordinates plot by using parallelPlot().\n\n\nCode\nwh &lt;- wh %&gt;%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250)\n\n\n\n\n\n\nNotice that some of the axis labels are too long. You will learn how to overcome this problem in the next step.\n\n\n4.5.2 Rotate axis label\nIn the code chunk below, rotateTitle argument is used to avoid overlapping axis labels.\n\n\nCode\nparallelPlot(wh,\n             rotateTitle = TRUE)\n\n\n\n\n\n\nOne of the useful interactive feature of parallelPlot is we can click on a variable of interest, for example Happiness score, the monotonous blue colour (default) will change a blues with different intensity colour scheme will be used.\n\n\n4.5.3 Changing the colour scheme\nWe can change the default blue colour scheme by using continousCS argument as shown in the code chunk below.\n\n\nCode\nparallelPlot(wh,\n             continuousCS = \"YlOrRd\",\n             rotateTitle = TRUE)\n\n\n\n\n\n\n\n\n4.5.4 Parallel coordinates plot with histogram\nIn the code chunk below, histoVisibility argument is used to plot histogram along the axis of each variables.\n\n\nCode\nhistoVisibility &lt;- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#references-1",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#references-1",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "4.6 References",
    "text": "4.6 References\n\nggparcoord() of GGally package\nparcoords user guide\nparallelPlot"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#overview-4",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#overview-4",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "5.1 Overview",
    "text": "5.1 Overview\nIn this hands-on exercise, you will gain hands-on experiences on designing treemap using appropriate R packages. The hands-on exercise consists of three main section. First, you will learn how to manipulate transaction data into a treemap strcuture by using selected functions provided in dplyr package. Then, you will learn how to plot static treemap by using treemap package. In the third section, you will learn how to design interactive treemap by using d3treeR package."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#packages-4",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#packages-4",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "5.2 Packages",
    "text": "5.2 Packages\nBefore we get started, you are required to check if treemap and tidyverse pacakges have been installed in you R.\n\n\nCode\npacman::p_load(treemap, treemapify, tidyverse)"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#data-3",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#data-3",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "5.3 Data",
    "text": "5.3 Data\nIn this exercise, REALIS2018.csv data will be used. This dataset provides information of private property transaction records in 2018. The dataset is extracted from REALIS portal (https://spring.ura.gov.sg/lad/ore/login/index.cfm) of Urban Redevelopment Authority (URA).\n\n\nCode\nrealis2018 &lt;- read_csv(\"data/realis2018.csv\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#data-prep-1",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#data-prep-1",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "5.4 Data Prep",
    "text": "5.4 Data Prep\nThe data.frame realis2018 is in trasaction record form, which is highly disaggregated and not appropriate to be used to plot a treemap. In this section, we will perform the following steps to manipulate and prepare a data.frtame that is appropriate for treemap visualisation:\n\ngroup transaction records by Project Name, Planning Region, Planning Area, Property Type and Type of Sale, and\ncompute Total Unit Sold, Total Area, Median Unit Price and Median Transacted Price by applying appropriate summary statistics on No. of Units, Area (sqm), Unit Price ($ psm) and Transacted Price ($) respectively.\n\nTwo key verbs of dplyr package, namely: group_by() and summarize() will be used to perform these steps.\ngroup_by() breaks down a data.frame into specified groups of rows. When you then apply the verbs above on the resulting object they’ll be automatically applied “by group”.\nGrouping affects the verbs as follows:\n\ngrouped select() is the same as ungrouped select(), except that grouping variables are always retained.\ngrouped arrange() is the same as ungrouped; unless you set .by_group = TRUE, in which case it orders first by the grouping variables.\nmutate() and filter() are most useful in conjunction with window functions (like rank(), or min(x) == x). They are described in detail in vignette(“window-functions”).\nsample_n() and sample_frac() sample the specified number/fraction of rows in each group.\nsummarise() computes the summary for each group.\n\nIn our case, group_by() will used together with summarise() to derive the summarised data.frame."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#grouped-summaries-withthe-pipe",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#grouped-summaries-withthe-pipe",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "5.5 Grouped summaries withthe Pipe",
    "text": "5.5 Grouped summaries withthe Pipe\n\n\nCode\nrealis2018_summarised &lt;- realis2018 %&gt;% \n  group_by(`Project Name`,`Planning Region`, \n           `Planning Area`, `Property Type`, \n           `Type of Sale`) %&gt;%\n  summarise(`Total Unit Sold` = sum(`No. of Units`, na.rm = TRUE), \n            `Total Area` = sum(`Area (sqm)`, na.rm = TRUE),\n            `Median Unit Price ($ psm)` = median(`Unit Price ($ psm)`, na.rm = TRUE),\n            `Median Transacted Price` = median(`Transacted Price ($)`, na.rm = TRUE))"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#designing-treemap-with-treemap-package",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#designing-treemap-with-treemap-package",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "5.6 Designing Treemap with treemap Package",
    "text": "5.6 Designing Treemap with treemap Package\ntreemap package is a R package specially designed to offer great flexibility in drawing treemaps. The core function, namely: treemap() offers at least 43 arguments. In this section, we will only explore the major arguments for designing elegent and yet truthful treemaps.\n\n5.6.1 Designing a static treemap\nIn this section, treemap() of Treemap package is used to plot a treemap showing the distribution of median unit prices and total unit sold of resale condominium by geographic hierarchy in 2017.\nFirst, we will select records belongs to resale condominium property type from realis2018_selected data frame.\n\n\nCode\nrealis2018_selected &lt;- realis2018_summarised %&gt;%\n  filter(`Property Type` == \"Condominium\", `Type of Sale` == \"Resale\")\n\n\n\n\n5.6.2 Basic Arguments\nThe code chunk below designed a treemap by using three core arguments of treemap(), namely: index, vSize and vColor.\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nThings to learn from the three arguments used:\n\nindex\n\nThe index vector must consist of at least two column names or else no hierarchy treemap will be plotted.\nIf multiple column names are provided, such as the code chunk above, the first name is the highest aggregation level, the second name the second highest aggregation level, and so on.\n\nvSize\n\nThe column must not contain negative values. This is because it’s vaues will be used to map the sizes of the rectangles of the treemaps.\n\n\nWarning:\nThe treemap above was wrongly coloured. For a correctly designed treemap, the colours of the rectagles should be in different intensity showing, in our case, median unit prices.\nFor treemap(), vColor is used in combination with the argument type to determines the colours of the rectangles. Without defining type, like the code chunk above, treemap() assumes type = index, in our case, the hierarchy of planning areas."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#working-with-vcolor-and-type-arguments",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#working-with-vcolor-and-type-arguments",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "5.7 Working with vColor and type arguments",
    "text": "5.7 Working with vColor and type arguments\nIn the code chunk below, type argument is define as value.\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type = \"value\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nThinking to learn from the conde chunk above.\n\nThe rectangles are coloured with different intensity of green, reflecting their respective median unit prices.\nThe legend reveals that the values are binned into ten bins, i.e. 0-5000, 5000-10000, etc. with an equal interval of 5000."
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#colours-in-treemap-package",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#colours-in-treemap-package",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "5.8 Colours in treemap package",
    "text": "5.8 Colours in treemap package\nThere are two arguments that determine the mapping to color palettes: mapping and palette. The only difference between “value” and “manual” is the default value for mapping. The “value” treemap considers palette to be a diverging color palette (say ColorBrewer’s “RdYlBu”), and maps it in such a way that 0 corresponds to the middle color (typically white or yellow), -max(abs(values)) to the left-end color, and max(abs(values)), to the right-end color. The “manual” treemap simply maps min(values) to the left-end color, max(values) to the right-end color, and mean(range(values)) to the middle color.\n\n5.8.1 The “value” type treemap\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above:\n\nalthough the colour palette used is RdYlBu but there are no red rectangles in the treemap above. This is because all the median unit prices are positive.\nThe reason why we see only 5000 to 45000 in the legend is because the range argument is by default c(min(values, max(values)) with some pretty rounding.\n\n\n\n5.8.2 The “manual” type treemap\nThe “manual” type does not interpret the values as the “value” type does. Instead, the value range is mapped linearly to the colour palette.\nThe code chunk below shows a manual type treemap.\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"RdYlBu\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk above:\n\nThe colour scheme used is very confusing. This is because mapping = (min(values), mean(range(values)), max(values)). It is not wise to use diverging colour palette such as RdYlBu if the values are all positive or negative\n\nTo overcome this problem, a single colour palette such as Blues should be used.\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n5.8.3 Treemap Layout\ntreemap() supports two popular treemap layouts, namely: “squarified” and “pivotSize”. The default is “pivotSize”.\nThe squarified treemap algorithm (Bruls et al., 2000) produces good aspect ratios, but ignores the sorting order of the rectangles (sortID). The ordered treemap, pivot-by-size, algorithm (Bederson et al., 2002) takes the sorting order (sortID) into account while aspect ratios are still acceptable.\n\n\n5.8.4 Working with algorithm argument\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"squarified\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n5.8.5 Using sortID\nWhen “pivotSize” algorithm is used, sortID argument can be used to determine the order in which the rectangles are placed from top left to bottom right.\n\n\nCode\ntreemap(realis2018_selected,\n        index=c(\"Planning Region\", \"Planning Area\", \"Project Name\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"manual\",\n        palette=\"Blues\", \n        algorithm = \"pivotSize\",\n        sortID = \"Median Transacted Price\",\n        title=\"Resale Condominium by Planning Region and Area, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#designing-treemap-using-treemapify-package",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#designing-treemap-using-treemapify-package",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "5.9 Designing Treemap using treemapify Package",
    "text": "5.9 Designing Treemap using treemapify Package\ntreemapify is a R package specially developed to draw treemaps in ggplot2. In this section, you will learn how to designing treemps closely resemble treemaps designing in previous section by using treemapify. Before you getting started, you should read Introduction to “treemapify” its user guide.\n\n5.9.1 Basic Treemap\n\n\nCode\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`),\n       layout = \"scol\",\n       start = \"bottomleft\") + \n  geom_treemap() +\n  scale_fill_gradient(low = \"light blue\", high = \"blue\")\n\n\n\n\n\n\n\n\n\n\n\n5.9.2 Defining hierarchy\n\n\nCode\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`),\n       start = \"topleft\") + \n  geom_treemap()\n\n\n\n\n\n\n\n\n\nGroup by Planning Area\n\n\nCode\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap()\n\n\n\n\n\n\n\n\n\nAdding boundary line\n\n\nCode\nggplot(data=realis2018_selected, \n       aes(area = `Total Unit Sold`,\n           fill = `Median Unit Price ($ psm)`,\n           subgroup = `Planning Region`,\n           subgroup2 = `Planning Area`)) + \n  geom_treemap() +\n  geom_treemap_subgroup2_border(colour = \"gray40\",\n                                size = 2) +\n  geom_treemap_subgroup_border(colour = \"gray20\")"
  },
  {
    "objectID": "HandsOnEx/HandsOnEx9/handsonex9.html#designing-interactive-treemap-using-d3treer",
    "href": "HandsOnEx/HandsOnEx9/handsonex9.html#designing-interactive-treemap-using-d3treer",
    "title": "Ex 9 - Multivariate Analysis",
    "section": "5.10 Designing Interactive Treemap using d3treeR",
    "text": "5.10 Designing Interactive Treemap using d3treeR\n\n5.10.1 Installing Package\nThis slide shows you how to install a R package which is not available in cran.\n\nIf this is the first time you install a package from github, you should install devtools package by using the code below or else you can skip this step.\nNext, you will load the devtools library and install the package found in github by using the codes below.\nNow you are ready to launch d3treeR package\n\n\n\nCode\nlibrary(devtools)\ninstall_github(\"timelyportfolio/d3treeR\")\n\n\n\n\nCode\nlibrary(d3treeR)\n\n\n\n\n5.10.2 Designing An Interactive Treemap\nThe codes below perform two processes.\n\ntreemap() is used to build a treemap by using selected variables in condominium data.frame. The treemap created is save as object called tm.\n\n\n\nCode\ntm &lt;- treemap(realis2018_summarised,\n        index=c(\"Planning Region\", \"Planning Area\"),\n        vSize=\"Total Unit Sold\",\n        vColor=\"Median Unit Price ($ psm)\",\n        type=\"value\",\n        title=\"Private Residential Property Sold, 2017\",\n        title.legend = \"Median Unit Price (S$ per sq. m)\"\n        )\n\n\n\n\n\n\n\n\n\n\nThen d3tree() is used to build an interactive treemap.\n\n\n\nCode\nd3tree(tm,rootname = \"Singapore\" )"
  },
  {
    "objectID": "InClassEx/Ex09/inclassex09.html",
    "href": "InClassEx/Ex09/inclassex09.html",
    "title": "In Class Ex 9 - Interactive Multivariate",
    "section": "",
    "text": "Use of ScatterPlotMatrix\nhttps://cran.r-project.org/web/packages/scatterPlotMatrix/vignettes/introduction-to-scatterplotmatrix.html\nUsing widgets instead of wrapping\n\n\nCode\npacman::p_load(scatterPlotMatrix, parallelPlot, cluster, factoextra, tidyverse)\n\n\nWe will be using the wine data from the hands on exercise.\n\n\nCode\nwine &lt;- read_csv(\"data/wine_quality.csv\")\n\n\n\n\nCode\nggplot(data = wine,\n       aes(x=type)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n\n\nCode\nwhitewine &lt;- wine %&gt;%\n  filter(type== \"white\") %&gt;%\n  select (1:11)\n\n\nThese widgets usually need a special definition of the size of the container, i.e. width and height = 500 = pixels.\n\n\nCode\nscatterPlotMatrix(whitewine,\n                  corrPlotType = \"Text\",\n                  distribType = 1,\n                  width = 700,\n                  height = 700)\n\n\n\n\n\n\nUsing the interactive tools - we can use visual inspection to check on the outliers. For example, here we can select the outlier and see that the point is outliers for other factors as well. Then we can choose to investigate further into the data. (Point 2782)\n\nThis package is available for use with Shiny - but need to read the documentation carefully. The code may be different, for example here: scatterPlotMatrixOutput and at the server end: renderScatterPlotMatrix, instead of the typical code in R.\n\n\nClustering\n\n\nCode\nset.seed(1234)\n\ngap.stat &lt;- clusGap(whitewine, \n                    FUNcluster = kmeans, \n                    K.max = 8)\n\nfviz_gap_stat(gap.stat)\n\n\n\n\n\nCode\nset.seed(123)\nkmeans4 &lt;- kmeans(whitewine,4, nstart =25)\n\nprint(kmeans4)\n\n\nK-means clustering with 4 clusters of sizes 757, 978, 1444, 1719\n\nCluster means:\n  fixed acidity volatile acidity citric acid residual sugar  chlorides\n1      6.981506        0.2965786   0.3563540       9.705878 0.05227081\n2      6.805112        0.2759356   0.3168814       3.607822 0.04012781\n3      6.908172        0.2776939   0.3455402       7.780852 0.04919668\n4      6.782403        0.2719372   0.3247469       5.348342 0.04324549\n  free sulfur dioxide total sulfur dioxide   density       pH sulphates\n1            52.83421             206.8164 0.9965522 3.176975 0.5179392\n2            20.52761              83.1411 0.9919192 3.175256 0.4707566\n3            42.31129             160.3061 0.9951215 3.193996 0.4940651\n4            30.11635             121.1963 0.9931958 3.195829 0.4847935\n    alcohol\n1  9.611471\n2 11.233930\n3 10.120392\n4 10.833256\n\nClustering vector:\n   [1] 3 4 2 1 1 2 4 3 4 4 2 4 2 3 3 4 2 2 3 4 2 2 4 3 4 1 3 4 4 4 4 2 2 4 3 4 3\n  [38] 4 3 3 3 3 3 3 3 3 1 1 3 3 3 4 2 4 4 1 1 3 2 4 4 3 3 2 4 4 4 3 2 4 1 1 1 2\n  [75] 2 4 2 2 4 4 4 3 3 1 3 3 3 1 3 3 3 1 4 4 3 1 3 2 2 3 1 3 3 3 1 4 3 3 3 1 3\n [112] 1 1 3 3 2 4 2 1 1 2 4 4 4 3 3 4 1 3 3 2 1 1 1 1 3 4 3 2 2 2 3 4 2 2 4 3 2\n [149] 2 4 3 3 4 2 2 1 1 4 4 4 4 3 2 1 1 3 1 2 3 4 4 2 2 4 3 3 2 3 4 3 3 1 3 1 1\n [186] 1 3 4 4 1 1 3 4 4 1 1 1 1 1 1 1 1 1 4 4 3 4 4 2 3 2 4 4 4 4 3 3 3 3 3 3 3\n [223] 4 3 4 3 1 1 1 3 4 1 1 1 1 1 1 1 4 3 1 2 2 1 3 1 4 2 2 4 1 1 3 4 3 3 2 2 4\n [260] 2 4 3 2 1 3 3 3 3 3 3 3 3 3 4 1 3 3 2 2 4 4 4 1 1 1 3 1 1 1 1 1 3 1 3 3 3\n [297] 3 1 3 4 2 2 2 3 3 3 3 3 4 3 2 3 3 3 3 4 4 4 4 2 2 4 4 4 1 1 1 3 1 2 4 4 2\n [334] 4 2 2 4 3 4 3 3 4 4 3 3 4 2 3 4 3 3 4 4 4 1 1 1 3 3 3 3 2 4 1 2 4 3 3 3 2\n [371] 3 3 1 3 2 2 4 2 3 4 2 3 3 3 4 2 4 1 4 1 1 2 4 2 3 3 2 4 3 2 4 3 4 1 3 3 4\n [408] 4 4 2 3 3 2 2 3 3 2 1 2 4 4 1 1 1 3 1 1 1 2 1 1 2 1 3 4 2 1 1 1 4 2 4 4 1\n [445] 3 2 3 4 4 4 3 4 3 4 4 4 2 4 1 1 4 3 3 2 3 4 3 2 3 1 3 1 2 4 4 1 4 4 3 3 3\n [482] 4 4 3 1 4 4 2 3 3 2 2 3 3 4 3 1 3 3 1 1 3 1 1 3 3 4 3 3 3 3 3 4 2 4 3 3 3\n [519] 2 2 4 4 2 2 2 4 2 4 4 4 4 3 3 3 3 3 3 3 2 1 3 1 3 3 3 3 3 2 4 1 3 2 4 3 4\n [556] 2 3 4 3 3 3 4 3 4 3 2 2 3 3 3 1 4 3 3 4 1 1 3 4 4 1 4 3 2 4 2 3 4 4 4 4 4\n [593] 3 4 4 4 3 4 4 2 3 4 4 4 4 4 3 3 3 2 4 2 4 4 4 4 2 1 1 4 1 3 4 2 4 4 3 1 1\n [630] 2 3 3 4 1 3 4 4 3 1 1 4 1 1 3 3 3 3 3 1 1 1 1 1 4 3 4 2 4 1 1 2 4 3 2 3 4\n [667] 1 3 3 1 1 2 3 4 1 1 1 2 2 2 3 3 3 3 3 1 4 1 1 4 4 1 1 3 1 1 2 1 1 1 1 4 2\n [704] 4 4 2 1 3 4 2 3 4 4 1 1 3 1 3 3 4 3 3 4 2 4 4 4 2 3 3 4 1 2 3 1 4 3 1 3 4\n [741] 2 2 4 3 3 4 1 3 3 3 3 3 3 1 4 4 3 3 3 4 3 3 1 4 3 4 1 2 4 4 4 3 3 3 4 4 2\n [778] 1 3 3 2 1 3 3 1 4 4 4 4 4 4 2 3 2 3 3 1 3 4 2 3 1 1 3 4 3 1 1 1 1 1 4 3 3\n [815] 1 4 2 4 4 4 2 1 4 4 2 3 3 4 2 2 4 3 4 2 4 4 3 3 3 4 4 3 3 4 4 4 3 2 3 4 4\n [852] 3 4 3 4 4 3 3 3 3 4 1 3 4 3 4 4 3 3 2 3 3 4 2 2 4 4 4 4 4 4 4 4 4 1 4 3 2\n [889] 3 2 3 4 4 4 4 2 1 2 2 1 3 4 1 1 3 2 2 4 3 1 4 4 4 2 2 2 4 4 4 4 3 3 3 1 3\n [926] 2 2 3 3 4 2 1 1 1 1 1 2 4 1 1 1 1 2 4 4 4 1 3 2 2 4 4 2 4 4 4 4 2 2 3 3 4\n [963] 3 4 3 2 1 3 2 2 2 4 3 2 4 4 4 1 3 2 2 3 2 2 3 4 3 3 3 4 3 2 1 2 3 3 2 3 3\n[1000] 3 2 1 1 4 3 2 3 2 1 3 4 3 2 1 3 4 4 4 3 1 4 4 1 3 3 4 3 2 4 1 3 1 1 1 1 3\n[1037] 2 2 4 2 4 2 4 1 2 2 4 2 2 4 3 4 2 4 2 4 4 1 4 3 4 1 1 1 3 4 3 4 2 3 3 4 4\n[1074] 1 3 4 3 4 1 1 4 3 3 1 4 3 4 4 1 4 1 3 3 4 1 2 3 4 4 4 3 4 3 4 3 1 4 2 2 3\n[1111] 2 2 3 2 2 2 2 1 2 4 4 4 2 4 4 3 3 2 2 4 3 4 3 4 4 3 3 3 4 2 2 3 4 4 4 1 3\n[1148] 3 4 1 1 1 2 2 3 3 4 4 1 4 3 4 3 1 2 4 2 4 2 3 4 4 4 4 1 3 1 3 3 4 4 4 4 4\n[1185] 4 1 3 4 3 2 4 4 4 4 1 3 4 4 4 2 2 2 1 2 2 1 3 1 4 4 2 3 3 2 2 3 2 1 4 2 1\n[1222] 4 4 3 4 2 4 4 4 2 1 4 2 4 3 1 2 4 4 3 3 3 3 4 4 1 3 2 2 1 3 3 3 3 3 4 3 1\n[1259] 1 1 1 3 3 1 2 3 4 3 4 1 3 4 3 4 1 4 3 4 4 3 4 3 3 3 3 4 3 4 4 2 2 1 2 2 2\n[1296] 1 4 4 3 3 3 3 1 3 1 4 4 4 4 2 3 4 3 3 3 3 1 3 2 1 4 4 3 3 3 4 3 3 2 4 4 4\n[1333] 1 3 4 1 3 1 1 4 4 3 4 3 3 4 3 3 3 2 4 4 1 1 3 3 1 3 4 4 3 1 4 2 3 4 2 4 1\n[1370] 1 4 3 3 3 4 4 4 4 4 4 3 2 2 2 4 4 4 2 4 1 4 2 2 2 4 2 4 1 1 2 1 1 4 4 2 4\n[1407] 2 2 1 4 2 2 3 4 4 2 4 1 4 4 4 2 4 1 4 4 4 3 2 2 4 2 2 2 3 2 1 2 1 1 3 4 4\n[1444] 4 3 4 2 3 3 3 3 4 3 3 1 3 2 4 3 4 4 3 3 4 3 3 3 2 2 4 3 3 2 4 2 3 3 2 3 4\n[1481] 3 4 1 2 4 4 2 3 1 1 4 2 1 3 1 1 2 4 2 3 4 3 4 4 4 4 1 3 3 4 4 4 4 3 4 4 3\n[1518] 3 2 3 3 4 3 3 3 3 3 1 3 3 3 3 1 4 3 4 2 3 4 4 3 2 4 2 2 3 3 3 4 4 3 4 3 3\n[1555] 3 3 3 3 4 2 3 4 4 3 4 4 3 4 1 3 3 1 3 4 4 1 2 4 3 1 4 2 4 3 1 3 3 1 3 4 3\n[1592] 3 4 2 4 1 4 1 4 2 4 1 2 2 4 4 4 4 1 1 4 2 2 4 4 3 1 4 1 4 2 4 3 4 4 3 1 4\n[1629] 4 2 4 4 4 4 1 4 3 3 1 4 3 3 4 3 4 3 3 2 2 3 4 1 4 3 3 4 2 3 1 1 1 1 4 3 3\n[1666] 4 2 4 2 4 3 2 3 3 1 1 2 3 3 4 1 1 1 1 1 1 3 1 1 4 3 1 1 1 3 4 1 1 1 3 4 1\n[1703] 4 3 3 4 3 3 3 3 2 4 3 4 4 3 4 4 3 2 3 1 3 3 4 3 2 1 4 4 4 1 4 4 1 3 2 1 2\n[1740] 2 3 3 3 3 4 1 2 3 2 4 3 3 1 3 2 3 1 1 2 1 1 4 2 4 1 1 1 3 3 4 3 3 3 3 2 4\n[1777] 3 3 3 3 3 1 3 2 4 3 4 3 4 1 3 4 3 1 4 3 4 4 3 3 1 2 3 3 1 4 4 1 4 1 3 4 2\n[1814] 4 2 3 4 4 2 4 3 4 2 1 3 2 3 1 1 3 3 3 3 3 3 1 4 4 1 4 3 4 1 4 2 3 3 3 1 1\n[1851] 3 2 4 4 3 1 3 3 3 1 3 1 4 1 4 4 1 4 3 3 3 3 3 3 3 3 3 2 1 2 1 2 1 1 4 2 4\n[1888] 3 1 4 1 1 3 3 3 1 3 3 2 4 3 4 3 4 1 3 4 3 2 4 3 2 4 3 4 2 3 2 3 1 3 4 4 2\n[1925] 2 2 2 3 1 3 1 1 2 3 2 3 1 3 2 3 1 3 1 1 1 3 3 1 4 3 1 3 4 3 1 3 2 2 1 2 2\n[1962] 4 2 1 3 3 4 1 3 3 4 3 4 4 4 1 1 3 4 1 1 1 1 1 1 3 3 3 1 4 4 1 2 3 3 3 3 3\n[1999] 3 1 3 3 3 3 3 3 3 2 3 2 2 3 3 4 2 2 4 2 4 4 3 3 1 3 1 3 2 3 3 1 4 3 2 1 4\n[2036] 2 3 3 4 2 1 4 4 4 4 2 4 3 3 3 4 3 3 2 2 3 3 3 1 3 1 2 4 4 3 4 4 3 4 4 3 4\n[2073] 3 1 3 4 4 1 4 4 4 2 4 4 3 3 2 3 4 3 3 3 2 4 4 3 4 3 3 3 3 2 1 4 3 4 1 3 3\n[2110] 1 3 3 3 2 1 3 2 4 4 4 3 4 3 3 4 3 3 1 3 4 4 3 3 3 4 1 4 1 2 2 4 4 3 2 3 3\n[2147] 4 4 2 2 4 4 2 2 1 3 2 2 4 2 4 2 4 2 4 3 3 1 1 1 1 1 4 3 1 1 4 4 3 4 3 4 3\n[2184] 3 4 2 2 4 2 4 4 3 3 4 2 4 2 2 1 1 3 3 1 3 3 3 4 4 4 4 3 4 4 4 4 3 2 4 3 4\n[2221] 4 3 3 3 3 3 3 3 4 3 4 3 2 3 2 4 1 3 3 4 3 1 3 3 1 4 3 3 2 1 1 4 3 1 3 4 4\n[2258] 4 1 4 1 4 2 3 3 3 3 3 3 3 4 3 4 2 4 3 1 2 1 3 2 2 1 1 1 1 3 3 1 2 4 3 1 2\n[2295] 4 3 3 1 4 4 4 4 1 4 3 3 4 3 4 4 3 4 4 2 4 3 4 3 3 2 4 3 4 3 1 4 4 4 4 3 1\n[2332] 3 1 4 1 4 1 3 3 2 3 3 2 3 2 1 3 2 4 3 1 1 4 2 2 4 4 2 1 4 4 2 3 3 1 4 1 1\n[2369] 3 3 4 1 2 2 1 3 1 2 1 1 1 3 4 2 4 3 3 3 2 2 4 3 4 4 1 1 1 2 2 2 2 4 1 4 4\n[2406] 1 2 4 1 4 1 1 1 4 1 4 1 1 2 1 4 1 1 4 1 4 3 1 3 1 1 3 1 1 1 4 3 3 3 4 3 3\n[2443] 1 1 1 1 1 4 4 1 3 3 4 4 1 1 3 3 1 3 3 2 2 3 4 3 3 4 2 4 3 3 2 4 2 4 3 2 1\n[2480] 4 4 1 1 1 1 1 4 4 4 3 4 1 3 4 4 3 2 4 4 3 4 1 4 4 3 1 1 4 3 4 1 1 2 4 3 2\n[2517] 3 1 2 1 3 4 3 3 3 3 4 4 4 3 3 3 3 3 2 3 4 4 4 4 3 3 3 4 4 3 3 4 1 1 4 1 4\n[2554] 3 3 3 3 3 3 4 2 4 2 4 3 1 2 4 1 4 4 2 2 3 3 1 1 1 4 4 3 3 3 3 3 3 3 2 3 3\n[2591] 4 3 3 3 4 3 1 4 1 1 4 1 4 4 4 2 3 1 1 2 3 1 4 4 2 4 4 4 4 3 3 4 4 4 2 3 4\n[2628] 4 1 1 4 4 1 3 1 2 3 1 4 2 2 3 2 3 3 4 2 4 3 3 3 3 2 3 1 1 1 4 3 2 3 3 4 2\n[2665] 2 4 3 4 4 3 3 3 4 2 4 4 2 3 4 4 4 3 4 4 4 2 4 1 3 4 4 4 3 4 4 4 3 2 3 4 2\n[2702] 4 4 4 1 1 1 4 1 1 1 3 3 1 1 3 1 3 2 3 2 3 4 4 3 3 2 4 1 2 1 3 4 2 3 1 4 2\n[2739] 4 2 3 4 3 2 2 2 3 4 3 4 3 4 4 2 2 1 1 2 2 4 3 3 3 4 3 4 2 3 4 3 1 4 4 2 4\n[2776] 4 4 4 2 4 4 3 1 1 1 3 2 3 3 3 1 1 1 4 3 2 4 3 4 4 1 1 2 2 2 4 3 3 1 3 2 4\n[2813] 4 3 2 2 4 2 3 4 4 1 3 2 3 3 1 3 3 3 3 3 2 4 4 3 1 3 2 2 2 2 2 2 2 2 2 2 3\n[2850] 1 3 2 3 4 2 3 4 2 3 4 3 2 2 2 4 4 4 4 4 4 4 2 3 2 4 2 3 3 4 2 2 2 4 2 4 2\n[2887] 2 2 2 4 3 3 1 3 2 3 1 1 2 3 2 2 3 2 4 3 1 2 2 2 3 3 2 1 2 2 4 4 2 4 2 1 4\n[2924] 4 4 1 2 3 3 4 3 2 1 4 2 2 2 1 4 4 4 4 3 4 4 3 4 4 1 4 4 2 4 4 2 4 2 2 2 2\n[2961] 4 4 2 4 4 4 4 4 3 2 3 4 4 4 4 3 4 4 4 4 4 2 1 3 2 4 4 4 2 1 3 3 4 4 4 4 4\n[2998] 3 4 4 4 4 3 2 4 3 1 3 3 1 1 4 2 4 2 2 4 3 4 2 2 2 4 2 4 3 4 3 4 4 4 4 2 1\n[3035] 3 2 1 3 4 1 4 3 3 4 4 2 4 3 4 1 1 1 3 4 2 4 2 4 1 2 3 3 4 3 1 4 1 4 4 2 4\n[3072] 2 3 4 4 2 4 1 2 4 2 3 2 2 2 2 2 1 2 2 2 1 3 4 2 2 2 4 4 4 4 2 4 4 4 3 3 3\n[3109] 3 1 4 2 4 4 4 4 2 2 3 2 1 4 4 2 4 3 4 2 2 4 3 1 4 4 4 1 4 4 4 4 1 2 4 4 4\n[3146] 4 4 3 4 3 2 4 1 2 4 4 4 4 4 4 2 4 4 4 1 4 4 4 2 4 3 2 4 4 4 3 2 3 2 4 2 4\n[3183] 4 2 2 4 2 4 4 3 4 3 4 4 2 4 4 4 4 4 3 4 2 4 3 3 2 4 3 3 4 3 4 3 2 2 4 4 4\n[3220] 2 2 2 4 3 3 2 4 1 1 4 3 4 2 2 4 3 3 3 4 2 4 4 4 2 2 4 4 3 3 3 4 3 4 4 1 1\n[3257] 1 1 1 1 1 2 1 2 1 3 4 3 4 1 4 2 2 4 4 2 3 4 1 4 4 4 4 3 4 4 4 4 3 1 2 2 1\n[3294] 2 4 1 1 1 4 4 2 2 2 2 3 2 3 1 4 2 4 3 2 2 1 2 2 4 4 3 4 2 4 2 4 4 3 2 4 4\n[3331] 3 3 3 3 2 1 1 1 2 2 4 2 4 1 1 1 1 3 2 2 4 2 2 2 4 4 3 2 2 2 2 2 4 2 2 2 4\n[3368] 4 3 4 4 4 3 4 3 4 3 1 3 1 4 4 4 3 3 4 3 1 2 2 4 4 2 4 1 1 4 1 1 2 4 4 4 4\n[3405] 2 4 2 1 1 4 3 4 3 1 3 3 1 2 1 3 3 2 4 3 4 3 3 3 4 3 3 3 4 2 2 2 2 4 1 4 4\n[3442] 4 2 4 1 4 3 2 4 4 4 4 4 2 4 2 3 3 4 3 4 1 4 4 3 4 4 1 2 3 1 4 4 2 1 3 2 3\n[3479] 3 2 2 4 2 2 2 4 2 1 2 2 3 4 4 4 4 4 3 3 4 4 4 4 3 2 4 4 3 4 3 3 3 2 4 2 2\n[3516] 2 3 4 4 4 1 3 3 1 4 4 4 3 2 4 3 3 2 3 3 3 2 4 4 2 2 4 3 3 3 1 3 1 4 3 4 4\n[3553] 4 4 2 4 4 2 4 2 2 2 3 2 2 2 4 2 2 2 2 2 4 2 4 4 3 4 4 2 3 4 2 2 2 4 3 4 4\n[3590] 4 4 3 3 3 4 4 4 3 3 1 2 4 4 4 2 3 3 2 3 3 3 2 4 3 3 2 1 4 4 4 3 4 2 4 2 1\n[3627] 4 1 3 3 4 4 4 4 3 2 2 4 2 2 4 3 3 4 4 3 2 2 4 4 4 1 4 1 4 4 1 4 3 4 4 3 2\n[3664] 3 3 4 3 4 2 4 3 2 2 2 4 3 2 3 4 4 1 4 4 1 4 1 3 2 1 4 3 4 4 4 4 3 4 1 2 3\n[3701] 3 4 3 3 3 3 2 4 1 3 2 3 3 1 2 1 3 4 4 1 3 4 4 3 4 4 4 3 2 4 1 3 4 4 4 2 2\n[3738] 4 4 3 3 3 3 3 3 3 4 1 4 3 3 4 3 3 4 4 4 3 3 4 4 2 2 2 4 1 1 1 4 1 4 4 4 4\n[3775] 1 4 4 4 4 2 1 4 2 1 4 2 1 1 1 1 1 1 4 3 4 4 2 2 4 3 2 2 4 4 2 2 2 4 4 4 3\n[3812] 3 4 3 3 4 4 4 4 4 4 3 1 1 4 2 4 2 4 2 4 4 4 4 3 4 4 4 3 4 2 1 4 4 2 3 4 3\n[3849] 2 2 4 4 2 4 4 3 2 4 4 1 1 3 1 1 2 4 4 1 1 3 3 1 1 3 1 4 3 2 3 2 4 4 4 3 4\n[3886] 2 3 2 4 4 2 4 4 2 4 2 3 3 4 4 2 2 2 2 4 2 2 2 4 4 3 4 2 4 4 4 3 1 4 4 4 3\n[3923] 2 4 4 2 2 4 3 3 2 4 4 2 2 1 4 3 2 3 3 3 4 4 3 3 4 3 4 3 3 3 2 4 3 2 4 2 4\n[3960] 4 3 3 4 4 3 2 4 1 1 4 3 4 2 1 1 3 4 4 1 1 3 3 3 4 4 4 4 1 4 4 1 4 2 4 4 4\n[3997] 4 3 4 4 4 4 2 4 4 4 2 4 2 3 4 3 4 3 1 2 3 4 1 2 2 4 3 3 3 2 3 3 2 4 4 4 4\n[4034] 4 4 3 3 3 4 4 1 3 4 4 4 4 3 4 4 2 4 2 3 4 3 2 4 4 4 2 2 2 4 4 2 4 3 3 3 4\n[4071] 3 2 3 4 2 4 4 4 4 2 4 4 3 3 2 2 2 4 2 4 3 2 4 2 2 2 4 2 4 4 2 3 3 2 2 4 3\n[4108] 3 4 3 1 2 2 2 4 2 3 3 4 3 4 3 3 2 2 3 3 1 1 2 4 1 1 4 2 4 4 1 2 3 3 3 4 4\n[4145] 3 3 4 3 4 2 1 1 4 1 1 1 1 3 3 3 3 3 3 4 4 2 3 4 4 4 3 4 3 2 3 3 3 4 4 1 4\n[4182] 2 3 2 2 1 2 4 4 4 2 4 2 2 2 2 2 3 3 2 2 2 4 3 4 2 3 4 2 2 4 1 3 2 1 1 1 4\n[4219] 3 1 2 4 4 2 2 1 3 2 1 4 4 2 2 4 4 4 4 2 4 2 4 3 3 2 4 4 2 4 4 3 2 2 2 2 4\n[4256] 4 4 4 4 4 3 4 3 3 4 3 4 4 3 1 3 1 4 4 4 4 4 3 2 4 4 4 4 2 2 2 2 4 2 4 4 1\n[4293] 4 1 4 1 4 4 4 3 3 3 1 4 4 4 4 4 2 4 3 4 4 2 4 4 2 3 4 4 1 3 4 4 4 3 3 3 3\n[4330] 3 3 3 3 3 3 3 3 3 3 2 3 4 3 4 4 4 4 3 3 1 2 4 3 3 3 4 3 1 3 1 3 4 4 4 4 3\n[4367] 4 4 4 4 4 2 4 2 3 1 4 2 4 4 3 3 4 2 3 3 3 2 2 4 3 1 3 3 3 3 3 3 3 3 3 4 3\n[4404] 1 1 1 4 2 1 4 3 2 4 2 4 4 3 4 4 4 4 4 4 4 4 4 4 1 3 3 3 2 2 1 3 3 2 3 4 4\n[4441] 3 4 3 4 4 4 4 2 4 3 4 1 3 2 3 3 3 3 4 4 3 3 4 4 4 4 3 3 2 4 2 2 2 4 4 4 4\n[4478] 3 3 4 4 3 3 4 4 2 2 2 4 4 4 2 2 3 2 1 2 3 4 2 3 3 3 4 4 3 4 2 3 2 3 4 4 2\n[4515] 1 4 2 2 2 3 1 1 2 3 3 3 1 2 2 3 3 3 4 4 4 3 3 2 4 2 4 4 2 2 4 4 2 2 1 2 2\n[4552] 4 4 4 4 2 4 1 4 4 4 2 4 4 4 3 3 3 4 4 2 2 2 2 4 4 2 2 2 4 4 4 3 3 4 3 4 4\n[4589] 4 4 3 1 3 4 4 4 4 2 4 2 4 4 3 4 3 2 4 3 2 2 2 2 3 3 3 4 2 4 4 1 4 2 4 4 2\n[4626] 3 1 2 2 2 4 4 1 1 4 4 3 4 3 1 4 4 2 1 4 3 2 4 1 2 2 4 1 2 3 3 3 3 4 2 2 3\n[4663] 4 4 4 4 1 4 4 4 3 3 3 4 3 3 4 4 3 3 4 2 2 4 1 4 4 3 3 3 3 3 3 3 3 4 2 4 4\n[4700] 3 3 3 3 2 1 4 4 4 4 3 4 4 4 2 4 2 2 4 4 2 2 2 4 3 2 4 2 4 4 2 4 3 3 4 2 2\n[4737] 2 4 4 2 1 4 4 3 2 1 4 2 3 3 3 1 2 4 4 2 4 4 4 4 4 4 2 4 4 2 4 3 3 3 3 3 1\n[4774] 2 4 4 4 4 4 2 4 3 4 4 3 2 4 4 3 4 4 4 4 3 3 3 3 2 4 4 4 3 4 4 2 2 4 4 2 3\n[4811] 3 2 4 3 4 4 3 4 2 4 3 4 3 4 3 4 4 2 3 2 4 4 4 2 2 4 2 1 4 2 4 1 2 3 3 2 3\n[4848] 4 3 3 3 3 4 2 2 3 3 4 3 4 4 2 2 2 3 2 4 2 4 2 4 2 3 4 4 2 4 2 2 3 3 4 3 3\n[4885] 3 3 4 2 4 4 2 4 4 2 3 4 4 2\n\nWithin cluster sum of squares by cluster:\n[1] 681403.3 357903.9 579703.3 462118.7\n (between_SS / total_SS =  80.0 %)\n\nAvailable components:\n\n[1] \"cluster\"      \"centers\"      \"totss\"        \"withinss\"     \"tot.withinss\"\n[6] \"betweenss\"    \"size\"         \"iter\"         \"ifault\"      \n\n\n\n\nCode\nfviz_cluster(kmeans4,data = whitewine)\n\n\n\n\n\n\n\n\n\n\n\nCode\nwhitewine &lt;- whitewine %&gt;%\n  mutate (Cluster = kmeans4$cluster)\n\n\n\n\nCode\nwhitewine$Cluster &lt;- as.factor(whitewine$Cluster)\n\n\n\n\nCode\nhistoVisibility &lt;- rep(TRUE, ncol(whitewine))\n\nwhitewine %&gt;%\n  parallelPlot(whitewine,\n              rotateTitle = TRUE,\n              histoVisibility = histoVisibility)\n\n\n\n\n\n\nParallel Plot is also available for Shiny - refer to the documentation!\nparallelPlotOutput()\nrenderParallelPlot()\n\n\nShiny App Built\nhttps://zjjgithub.shinyapps.io/MultivariateAnalysis/"
  }
]